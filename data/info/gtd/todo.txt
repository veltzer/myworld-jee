-fix up pdf generation.
-fix up resume and send to shay.
-read up the 250 page linux stuff.

buy sound card for the windows machine (cheap).
put better alarm system in car.
fix up my desk drawer.
solve problem of dependency in PDMT full build (temp file dependency).
send amdocs grades to maya.
bolt up the windows machine. -
fixup my web site - put new joomla etc....
start doing the mozart piece - see how it goes.
write the "who are we" part of the dd site.
do music homework.
put second life in a nice place with icon.


-do gcc slides for linux kernel course.
-do make slides for linux kernel course.
-do kernel compilation slides for linux kernel course.
-do three exercises for linux kernel course.
	- hello world.
	- driver (block driver).
	- new file system. 
	- proc entries.
-do p syncup.
-do something for wellsphere (get to working project).
-arrange bookmarks in my firefox.
-do amdocs grader.
-chess practice.
-copy cd from amit to computer.
-solve yarons riddle.
-get my personal site backup.

-write script for finding bad files and fixup all problems.
-study for course this week.

sunday:
=======
	- do some work for shay.
	- do one thing in meta (set dates to 07).
	- print out the tune amit gave me (lilypond).
	- throw out garbage that remained after computer screen buy.
	- good lunch.
	- read the communist manifesto.
	- finish reading the dawkins book.
	- do work for amdocs tommorow - check work and make list of all who sent them.
	- do work for amdocs tommorow - ant file for distributing the entire app.
	- do hearing training.
	- do drums training.
	- do bt training.
	-add the following subjects to my resume:
		-also add teaching for interbit to it.
		j2ee, servlets/jsp, jprobe, ant, java/xml, jboss, weblogic, tomcat, .net(general),
		ejb design patterns, extreme java programming, eclipse.

	- ear training (x12).
	- finish whats on the p plate.

misc:
========
	- talk to music shop about card for computer.
	- login to yahoo and read mail.
	- buy good sound card for cantor.
	- buy good router (+switch +cable connection +wireless)
	- buy a couple of wireless ethernet cards (3 cards).
	- put the car in the garage (for tipul).
	- get money for the expenses from shay.
	- read stuff in orchestration.
	
	- write the ecology article.
	- pass over the dd site and fix errors.
	
sunday:
=======
	-hook up printer to my new computer and make it print.
	-get wireless to work on my laptop.
	-install skype on my laptop.
	-install ksh on my laptop.
	-install eclipse and relevant java packages on my laptop.
	-install vmware on my main computer.

	-ba:
		register to ff.
	
	-homework for harmony.
	-p work.
	
sunday:
=======
	-buy book (baalat haarmon).

	-work for amit golan.

	-pay electric bill.
	-bt training.
	-school work.
	-prepare for friday course (exercises).
	-get shay to pay me the money he owes me.

	-piano practice.
	-drums practice (2).
	-hearing practice (2).
	-bt training.
	-cut nails.
	-do homework in harmony.
	-do homework in theater composition.
	-send debug to erez.
	-upgrade cantor and godel.
	-do application which records done items with date.

	-3 piano practice.
	-7 hearing trainings.

	-p sync work (pornstarbook).
	-v sync work.
	-try to get my laptop to boot on lean configuration (no dock).
	-get the interbit download stuff to point to the interbit project.
	-burn lots of dv (about 50 gigs worth).

	-send fix to gcc slide to interbit.
	-fix the joomla site problem.
	-sync amdocs material with my laptop.
	-download amits lessons to the hd.
	-chess (11x).
	-6 hearing training.
	-put music stuff into music box (and the other stuff too).
	-order my stuff from mom.
	-do work on healthcard.
	
evening:
	-send algo for david to shay.
	-get shay to give me money for the trip.

sun:
====
	-prepare the monetary report for the cyprus trips and give them to interbit.
	-handle grades for the unix course.
	-give them the grades for the course also.
	-do stuff for connegy.
	-handle stuff for other consulting work (send to erez on CC also).
	-prepare for extreme java course.

	-see end of film.
	-write down "I Remmember You" (from any real book but I want
		to have it on ly collection). Also practice on it.
	-chess x 10.
	-change local passwords to something better.
	-ten standards to ly.
	-do a list of music mental exercises.
	-write debug stuff for interbit and send it to them.
	-write a "open source conclusions for team managers" course.
	-move both of my machines to grub.
	-find virtual keyboard application and put it in my favourite applications.

sunday:
=======
	-do washing of dirty clothes.
	-submit travel docs to interbit.
	-get loan for paying back parents.
	-call gershon about working on jazz.
	-register to rimon.
	-do stuff about upcoming apartment.
	-fix up my cell phone to work.
	-take care of schema papers.

Pdmt:
	do my own function framework:
		A function is is much like a PDMT function (the pdmt function could
			eventually be removed and this function used).
	do my own readline implementation.
	prohibit my modules from using non Meta:: modules.
	dont do use Meta::xxx qw() - there is no need for the qw since we do
		not export anything. ever. and if we ever do it will probably
		be for good reason.
	my readline implementation will be based on nopts.
	do packages for lilypond for debian and put them on my
		site.
	makeing pdfs from docbooks takes too long. fix it.

	write a tool for xmlstarlet
	make my downloaders do the <img src=> stuff.
	finish all xml cofirmations in PDMT.
	change the defitions of the digest to the new producer.

	do the loading of the modules on demand (only modules which are needed
		will be loaded when they are needed).

	create a list of config files to backup and a program to backup
		them. do an option to derive this list from debian -
		by checking which config files I changed + which
		files are not under source control in /etc.

	restrict access to server-info and server-status.
		do this using an apache user admin with
		a password.
	install eskuel in my sites (and register its password).
		protect it with a password.
	install phpmyadmin in my sites (and register its password).
		protect it with a password.
	create a backup process for joomla.
	add links in joomla to
		ssh
		server-info
		server-status
		eskuel
		phpmyadmin

	run my own certification authority.
		do a set of commands to do this so it could be repeated.
	sign my certification and turn my site to https only (with possibly http
		only to get the certificate).

	do enable/disable option for internet testing (
		like email harvesters, imdb, perl upload etc...).
	do pdmt work (finish, lets say, perl module testing).
	stop using "throw Meta::Error::Simple(' in any of my modules.

	do threading object.
	make pdmt use linux::inotify and threading to know when things
		are changing and print them out to the command line.

	create usbmount.pl package.
	make usbmount.pl more configurable (use tt2 for the
		location and read stuff from configuration files).

	get a manual for mysql 5.
	do a full backup to gpg and document how to do that.
	finish the java making script and put it in my baseline.
		(stop it from being iteractive).
	make my own script to do a kernel package and put that
		kernel on my site.
	build mysql packages with ssl support and put them on my site.
		(do this using a script).
	make mysql use ssl only.
	make mysql use new password format only.
	do only single line of priveleges in mysql.

	one more p cut down.
	do work analysis for tdnet.

	do a script which runs tt with a hash file.
	use gpp in my apt repository thingy
		(both in the howto file and in the distributions/options files).
		write makefile which does everything.

	read about bind and understand it.
	install bind server at veltzer.net and manage it well.
	[name].veltzer.net servers are not known in the world. fix this using my bind.

	make my apt repository work with https.
	make my apt repository work with ssh.
	make my apache only listen to https.

	change documentation in my apt site to point to my keyserver.

	merge all older backups into once concise one (dvd).
	merge older emails from older backups.

	put machines in their place.
	connect printer to the new machine.
	stop the printing of the firewall stuff on the console.
	find out how to store stuff encrypted on my disk on key and do it.
	
	draw money from bank (for school).
	michal (!!!)

	make my deb site behave well.
	make a deb package out of IBM vm as well and check it out.

	catch up on mail.
	clean computer screen.
	do homework for gury.
	13 hearing training.
	write a program to transform links in almighty.
	8 movies.
	25 games of chess.
		put chess riddles away.
		start envelope for 2006.
	
	music:
		buy modus novus.
		buy czerny school of speed.
		talk to asia about violin lesson.

today:
	build a kernel.
	do a violin workout.
	merge my dev files.
	see another movie.
	backup my new files.
	inform amit about no lesson tommorow.

today:
	build a standard kernel.
	start my own debian package repositoy. make it a separate
	site in the apache config and make scripts to handle it cleanly.

	tommorow
	-pay electric bill
	-fax documents to guy.
	-order spraying of the house.
	-buy a sound recorder for music lessons and recording.
	-call ofra.
	-buy weight scale (need to have a diet).

	-test all pmtesters to see that they are quiet.
	-move all code to new options parsing thingy.
	-do the pretty printing class.
	-do pretty printing for the sql files.
	-distribute xml parsers between the various projects (they should be with them).
			Connections.pm -> Db
			Dbdata.pm -> Db
			Dbdef.pm -> Dbdef
			Digest.pm -> Digest
			Enum.pm -> Enum
			Links.pm -> Pdmt
			Movie.pm -> Movie
			Packages.pm -> Pdmt
			Persons.pm -> Persons
			Schedule.pm -> Schedule
			User.pm -> users
	-check for the following in database creation:
		0. boolean conversions from the xml files are probably not working.
		1. import of all projects.
		2. creation of constraints.
		3. default values.
		4. correct run of the schedule project.
		5. correct run the movies project (using query).
		6. correct use of the BOOLEAN type (the new one).
		7. correct indices creation.
		8. correct reference creation.
		9. behviour on reference deletion.
	-convert html files.
	-create html compressor and make it work.
	-use website as result of html compressor.
	-make pdmt control the copying of the files to the website (and remove the CopyFiles
	pdmt function).
	do a pdmt image scaler which automatically scales all my scanned images. use
		convert [infile] -scale XxY [outfile]
	do a routine task in pdmt which does:
		dpkg --get-selections
		which created a list of my installed packages.
		this way I will always have an update list.
		make it run every 48 hours.
	wrap meta up (do the packager project).
	save the book marks from the 2 files that I have in old_bookmarks.xml.
	do real dtd2docbook conversions.
	fix the fact that xsl files are unknown/standard types.
	get css out of the backups and put it back in (and build a type for it).
	use those to fix all remaining problems of the temp2any conversion.
	rewrite xml2chun using a real xml parser.
	build temp2any for all (we need those dtds!!!)
	then try to rebuild checking of xmls.
	build hints mechanism (to read hints from files hidden in comments).
	check that xinclude works in XML::SAX (add it to the current demo).
	use the type parser in Meta::Lang::Xml::Xml.
	write a demo that shows that XML::Parser::Expat leaks and mail it to the author.
	remove the EMPTY declarations from dtds and instead find the
		root of these DTDs.
	write standalone dtd to html convertor and start testing the
		dtd to html conversion which doesnt work.
	write deduction of html deps in PDMT.
	do a pdmt copy_with_deps function which defaults to copying my web site.
	get my web site up and running.
	need to say "Paper type A4" in all my lilypond source files.

	fix my central locking in the car (and behind the hanger of my backside).
	return the modem card and get a real modem instead.
	buy a speaker system with place for headphones and mike - connect head phone and mike.
	buy mp3 player and recorder on key.
	buy glasses.
	buy detachable headphones.
	buy boxes for packing in the house.
	upgrade the mother board on my linux pc (mother, memory and cpu).
	buy new flat big screen for the computer.

school:
	talk to school about grades from hearing development.
	sign up for next year.
	sign up for derug (start of next year).
	decide on next years courses.
	buy a computer and install windows.
	build a software repository for music software on that machine.
	hook up the computer to the synthesizer.
	buy a few condensorts to record my piano.
	buy a mixer to control my setup.
	fixup my master keyboard.
	
computer:
	write md5 find dups program for xml files (this is useful in examining which files have same
		info in them).
	reduce the size of my home dir.
	make azureus load faster (peer).
	re-enable userfreq after checking that my fix is right for it.
	full p fixup.
	make the docbook stuff work and send out my resume.
	make sure that kmail works and check out mails.
	organize a fax incoming and outgoing at my house.

arrangements:
	pay money to rimon.
	fill out the domain form and send it out to actcom.
	move my address at mas hachnasa to the right one.
	handle police reports that I need to pay.
	handle medical insurance.
	handle regular insurance (guy).
	fix remote of yamaha.
	fix dvd player.
	resume gas supply.

programming:
	add xinclude to stats parser.
	do C++ linking.
	10 module testing.
	store my own xbel definition at my computer and get it to pass.
	profile pdmt ram.
	get to full pdmt build.
	hide errors when running builds in PDMT.
	fix all show_* functions.
	add touch_node function in pdmt.
	check fast import of my md5 data (do tests).
	remove all empty test methods that still remain (I'm not sure there are any).
	check all init methods (should call super).
	put all lit data into the xml.
	do translation of lilyponds to pdf and ps (its better that way).
	make the node build runner cache the stderr results and print it on demand.
	do net domain (veltzer.net).
	do a message passing mechanism with subscription and unsubscription of messages.
	write a script which does what md5_purge.pl and md5_db_remove.pl do at
	the same time (saves resouces calculating these md5 sums).
	unlimited progress on text console: don't show the cursor.
	do a script that fixes files names to be standard (\w\d*.\w\d). 
	fix my file names in my p collection.
	do a script which calculates how much can be put on a CD.
		(files that is). And creates iso images from the calculations.
	fix all my xml files.
	do compilation of c++ files.
	do linkage of C++ files according to a link xml file.
	idea for Shell.pm module:
		have a ProtectedShell.pm module which inherits from shell and
		catches all errors from it thus keeping the shell alive always.
		Make the Pdmt shell inherit from that one (and actually all my
		shells).
	
in the house:
	fix the DVD player (doesnt play ends of DVDS and make it multi system).
	fix the remote of the amplifier.
	do new glasses.
	take care of gas account at my house (pay by credit).

in my apartment:
	do a new kitchen (and remove grates at kitchen window)
	get kitchen door out.
	add more electricity spots.
	replace two cracked tiles in the living room.
	remove stone defeneders on two small windows.
	remove steel defenders on two windows.
	do "roba" under the living room shutters.
	put some kind of mass storage place in the bathroom.
	hide the electricity cable in the bathroom.
	hang heater in the bathroom.
	new gas system.
	change door buzzer and door intercom.
	holder of extra papers in the toilet.
	shelf in the toilet.
	hide the big grey hose in the toilet.
	remove irons in the small balcony.
	another phone jack in the bedroom.
	fix the yamaha remote control.
	fix multi zone for DVD.
	cassete for cleaning the VCR.
	new toilet cover seat.
	new glasses in the living room (big ones).
	living room (leather seats).
	washer and dryer.
	big library.
	hang more decorative paitings.
	put new air conditioner.
	new window in the toilet.
	make a tunner to pass cables between living room and bed room.
	buy a small set of speakers for the bed room and hang them.

writing:
	write idea for a movie about my life philosphy.
		names could be "grow up", "everybodys fucked".
		sections: politics, economy, religion, sex, war, death.

idea about checking multiple files:
	Have a set of pipeline functions:
		1. function which checks permissions.
		2. function which checks file names.
		3. function which checks extensions.
		4. function which checks that the file is an image (or other type).
		5. function which checks that the file is larger in size than x.
		and more.
	Enable to compose such a pipe line from the cmd line by using known functions
	and enable to add functions of your own.

open up my palm backups and integrate the information there.
re-apply patch to podlators and store it (the dump syntax OK messages are here again).

bookmarks:
	1. do SAX import from my own bookmarks xml files.
	2. do SAX import from the galeon session files.
	3. do SAX import from the galeon bookmarks files.
dbman:
	1. does not work to show manual pages - check it out and fix it.

computing:
	Do a non circled graph.

	signature problem:
		only CPAN gets emitted into my signature (other open source
		development stuff doesn't).

	DBI:
	has to remove long table name from schedule project because of Pg limitation.
		remove that limitation. Check the postgress mailing lists and maybe
		compile a new version of pg.
		bring back pg supprt.
	separate generating primary keys in posgress:
		ALTER TABLE distributors ADD PRIMARY KEY (dist_id);

	unify all installation instruction to a single big xml file.
	
	libxml does not show me errors in xml checking. Make it do that.
	build all databases (schedule refuses to be built).
	bring back unique constraints and build all databases.
	check that unique constraints work.
	get to clean pdmt build.

	recreate all databases.
	do my own capturing of stdout and stderr.
	do a database defintion for Pdmt.
		Pdmt will start connection to the database on startup.
		This way the connection could be used by any build
			method etc...
		Store the uptodate info in the database.
		Store the last error descriptions in the database.
		add "sql" command in PDMT to give an SQL statement to the
			Pdmt database.
	fix up the Meta::Baseline::Test class which throws warnings
		on Pdmt startup.
	do an executable which tries to compile each library in its own right.

	add command line analysis capabilities to Pdmt functions.
		make the hello world function not accept any
		arguments.
		make the backup function accept the file name to
		hold the backup as parameter.
	the construction of the opts object should be a one time
	thing (at object construction or other time).

	output a Class::DBI like file for a database definition.
		options:
			1 file <-> many files.
			automatic update of files in the baseline.
			Prefix: Meta::Projects::[dbname].
		and other options.
	A command line tool to do the work: db_create_interface.pl

fortune project
	write a paper about it in docbook.
	add a programmers TT2 substitution of fortune. 

	put compressed xml files into the baseline and do operations
		on them (that is not supposed to be a problem).
	do a scanner for xml which generates the dependency on
		.dtd files.
	do a scanner for dtd which generates dependencies on .mod
		files.

pdmt:
	add an uptodate calculation command to pdmt on only a few nodes.
		(by node name etc...).
	optimize the command in Pdmt which calculates uptodate
		status on all nodes.
	do the steven knight ideas do:
		0. locate h files by name.
		1. locate h files by function they declare.
		2. locate .so files by function they implement.
		This is a begining of autoconf support by Pdmt.
	implement show_by functions in Pdmt.
	implement edit_by functions in Pdmt.
	finish the backup function in Pdmt and check it.
		and make a real backup.
	do completions in Pdmt.
		start with build_by_type_names [tab] which will show
			all type names.

	perl quality:
	make script which checks:
		#sub foo vs sub foo vs =head2 foo
		run this on all files.
	pass all checks on all perl source files.

	fix all xml checking (md5 is weird and only works on
		some of the files).
	check out the DBI error class which I saw.
	pass checks for perl files.
	capture output from every command I run in Pdmt.
		store the output for each one as error for the node.

	warnings in HTML generation from POD should be caught as errors.
		Make it so. How do I catch stdout ?!?
		use IO::Capture::stdout (install it and use it).
			test is by putting =back in .pl file

	remove win2lin project from source forge.
	do syntax checking in PDMT of docbook pieces.
	do creation of perl packages.

	create new patch for PodParser (1.23).

	make sure all of my patches are up to date with CPAN.
	publish my perl patches on my web site (automatically).

	unite the perl_check and perl_check_single scripts.

	add following function to PDMT:
		add passing of argument to functions in PDMT.
		search_and_replace_by_type_name [node type name] [regexp] [regexp]
		This way I will not need base_aegis_grep.pl

	change the dbdata parser to use attributes.
	make sure that dbdata importing works.
	make sure that weblog_cgi works again.

	upgrade my libxml version and update version of perl wrapper.
	make the weblog import thingy work again (actually the entire
		db import stuff).
	do a UI for inserting contacts.
	finish the last database which is still not created.
	fix the PDMT bug.
	do utils_save_env.pl which saves the encironment into a file.
	use utils_save_env.pl to fix my login script.
	check that the contacts related executables still work.
	work on the mailing list filters as defined in my xml and
		on their export to kmail.
	The movie.xml file doesnot pass tests - fix it.
	some xml files (theme.xml) do "out of memory" when being
		checked. Make it not so.
	fix all xml files (make them pass all checks).
	make all tests pass.
	get to a clean PDMT build.
	get to md5 import xml working.
	make the md5 produce script work correctly with symlinks.
	fix the symlink stuff in file iterator and add that option
		to every utility using the file iterator.

computing:
	do checking of DTD in one way or another.
	get console file sharing software on my machine at home (emule client).
	do the heirarchical permission system some more.
functions:
	add perl object which read, write, present, print and calculate these functions.
	This is for UI and web also.
	make the schedule database inherit from that database.
dbdef:
	0. write rules about conventions about writing dbdefs:
		I. table names are in SINGULAR form.
		II. primary key is "id".
		III. reference to a key in another table "foo" is foo_id.
			(unless there is more than one and then it will be:
			foo_[purpose]_id).
		IIII. more to write....
	1. non inheritable attribute for tables in dbdef.
	<table id="foobar"
		name="foo"
		inherited="false"
	/table>
	This feature will make a reader screem if a parent already has this table.
	2. check that my conventions for writing dbdefs (singular form etc...) are followed
		in all of my dbdefs.
	3. are "key" type fields always optimized ? It should not be so. Force users to
		use optiomized="hash" in key fields too and see that all works.
	4. limit length of identifiers (table names, field name etc..). we had a problem like
		that with postgres.
	5. make using the db protector (alternator) an options that can easily be changed.

programming work:
	check out http://search.cpan.org/src/AJGOUGH/Data-Dimensions-0.04/lib/Data/Dimensions/Map.pm.
		This is great!!!
	http://search.cpan.org/author/ABIGAIL/Geography_States-1.6/

perl module documentation updates:
	add FAQ section to every perldoc.

	submit request to the galeon team to allow to configure the
	http port (from 80 to something else). Stress that this
	is different from proxy configuration.

	redirect port 80 to 8080 and run my http daemon on 8080.
	build everything.
	do real dependencies in PDMT.
	do packaging of new Meta in PDMT.
	do new website.
Ad&d:
	get some tools for Ad&d programming to my computer.
	write a document describing my campaign in Ad&d.

user space linux kernel configuration idea:
	hooks in the kernel to user space which enable the user to provide own
	routines which provide configuration options for kernel modules.
	each call by the kernel will be routed to user space and the user will have
	to write a module which knows how to answer such calls.
	Example of configuration mechanisms:
	1. configuration read from modules.conf (like today).
	2. configuration read from an RDBMS (many machines could be synched vs
		the same database).

ideas:
	do an xml file which matches colors to file types (like dircolors).
	make an ls substiture which runs that.

ideas for certification
	the bug 2027 (2^32 since 1.1.70).
	more than 4,000,000 records per db
	cannonical planet name. which includes:
		meta galaxy
		galaxy
		metcluster
		cluster
		star
		planet
	This is an extension to the url concept.
	Extension to the time concept which involves the point of view.
	tables in databases with stars etc...
	various 4d coordinate system regulation.

add a patch to the progress bar widget which will show progress without
knowing when the end will come (send that as a patch to the author).
see that this patch works well with my font import program.

support views in my dbdef system:
	1. add it to the dtd. 
	2. add some views for example (add example database).
	3. implement it for mysql and pgsql.

shield stuff:
	do the shield interface to Pdmt, put the files in it
	and start using it. Bye bye to aegis.
dbman:
	finish dbman system with search capabilities.
	make a partial import and see that the database is well
		and can be searched (do it with postgres too).
	borrow code from makewhatis to get the one liners.
		do many tests for the oneliner in groff.
pdmt:
	create real HTMLS from perl code.
	create xslt targets in Pdmt.
	make the PDMT show graph a function.
	have PDMT have an "edit [nodename]". command that each node will implement.
		File nodes will open an editor on their content after checking
		it out from the source management system while database nodes
		will use my database record editing capability.
	pdmt shell will have a "edit_sources [nodenames]" which will edit all
		source for the nodes.
	better yet - have a PDMT option to edit all source files responsible for 
		target not being up to date.
	add show_mod_time_by_names command to PDMT which will run over the nodes,
		will ask them for modification time support and will print that
		info if they have it.
	do pod->docbook conversions in Pdmt (they should be docbook fragments
		and not have docbook declarations in front of them).
		PATH/FILE.pm -> xmlx/docbook/PATH/file.xml
	do pod->html conversions in Pdmt.
	do pod->txt conversions in Pdmt.
	do pod->latex conversions in Pdmt.

put my own catalog into my own XML file (use my own conversion for
	that).
download new docbook documentation and improve my documents.
add application which prints stats about an XML file (and among
	them its type). Make that application be recursive on
	directories and run in on my XML directory to check the
	types of the documents.

remove unneeded line at the end of my tables in my home page. add
	them only if no documents are found.

fix up the libxml code to get my docbookx verified.

move all of my documents to the XML subdirectory.
get ridd of the SGML subdir.

Meta Meta::Template to Meta::Lang::Tt. (its better if It's there).
	This marks a departure from having to store objects the
	way CPAN does this. Check out other areas of the code
	and do the same if the CPAN convention is not good enough
	for me.
make the code which does regexps on development files collections
	using TT2 when converting temp->html use the PDMT graph
	and do this much faster.
	Actually move all of this substitution code to some TT object.

do more of the CATALOG class until all the functions there are operational.
use Catalog.pm in libxml to identify resources and get them.
use URIs in libxml so that I wouldn't do stupid regexp matches.

bring back web cache usage to LibXML.
get my docbook verified (use a catalog maybe ?!?).

accoding to jade I can now write my docbook documents in xml.
	This means that I can open a directory:
		xmlx/docbook/
	and add SGML content there and check it as straight XML and
	add a URL to point to the XML DTD of docbook on the WEB.
	Check it OUT!!!!
	If I manage to do this then move all my SGML content to temp/xmlx/docbook.
email Dtd2html author about the fact that putting documentation
	for attributes renders the resulting html non xhtml compliant.
I can remove my imported DTDs and use URLS instead (they will be
	used using webcache).

make a website_copy function in Pdmt.
	The function activation will be like this:
	PDMT# function website_copy
	This will cause PDMT to call a registered function called
	website_copy with the PDMT graph and perhaps some
	parameters.
	The function will read xmlx/modules/website.xml
	and will deduce it's dependencies using the pdmt graph
	and will copy them to the right location.

try the following improvement to the graph module:
	dont always create in and out edges - create them only if
	edges are inserted. This means that edge_ou and edge_in
	methods will check for that and return empty sets if
	they do not exist. Create a single empty set (global)
	and use that as a return type for these.
	See how this affects memory consumption (it should).

make dummy running tests for pl modules.
make pdmt unload modules after testing them.
	make another piece of code that tests code on the outside
	(using an external perl interpreter).

try to import the celebrity database I found on the web.
start a new project for celebrity data.

make a backup option in PDMT (it does know all the sources !!!).
	make a backup option for targets also.
	(actually make a backup option for every node set).
	(this would be yet another function).

make htmls generated from dtd look nicer:
	1. titles.
	2. description paragraphs.
	3. generated by should be changed.
	4. documentation for element attributes (removed because they render
		the resulting html non XHTML compliant).

pdmt:
	performance work: work on reducing pdmts memory footprint.
	move all Pdmt Nodes to Pdmt::Nodes.
	make successful run nodes (they will be used to pass all tests).
		make one of those for each Perl file!!!! YES!!! PDMT IS GREAT!!!
		same thing for performance measurments.
	add a feature to reload a class to PDMT. (a runtime feature).
	make the pdmt show correct out of date information.
		(deps!!! deps!!! deps!!!).
	make not all source files which are not handled by handles be of
		SourceFileUnhandled type.
		All other sources will be given types by the handlers.
	build an alias system for pdmt.
		alias foo bar
		which create a new command called foo which will read command bar.
		put some alias into my ~/.pdmt_shell.rc file.
	Put all Pdmt modules under Projects/Pdmt and not under Pdmt.
	Move all Pdmt Nodes under Nodes.
	Move all Pdmt Handlers under Handlers.
	enable pdmt to run in non interactive mode and give it a command or script.
	add levels to show_ingredients and show_products.
	build links with pdmt.
	implement the content of the help command in pdmt.
	thread which monitors files for changes.
	auto completion of node names.
	add feature which will show you types of edges in the Pdmt system.
	make pdmt do all the really needy stuff.
		0. compile and link C++.
		1. do databases.
		2. make documentation out of dtds.
		3. make stuff from templates.
	make the arch object be parsed right as part of the perlpkgs parsing.
	add counter to the commands that pdmt executes so that you could use that at the pdmt prompt.
	performance enhancement: do FAM and so don't always ask who is uptodate. Just print what you cache.

add dependencies for XML files.
another feature for pdmt - show out of date types
	this will should all out of date files according
	to types and each type with the number of nodes of it's
	type.
make the dgraph object accept pair objects as edges and store them.
	This way people could inherit from edge objects.

open source stuff:
	write a bug report on IO::Pipe to the maintainer to tell him that there
	is a problem with inheritance.
	write a bug report to the kmail people about the fact that I have to exit
	kmail to make my status save itself (which emails I wrote for instance).
do the same thing that I did for colors for:
	language names,
	icons,
	currency names,
	timezones,
	mouse names,
	screen names
	termcap database.
	and lots more!!!.

make all parsers in Meta::Xml::Parsers inherit from proper parser
	(links does not for instance).
write SAX parsers instead of standard ones. Start with version parser.
make the version object be able to read itself from xml using SAX. 
do a test for the version object which reads itself from XML.
start reading version object when reading perlpkgs.

architecture changes:
	-fix platforms.xml
	-read the platforms from platforms.xml.
	-determine compatibility.

-build everything and pass all tests.
-put cell phone numbers into my xml file.
-put project documentations into the meta distribution.

-make a dtd for a platform:
	CPU family
	CPU version
	OS family
	OS version
	Compiler family
	Compiler version

dependencies for xml files are wrong.
dependencies for dtd files are wrong (or nonexistant).

download and document aalib.
make an SLOC functions in PDMT (each node knows how to count it's sloc).

	put all cell phone details into contacts.xml.
	export my xml file to my phone.

make export to kmail with VCARD format.
make export to gnokii format.

elems:
make sure that elems knows how to reuse connections.
make elems use https too.
run my elems on a regular basis and redirect port 80 to the elems port (65000).
make a nice statistics page.
have elems store which fetches were on the same connection (add a columns with
	unique connection id).
make some algorithm which gathers fetches to multi featches (according to same
	ip etc...). Add another field for that too.
make a piece of software which deduces which paths are the most likely in the site.

make the archs dtd have attributes.
htmls from DTDs are still not made - fix that.

find out why when I install my Meta Pod::Man and Pod::Latex are not
detected.

move contacts into an RDBMS (write contact_import.pl).
make the script that moves things into kmail work from the db.

aegis prints results of tests - why should I ?

install a WAP gateway on my machine (are there any good ones ?)

sort all stuff in /mnt/hdc5/mark/unsorted
integrate /mnt/hdc8/mark/personal_databases/ into the baseline

publish bug in gnokii- gnokii does not install it's header files ?
get the GSM gnokii module to compile and play around with it.

make a script in perl that will check the prerequisites for me
	perl/bin/Meta/Lang/Perl/perl_check_prereq.pl
	It will take the prerequisites from a package (lets say
		Meta for instance).
	This way I will know that I have everything I need installed.

download sloc, install and document.
Make an sloc tool which runs sloc and takes the relevant output
parameters and provides them to the runner.
use this tool to estimate meta dynamically in my web page.

mark both of my cd burners as not working in the CD burner database.
	(both the yamaha with my card and the hp usb one).
	Maybe try to get them to work by writing better drivers ?

if I do md5_purge --directories=foo/ then the extra slash appears
	in everything it does because opts::sopt does not cut the
	extra slash for directory lists (just for directories).
	Do the following:
		to_cannoic($) return cannonic path (with no / at
		the end and relative to current location).
		to_cannonic_path($$) the same for paths and a separator.
		put them somewhere in utils::file and use them
		in opts::sopt.

add the windows2linux script to my meta package under the bookmarks
project.

add a backup script to backup all my stuff on a nightly basis and
send me an email as a result. Put this is crontab and
put a multi session cd in the drive. Make the script blank the cd
on end of space. make it backup the home directory as well with
exclusions.

consider joining the fsf as a member (120$ per year).

get the code of mime_import_mt.pl and put it into Mimes.pm.
get Mimes.pm to put itself into a database.
change the inport of mime to read a Mimes object and write it into
	a database.

kernel hacking:
port my script option to 2.4.20.

pics:
	make the thumbnail project work correctly with gqview (set the date).
	make the thumbmail creation script do dates.
	make the thumbnail creation script check for files sizes of 0
		(bug of gqview).
	check what is wrong with the thumbnails I'm creating.

idea:
	write down all components that I need for myself to be
	working on a Linux system and make a script to check that
	all components are there. It will either use RPM or
	try to find the tool at the command line.
	This project will be called prereqs.

publish contacts in the new kmail format too.
	~/.kde/share/apps/kabc/std.vcf

idea:
	write the ideas about subpackage.
	every perl package could have sub packages. They will be generated
	also by the same procedure. Meaning:
	pack1 pack2 pack3 : source files
	I could make packages such as: Meta-Ds Meta-Pdmt etc...
	Think about it.

start a new project which will help you with writing cds.
start a new project which will handle all server starts and stops
for you (store pid in a database and thus track if its running etc...).
(there are some stuff in my home directory).

connect the cd to my machine and get the cd stuff to my software
	services directory.

make the dbman_man.pl show it's stuff right (it's not right now).
make the dbman_man.pl extract correct headings from troff files (a troff
	parser out of CPAN ?).
make the dbman system only show errors of import.
make the dbman system use MMagic for content (it's still using filenames
	only).
import EVERYTHING into the dbman system and search on it and see that all
	is well.
eliminate usage of use Error (:try). Try to use this with the Error:: prefix.

build my own viewer in perl. It will use character input to do its thing
and the curses library. This way I could stop using Tool::Less.
This perl will also be a standard command line replacement for less.

now:
	bring back creation of html from dtd (fix their parser).
	bring back SGML using open jade.
	make creation of tables be a one time thing (not alter but
		rather full create).
	make Ocontainer which has size and elem and foreach above
		them all.
	make all possible container inherit from Ocontainer.
	remove all uses of Meta::Ds::Oset and move all users of Meta::Ds::Set
		to Meta::Ds::Noset.
	eliminate all the "sub print" methods.
	remove all ->print and replace with ->foreach.

idea:
	write a module to report your inet connections with nice objects.
	use that module to write a ppp(other ?) connection monitor daemon.
website:
	do automatic scanning for patches.
	do automatic scanning for packages.
	fix the broken DTD department.
dbi:
	do testing procedure for it.
	try to inherit from DBI again to cut down on code size.
graph modules:
	do a test which does very heavy duty testing on the graph module.
	Generate a graph with lots of nodes and lot of edges and run some
	algorithms on it. Measure the time it takes to run all of these.
	Now try to improve the graph object.
md5:
	do md5 executable which removes duplicates using sql.
		the executable will also remove md5 signatures in the database
		along with removing the files.
	remove the md5_finddup executable.
	change md5_import to md5_update.
	add feature to md5_update which creates the root directory.
	add default data to databases and add the root directory to the md5 database.
dbman import todo:
	send email to aegis mailing list about a problem with z_cr.so
		in the aetest.5 manual page. What is that thing ?
	fix this error in dbman import:
		not matched [/local/tools/man/man1/editdiff.1]
	handle the fact that the dbman import process leaves around a lot of
		.png files. Get ridd of them somehow (even a hack).
	change path of dbman to be taken from man automatically.
	check the search for manual page stuff.
make an option to login without development stuff or to turn
	off the development stuff on the fly (using the SAME script so
	that the turning on and off will be synced).
cleanup:
	stop using my text reader iterators (instead make it
	easier to use the built in File::IO...).
	make more error types.

add irc details to the author file and make it create automatic
	connection files in xirc and kirc.
compiling everything:
	do my own implementation of modules used (weak one).
	try to build everything again.
add reliance on perl 5.8 in my Meta package.

make an executable manager object. It will store a single object
	to resolve executable locations.
	It will also be configuration in that you would be able
	to override path derived executable location and give
	your own set of tools.

make ModInfo module in Meta/Lang/Perl to extern Module::Info
	and scratch Meta::Module::Info.

idea:
	make email_signature.pl store a cached version of the result
	in a database and if the ingredients have not changed give
	me the database version (it will make it run a lot faster).

make an RPM tool which knows how to:
	1. install packages.
	2. list which packages are installed.
	3. import the entire package database to a real RDBMS.

make X stop listening to the net and document how you did that.
make the --pod options (and thus the pod documentation in the binaries)
	describe the free arguments too.

publish my notes for installing CPAN modules on the net.

write a conversion program from /etc/services to XML with all
	the data.

build my own replacement for nmap which uses my own XML list of
	service names.

check that all my patches for perl modules are up to date.
	(config-general needs to be upgraded or maybe discarded ?!?).
do a script which generates a patch between two .tar.bz2 packages.
use that script to generate patchs to all my open source perl module works.
put all of those on my website (patch directory).
do a system whereby I put descriptions of the patches along side the patchs
	and they get presented in the HTML.

do automatic program which generates a graph of all library dependencies
in the system according to ldconfig (make a graphic version of this graph
too).
make a small piece of software which finds out if a library is self sufficient
and which other libraries it needs. This will work that way:
	1. scan all system libraries and store their symbols.
	2. take each library and try to link it.
		if it does not link then try and link it against
		other libraries which provide the missing symbols.
	3. generate a list of each additional libraries linked against
		each library.
add version numbers of libraries to my xml link script.
make an ldconfig tool (is there one in CPAN ?) which can give a service such as:
	list all directories for ldconfig
	list all libraries that ld.conf.cache has.
	and more.

order of todo items:
	1. finish building everything.
	2. unite perl/bin/Meta/Development and perl/bin/Meta/Project/Develop
	3. do a ui for putting todo items in.

get my favorite bookmarks into the baseline in XML format (get it from
	my old google) and do a program to moves it ot konq, mozilla and
	back to galeon. Do a syncing utility between them.
try to get my aegis account to work (use the new init script directly from baseline
	or change).
get the full development environment to build and work.
check why when I checkout files from the baseline they are under mark.aeuser
	ownership ?

hobbies:
        add darts as a hobby in my hobbies (as well as juggling).

hardware:
	buy stickers for my keyboard.

Java:
	do a tool for Kaffe (in the java section).
	move the code that currently run javac from the Java.pm into Lang/Java.

todo:
	send two messages to DBD::Pg development:
		1. patch to reduce messages.
		2. errors in testing.
	run a nameserver at my house and use it instead of
		actcoms. Also supply it's use to the outside
		world (open the port in the firewall).
	keep on arranging my papers.
	re sign in to various mailing lists.
	in the israel-hackers list change subscribption option so it wont send
	me digests.

Replace all die usage with Error.pm exception throwing.

buy for the house:
	Shaving blades.
	stick against cutting yourself while shaving.
	washer and dryer for clothes for the bath room.
	smell spary for the bath room and toilet.
	tooth picks.
	pills against head ache.

role playing hobby (new):
	Put all of my previous character sheets and maps
	in there (scanned).
	Put all of my current data in there.

idea:
	system for people from all over the world to assert that an
	idea is theirs. You add some info to a database and it stores
	the info with your date in it. You can also add encrypted info
	if you don't want the people running the database to know your
	idea (in that case you need to remmember the secret key used
	for the encryption yourself). This will enable you to prove
	in a court of law that you owned the idea a while back.
idea:
	system for people to make suggestions and have people
	vote on suggestions (could be made for town halls, web
	sites, what ever).

idea:
	When I have the Xml with codes in it (like bank code
	etc...) then I can tell the cell phone synching utility
	to put important codes in there too.

idea:
	some jpgs have animation built into them which is good
	for internet (first a very rough picture appears and only
	subsequent layers make it show). Make a routine to extract
	an md5 from an image JUST BY LOOKING AT THE PIXELS WHICH
	SHOW FINALLY. This can avoid stuff like:
	1. tags being different while the image is the same.
	2. the gradual effect describe earlier.
	and probably other stuff.
	make the md5 info gathering pieces of software ask for
	an md5 collecting function instead of running a standard
	md5 algorithm. Better yet - make it ask for a class which
	can do md5 according to the file it meets etc...

today:
	build my own desk.
	write the md5 update script.
	do a url retriever which uses the cache object.

books:
	but the new version of "Running Linux" from Oreilly.

codes:
	in the information about an author keep various codes
	(bank money machines and other codes).
	integrate my own money machine code into it.

xml stuff:
	fix my standard xml checking techniques.
	fix why dtd2html conversion emits warnings.
	fix the way htmls generated from DTD look.

Pdmt:
	make the tt2 transformation with attribtues from the graph (all kinds of
	methods of it REGISTERED AS METHODS!!!!).
	make pdmt produce html from dtd.

XML checking:
=============
remove my imported dtds from my baseline (instead point to urls
	as dtds).
make the URL cache stuff so that I will not bring a DTD over the
net every time I want to check it. Make the cache work over either
a file or a database.

svg in the baseline:
	check with the authors of sodi podi why can't I verify
	the sodi podi files using the svg dtd ?

md5:
	do the import script using DBI
	remmember modes in the database and not the stupid file/directory
	stuff.
	make the import script also do updates.

now: Pdmt work. Generate dependencies using scanners for perl
source files. Store the dependencies in an RDBMS.

Caching of info:
	A cache project with a cache class which works over a database.
	A single table is needed with the following attributes:
		id (integer)
		key (binary)
		data (binary)
		date (TimeDate) - when was the data inserted.
	The cache could receive a size and will keep itself under that size.
		(should a size field be added to the table ?).
		During the life of the cache it will not refer to the database
		to recalculate the size each time (wasteful). Instead it
		will keep the currnt size in RAM. To remove enough of elements
		so that it eactly the right space will be free will requie a
		strategy. Only a single strategy will be implemented in the
		begining : remove all old items. How do we know how many items
		we need ? The strategy could initialize itself on startup
		and this one will read all cached items sizes and will store
		them in a mathematical structure which will enable it to
		know exactly how many elements to remove. Build this math
		structure or get it from CPAN. strategies will be plugins.
	In general: try to fit this framework under the general Cache
	framework from CPAN.

Pdmt scanners:
	A scanner is a an object which has some abstract methods
	implemented and is executed whenever a source file changes
	or is added to the project. The scanner may choose not
	to rescan the actual file according to caching or whatever.

	Note:
		Scanning can only occur after the entire basic
		graph is read as a second phase.
		This means that when ever adding nodes to the
		graph first add the nodes and then scan them.

elems:
	When a request comes for a page and the page is missing
	I can give out a list of the closest pages in terms of name
	(some closeness in either MySQL SQL syntax or some perl
	module).

today:
======
write bosa by ofir.
record yoni rechter and put it on my web site.

SMS sending class:
==================
	find out about SMS classes on CPAN.
	Make a generic SMS sending class.
	make a class derivative for Pelephone.
	make the generic class generate a derivative according to phone number
	or the company tag attched to the phone so that the code that sends
	the message does not know the transport method.

idea about SMS:
===============
Make a class which translates country codes to country phone prefixes.

Data structures:
================
start a full Meta documentation and add this project as sub documentation of Meta.
put the full Meta documentation on my site.
compare the performance of oset.
finish the three way map.
make a new ordered hash using a three way map.
compare performance to the old oredered hash.

pdmt shell:
	0. make the can_remove [nodes] command.
	1. make the pdmt regular runner not do the loading (put it in
		the startup file if you like).
	2. make a better underlying graph object. The current one is
		just terrible.

use Cache::Cache to accomplish things.

write an inheritor from Shell.Shell which accepts a functional
documentation in XML and uses it to know which functions to run, do auto
completion, etc...

I do plan to get married. Just as soon as I find a female who is certified
	as a human.
	Mark Veltzer

The product of Linux kernel development is the source code. The binary that
	actually runs is a side effect and is not required by most intelligent
	users.
	Mark Veltzer

idea:
	my own shell in which every function available registers
	itself and thus I can make completions much more intelligent.

idea for pdmt:
	when pdmt knows of errors and keeps them for you have it also
	keep a tag next to each error which you can mark as "dealt with"
	(just for your own book keeping purposes). This way you can
	build this set of nodes and see that you indeed took care of
	those problems or just see errors which have not yet been dealt
	with.

Db infrastructure:
	make a database dbi object which connects to several databases at
	the same time and does everything on both...:) See the advantages ?
	change Meta::Db::Console::Console to Meta::Db::Shell.

project hints:
==============
	-do a hints database (tip of the day stuff).
	-be able to select a random hint.
	-Write a wrapper around the regular gtk and kde hints object for this
		object.

In pdmt keep a copy of the source file content cached (if the user
wants that that is). The idea is not to load the file if needed.

idea:
	write a TT2 function "[% state_name_permute("value") %]"
	and surround all database name with these.
	Next - my the script which moves my web site create all
	the databases with the production names and put
	data into them. That's it. That will keep my development
	and production environments apart.

today:
	url cache for RDBMs. This could also serve as a proxy.
	try to build a proxy around it. Build info into the proxy
	about when pages were requested and each time a page is
	requested add info about the request.

tommorows deals:
	phone insurance guy.
	build desk.
	send mail to the guy that works with tsemach about the job proposal.
	send heshbonit to Intel.
	get money from the bank.
	pay money to internet provider.

develop a url cache in an RDBMS. Each entry will be indexed
	according to the url and will have:
	0. url name.
	1. content.
	2. date on which it was retrieved.
A cache object above it will give be able to provide this service:
	$cache->get_cache($url);
	This method will:
		1. check if the url is in cache and if
			so return it.
		2. if the url is not in cache it will fetch it,
			put it in the database and return it.
build a database defintion for this (a single table def).
build an object to mask the table with the required method.
use this object for url retrieval only and not LWP directly.
Think about posts (we may want to cache those too by somehow
	stringing the arguments).
make my movie module use it.

Regarding the Meta::Lang::Xql::Cache and other various caches.
	Cant we sync the cache to disk or DB and have the cache
	accross runs ? Think about it. Use Cache::FileCache to do that.

film:
	run over database and get imdb ids from imdb.

tell the XQL people about my cache and advise them to do the same.

Integration - this is getting neccessary to not waste time in the future
========================================================================
why does build fail and try to GENERATE the temp files ?
get everything to build and run well and then integrate.
When the intergration succeeds upload Meta-0.07 to CPAN.

Try to install Alzabo again and write installation instructions.

Idea - make my own dbi be able to carry it's "def" with it.
	This will stop me moving it to everywhere.

In the biology paper about sex mention why the female has
more problems with orgasms.

use C::Scan to find C dependencies.

This is the URL for the Meta comments:
	http://use.perl.org/~autarch/journal/3490
	quote this at my homepage.
	make a cache of this page.

thoughts about completion:
	develop a module which has the SQL syntax in it (Parser::RecDescent)
	and which can offer correct completions for each prefix.
	For instance:
		SELECT [all fields in the database]
		SELECT foo [FROM|, and other options]
		SELECT foo FROM [tables which have field foo in them]
	etc...
	this seems pretty tough.

db_console work:
	make the db console show the results.
	(check the statement and if it is a select then issue a select method
	and print the results in some kind of table).

do a pdmt shell with at least a couple of commands.
	Do a generic shell wrapper with completions (didn't I start something
	like that a while ago ?).

Pdmt:
=====
	do another node - trasforming tt2 files.

administration:
	find out how to run programs at login (graphical ones that is) and
		run gaim on every login...

get pdmt to do deps calculations. That's tough.

Idea: make a DTD for an FAQ. (Frequenty asked questions).
	(also a database description for such).
	The questions will be categorized.

Definition:
	A partition set is a set where you can:
		1. add elements.
		2. remove elements.
		3. iterate over all elements.
		3. define a new partition on the set with a name.
	API:
		my($pset)=Meta::Ds::Pset->new();
		$pset->add_partition("methodname1");
		$pset->add_partition("methodname2");
		$pset->add($object1);
		$pset->add($object2);
		$pset->add($object3);
		$pset->add($object4);

		Now you can quickly:
		my($array1)=$pset->get_subset("methodname1");
		my($array2)=$pset->get_subset("methodname2");
	This type of set is essential for the nodes of a pdmt graph.

finish the business with my shell script and then bring back
the lines in ~/.bash_profile which run bashrc and check that
I can log in via console and X.

The serialization of the graph object is really hurting me. Take it out.
	Try to die in a method somewhere in PDMT and see what happens.

get kde 3.03 installed on my machine and install the new perl qt with
it (it supposed to be real cool). Do some of my applications in it.

send a feature request to the guys writing kterm to document how one
can change the name of the terminal session he is in from the command line.
(there is no mention of this in the current kterm documentation).

do a script like the perldiver script (script about system information).
	(its not hard). Borrow ideas from them. It's in my cgi directory.
do a script which loads all perl modules that you have into a database
	(which could be browsed from afar).

build a jabber client that has all the info it needs in a database.
	(and logs all into a database).

find a replacement for ymessanger which leaves junk in my home
directory.

organization:
	move Meta::Ds::String to some other directory.
	remove Meta::Ds::Enumerated to some other directory.

outstanding in this change:
	remove Meta::Ds::Enum and start using Meta::Info::Enum.
	(it has the same interface).

	problem with Xml/Xml.pm which cannot determine if aegis is up
	or not. move the aegis_available to some other module (not Aegis.pm).
	In preparation to fix this problem try to remove as many uses
	of Aegis::which as possible and use modules instead.

weblog:
	put some categories into my weblog database via the dbdata file.
	put selection of user and categries into weblog ui.

mailing list stuff:
	israleli perl mongers mailing list:
		http://israel.pm.org/
		address: israel-pm-list@hfb.pm.org
		owner: gaal@forum2.org
		bot: majordomo@hfb.pm.org
	sbuscribe to this group.

today:
======
	put up the table for the computer.

mp3 stuff:
==========
write a small script to move my passwords information to the coolmp3
database.
stock the coolmp3 system with mp3 files.
put it on line and check it.

make a new Meta::Info::Set and a dtd for it.
make the new Meta::Info::Enum be able to construct itself from XML.
make the new Meta::Info::Enum type be used in combination with Opts.
remove the old Meta::Ds::Enum type.

markings in databases:
	mark the song "ho eli eli rak tfila lecha shehashemes taavor alay"
	mark Yoav Kutners series "Sof Onat Hatapuzim - Sipuro Shel Harock HaIsraeli".
	"gan hashikmin".

make Meta::Info::Enum and Meta::Info::Set objects and use them in opts
instead of the current Meta::Ds::Enum and Meta::Ds::Oset which should
be stripped of comments, description etc...
make parsers for these.

add check that perl scripts that go into a perl package don't have the
same base names.

move my "you have new mail" script to perl and put it in the project.

do some project with SPOPS and see how it is.

write a perl script for new mail and use that from kmail instead of a script at my home page. 

idea:
	have default values when doing -jave=>"_attribute".
	These defaults will be read from an XML configuration file.

fix the author dtd (it needs lots of work).

clean out old backups and make sure I have a backup on each HD.
(backup work and mail on SF too).

do a script which shows which mailing lists I'm subscribed to.
(show this on my website).

today:
	0. add filters for seding on all my mailing lists in kmail.
		(filters on lists only work on incoming).
	1. finish the author bits.
	2. build desk.

data size is getting critical - make a backups of projects p and v.

idea:
	add type of machine that I'm using (various statistics) to template
	toolkit and thus have the ability to put them into signatures like
	this:
		Penguin : Linux version 2.4.18 on an i686 machine (797.90
		BogoMips).

idea:
	The find dup script in md5 can make a list of all duplicates and only
	then run the interactive part. This will enable behaviour of just
	emitting the list and will also provide with less screen time for
	the user that has to sit while md5_finddup does the processing.
idea:
	make a sorter script which helps put files in places according to
	directory names. The match will be fuzzy.

add my own file handle object (call it multi) which has a constructor
	which has two inputs: type and path.
	types:
		bz2
		gzip
		db
		aegis
		etc...
	Then add an opts object which can open such an existing file.
	add a demo gzip and bzip2 files to the baslines
		(bzxx/demo.bz2, gzxx/demo.gz). Those could be used
		as the tests.

fortune:
========
download many more fortune modules off the web and integrate them into
	my own database.
make an interface which allows adding fortunes via the web
	(with review by administrator).

add, for each mailing list, a set of tags by which to identify it
	(X-Mailing-List etc...).
	Should it be more than one tag ?
	This should enable to generate all good filters automatically.

Meta::Class::DBI:
	stop doing it so the attributes will show up as "_[att]" in
	Data::Dumper.

Perl Packages:
	add dependency on perl 5.6.1 (so that earlier and later versions
	could not be used).

author changes:
	change Author.pm to reflect changes in current stuff.
	make an Affiliations object.
	change the parser to match.
	add webpages object.
	add emails object.
	add security_key object.
	parse all of them and show all of them.

slowly unite author and contacts so that my information can go fully into
	the contacts XML file. At that point remove author.xml and authors.xml
	and the author DTD which should be like the contacts DTD.

md5 issues:
===========
	make md5_produce and md5_remove use same code.
	add md5 which does duplicate elimination on its own.

mail issues:
	-automate filter (and their corresponding directory) generation (with telling
	you if there are filters that you dont know about).
	-import stuff from evolution!!!
	-export stuff from evolution!!!

idea: file repository according to categories.
	in it there will be my patches also.
	build a definition for such a database (with categorization).
	make dbdata to include my current patches (with actual patches going
	into the database).
	make a cgi script to show them (and be able to download them).

brink back XML validation and really check that it works.

mark listening to the van morrison album (Fri Sep 13 17:44:43 IDT 2002)

idea: enhance from dbman to inherit from categories.
	This way dbman will be a sort of scroll keeper and you could put
	various other HTML and other info into it.

contacts:
	add XSL conversion of contacts into HTML and pulish it in my private
	section of the site.
	add XSL conversion of contacts to Vcards.
	convert to kab.
	convert to evolution.
	import into database.
	write cgi script to browse contacts.
	make a first draft of export into cell phone.

my contacts and mail managing:
	finish massaging the contacts.xml file (until it is all worked out!!!).
	merge my old emails from qlusters into my current one.
	backup all my emails.

hobbies:
	add sports as a hobby to my web page with database tracking activity
	and accomplishments.

Lyrics:
=======
make a lyrics dtd for poetry and songs.
start inserting some lyrics.
make a conversions (xslt) from that to HTML.
publish them on my web site.

chess:
	draw all the rest of the chess pieces (at standard 100x100 size).
	draw a board.
	make a test which creates an SVG file of a chess position in
	a game.

idea:
	make opts be able to read config options from a database too.
	make opts to be able to do regexps to specify groups:
		for instance:
			xml_lint.pl --type=[all]
		means that the subset of checks to be made are all the checks.
			xml_lint.pl --type=[all]\[xmllint,xmlparser]
		means all but without the xmllint and xmlparser checks.
			etc...

Meta packaging:
===============
	tests are coming in as scripts. get ridd of those.
	get ridd of the warnings in the installation of Meta.

idea: import fortune items into an RDBMS and show them whenever you want
	(add them to the mail signatures you create dynamically).
	The database will be categorized ofcourse.
	example:
	-Do you Veltzer ?!? Stock prices and other stuff unavailable due to non
	existant design at www.veltzer.org!!! Visit us today and be ashamed...
		(Mark Veltzer)
	-What the fuck did God ever do for me ? Fuck!!! He doesn't even take
	out the garbage!!! Al mighty my sorry behind!!!
		(Mark Veltzer)
	-Gartner Group ? Never heard of them. What did they ever do in
		computing except manage to put on their tie without
		accidentaly killing themselves ?
	existing fortune files could be found in /usr/share/games/fortune/
	and they are very easy to parse.
idea: cgi script which prints various information about the machine on
	which it is running (CPU, speed, disks, services, OS, packages
	etc...).

document how to use ssh without passwords
	(ssh-keygen and then copy to remote home/.ssh/authorized_keys).

now:
	backup important directories from /local/tools too.
	send kernel patch to LKML.

tommorrow:
	sync ALL of my personal databases into the baseline.
	build the desk and sort out the working room.
	tell mom to move money to my account.

use the Pipeline infrastructure to do Opts::Opts.

make the Meta::Ds::Enum object be able to read itself from XML (test that in
TEST).
make the Meta::Ds::Enum object work includes TEST testing (internal testing).
make the opts::opts work again after last changes.

add def_tnew type to Opts. (new file with template processing).
move the tests to the pm module.
check it in the tests.

wide changes:
	stop using my text iterator and use IO-File instead.
	derive Meta::IO::File which throws exception if it cannot open the
	file and use that instead of IO::File.

idea: think about working with Ima::Dbi and simplify my dbi interaction.

1. Dtd2Html - how to suppress the "Generated by Dtd2Html" message at the bottom.
2. move my documentation bookmarks from conqueror to galeon (use just one web browser -
	that is important).
3. start moving to a one directory development.
	in that development every tag of every file could have a string attached
	to it saying what you did with the file.

idea:
	translate papers through festival into voice format for disabled people
	and put it on my website.

try to fix the validwriter test by calling Xml::Xml::setuppath (it may
	fix it's parser). If not then write an email to the maintainer
	and tell him about the problem.

submit feature request to gqview for not storing two thumbs for two files
	which are the same symlink name. The way to do this is to call for
	the cannonic path of a file and store the thumb under that.

add capability for hole finding script to fill the gaps.
	do good regexp subs there.

write to the author of XML::Doctype (XML::ValidWriter) and tell him that
	there is no way to override external entity resolution with his
	modules.

make the movie parser use Class::DBI and not insert statements.

put a bunzip.exe and gunzip.exe in my baseline and publish them on my
website so that windows users could open my stuff.

do the database definition and basic document about the teachers.

find out what's going on with my passport (it's been in the home office for
decades).

add def_dbnm() option to Opts::Opts and start using it in my weblog interface.

fix my resume section under source management tools.

weblog stuff:
=============
	add categories to which weblog items belong too (categories
	can be in a tree).
	put dbdata info about categories in the dbdata file.
	have the curses ui enable you to choose the category to which
	the item you are inserting belongs too.
	also have a ui to add a new category.
	show categories in the cgi script too.

problem:
	Do I start putting weblog items into the DB now ?!?
	The db gets recreated with every integration or even random
	builds !!! potential for heavy loss of data here.
	something needs to be done to avoid this loss (and holding two data
	sources and synching them is not an option).

Another problem:
	apache makes uses of the databases as well as my development
	environment. This must change since I do various bad things when
	developing and only when stuff is ready it is moved to the apache.
	The idea is to have a module which distorts db names in a consistant
	manner. The copy_website script will recreate the databases in this
	distorted manner (runtime_weblog) and will populate them with data.
	When in the development environment all the tools will not distort
	the name and therefore will run with the regular databases.
	This is pretty easy to do. Just create a small method in Meta::Db::Ops
	or something which converts development to runtime db names and
	vice versa. Have all the programs which work with databases use
	that class via Opts::Opts::def_dbnm() (they won't know about it
	at all).

finish the extra importing stuff in Dbdata and get to clean import of the
	weblog stuff.
security problem:
	xmlx/connections/connections should not be accessible to the outside
	world.
	How do I prevent this ?
	First I need to specify this info in my website.xml file.
	Second the script must do something with it.
	What ?!?
page last modified in html files produced date is wrong because it puts the date
	put is the one of the last checkout and not last modification. change
	this. Maybe this type of change will cause aegis check and integration
	problems ? Don't think so since html is target (unlike perl source
	which holds it's own dates).

produce guide lines for writing field and table names in SQL databases:
	1. table names are always in singular (never "events" but rather
		"event".
	2. if a table name or field name need to have more than one word
		in them then it should be catenated by "_".
		For instance "birth_date". This is so that spell checkers
		could check those too.
	3. the special word "id" is reserved for unique ids for tables. don't
		use it for any other purpose.
	4. whenever a pointer is pointing to a table "foo" that pointer name
		will be "foo_id".
	5. If there are more than 1 pointer in the same table pointing at
		table foo that then will be called "prefix1_foo_id",
		"prefix2_foo_id" and so on.
	6. same rules apply for enumeration,set names and database names.

weblog:
	make the table generated look nicer (get CGI class).
	make an executable to put a new weblog event in.
	make a title for the generated page (cgi script).
	make a nicer title for the generated table.
	make ability to search the weblog database through the TEXT SEARCH of
	MySQL.

author information:
===================
	add unix accounts for each author with passwords.
	add ability to change these passwords and verify them.

automatic signature generation:
===============================
	finish IM parts of sig generation. Generate it.
	add more xsl files from more signature stuff (for instance - sgml type
	thing).
	make a signature for friends (with different style sheet).
	intgerate the current change and have kmail run the sig generation as
		a program.
	
bookmarks project
=================
	project aims at storing bookmarks in XML or RDBMS.
	publish bookmarks on the web.
	bookmarks organized according to flexible categories.
	bookmarks can be exported to netscape,konqueror,mozilla,galeon and
	more.
	bookmarks can be imported from all of those sources.

check postgress and mysql connectivity as mark.
remove traces of devel from the aegis database.

move the alon olearchic album to my mp3 section.

write the song by neomi shemer.
write the song by david broza.

dbdefs:
	test the new defs object (using it's own internal method).
	add the prefix thing to the defs project and check that it works.
		(otherwise a big project like the mail project cannot inherit
		from both people and categories).

basline organization:
=====================
	move the rest of the stuff from perl/bin/Meta/Baseline.
	bring back XML checking (a must). Maybe using SAX and my external URL
		handler ?

kernel stuff:
=============
	register to the kernel mailing list for digest.
	add the vger address to my own address file from kmail.
	send my first kernel patch to alan.

system administration:
======================
	run bind on my machine and make ftp.veltzer.org point to my machine too.

pmail:
	start working on the filters (generating automatic filters for kmail).
	do the mail box configurations for kmail automatically too.
	put my old qlusters emails in there too.
	make a script to backup all the text in my emails (not including attachments).

do demos for a better way of communication (object sharing).

start doing PDMT again (find a way to run remote procedures cleanly).

make the meta package be able to install itself again.

DTD and XML:
============
	commented out:
		dtd checking (fix it).
		xml checking does not work now.
	start using attributes in DTDs.

Back to PDMT work: try to run servers and clients again seamlessly.

author.xml issues outstanding:
==============================
write my own authors parser (use a lower level author parser).
find and abolish all "xmlx/author/author.xml" occurances.
create an author DTD with just the author info.
share the author DTD between authors and perlpkgs.
shere an author parser between authors parser and perlpkgs parser.
remove the old example for author and turn it into an example for authors.
remove the old parser for author and uneeded methods from Author.pm.
make the multi author object provide access according to unix name.

trademarks:
===========
	actually get the trademarks system to work.

dtd documentation:
==================
global documentation is not in a global place. Fix that (even mess with
	the parser if need be).
TODO items are not in a global place. fix that (even mess with the parser
	if need be).
add option to the current parser to check strictness (that every element
	is documented).
take care of the title (it appears empty).

improve all my documents and redistribute web site.

idea: make my own aegis clone which runs as server.

Caching tool:
=============
all caches will be stored in the database.
The database will also have numbers for invalidation so you could bump a tools
	number and get invalidation of it's cache.

CPAN package making:
====================
why doesnt my package have a description in CPAN ? whats missing ?

Vi integration:
teach vi to open template toolkit 2 files (.temp files in my project)
according to their content.

CGI/Tables presentation and HTML presentation:
In tables each line alternates in color so that it will be easier to read
make it so in both the HTML content and the CGI scripts.
Before doing that add is_even is_odd methods to the Math package.

idea:
=====
	To make the readme file in the Meta distribution look better
	pass it through one of the perl text formatters.

dbman:
======
	run import process for dbman again (for /usr too) and see that NO WARNINGS at all are
	emitted.
	get to a point where the dbman page viewer work again.
	get to a point where the free search works.

install gabber and start using it.

work related:
=============
	call Raz El and tell them.
	call the company I used to work for.
	call schema

Mimes:
make a Class::DBI object for mime types.
make an import stuff for mime types out of the Mime::Types just like
the code in Mime::Types.
import everything and then export it back to a dbdata file.
send an email to the Mime::Types maintainer about access to the full list
of mime types and better documentation.
write a general document about the project.

elems:
	use the mime types project (inherit).
	add mime type field to each content.
make new OF server serve CSS too.

get to a situation with a web log running.

perl code quality
=================
add "use warnings" to every module and script.
document it's use

make a class with all available Mime types (maybe theres already
	something like that).

run a vi tutorial and learn some more tricks.

manage to install transcode. (do some bug reporting or something).

generalize the OpenFrame Slot I made to handle a hash of allowed
	types.
add some images to my web site and make sure OF serves them.
	(add them to aegis under jpg or something and connect them to some
	html).

groff stuff:
============
write a proto of a regression suite for the groff people and send it.
problem 1:
	curr is [/local/tools/man/man1/javadoc.1]
	/tmp/fileyCMoYG:749: suppression limit registers span more than one page;
	image description 1 will be wrong
	--many more like this.
problem 2:
	curr is [/local/tools/man/man1/xmlep.1]
	Use of uninitialized value in length at /local/tools/lib/perl5/site_perl/5.6.1/i686-linux/Compress/Zlib.pm line 301.
	Use of uninitialized value in length at /local/tools/lib/perl5/site_perl/5.6.1/i686-linux/Compress/Zlib.pm line 301.
problem 3:
	curr is [/local/tools/man/man1/mysqldump.1]
	/tmp/filehuSLk4:67: a special character is not allowed in a name
	/tmp/file6dj8eb:67: a special character is not allowed in a name
	/tmp/filekK281h:67: a special character is not allowed in a name
	/tmp/fileO8jTLE:67: a special character is not allowed in a name
	/tmp/fileO8jTLE:67: a special character is not allowed in a name

make my own OpenFrame slot which can handle many types of files (for which
	I will tell which types should be served).
At this stage open frame should serve images and CSS.

Utils:
	improve File::load from Meta::Utils::File::File with FileHandles.

make the openframe server serve CGI documents too.

develop a service in Meta::Utils::System that can run a perl string.
	(maybe theres something like this in CPAN ?)
use that service to run CGI stuff in elems.

develop an elems server using open frame.
try to generate a web server that shows you the aegis images.
	use open frame.

idea:
	develop a class that does most of the funcionality of an
	/etc/rc.d/init.d script and just needs to be wrapped.
	use that to produce my own rc.d scripts for my own daemons
	(in the elems,dbman and other projects).

add the ability to run cgi scripts in the elems project.
check that my weblog cgi uses right cascade stuff.
put weblog_cgi on my site.

elems:
put my whole site in the elems project.
use Class::DBI for the elems project.
	(for page extraction too).
do logging of people visiting the website in the elems project.
	(use Class::DBI).
make the elems project inherit from the people project too.

build system problems:
======================
	when modifying a database definition of a database which has dbdata
	xml files that need to go into it the dbdata doesnt go into it after
	the db is generated which results in an empty database.

dbman:
	0. grohtml (groff html backend) produces images too (as part of the
	htmls it produces) and these are left as junk in the conversion
	folder.
	1. check the data that goes into the database (use my own shell).
	2. make all warnings and errors from the html conversion tool go away in regular import.
	3. try to import dbman stuff and see if I can see it all on my database browser.

cgiframework:
make a class derived from either Licols Steins CGI or from the other
CGI::Pretty which have the same methods but I want to be able to select if I'm
using a pretty or non pretty output. (I'll use pretty for debugging and non
pretty for sending out html).

md5:
	make a sync binary which syncs md5 files with a folder.
System:
	find a way to spell check my outgoing mail.

problems outstanding with the Set interface in Opts:
====================================================
	1. does not check that elems are indeed from the set.
	2. does not accept the default value.
	make a URL HANDLE: which is a handle you read from (as opposed
		to just fetching the URL as a string).
		at first stage this could be implemted as IO::String
		over a fetched URL if no implementation exists.
	veryfiy that URL does indeed have a url type format (urls).

My dbi console:
===============
try to make mysql not print very long text or binary fields.
	(better yet - implement it in my shell).
	make a text table which prints tables nice.

elems:
make the content which is text base a MySQL FullTextSearch so that you
	could have a facility to search the website.
make a new table for who visited the page (ip, full DNS name, time
	(automatic), what page, browser type).
maybe a table for browser types ?
do my own class to inherit from HTTP::Daemon and have just one method
	to override to do the actual serving work.

make a script which will check all of my login accounts.
	(from xmlx/passwords/passwords.xml).
In order to do that make a library which knows how to validate user
	with a password on the local machine.
	check for that on CPAN.

make my own object which can analyze an SQL statement and produce a table
(with the table devided to parts and the headers containing the synopsis of
their content). Cgi::Table

find a perl CGI framework.

start using Log::Agent for my logging needs.

today:
======
1. design some logos for my site and put them up.
2. organize php script to show my contacts from either
	xml or db and put it on my website as private.

checkout what plugins there are for phpwebsite and get some good
	themes.

security stuff:
===============
how come pgsql accespts junk passwords for user devel ?
	make it not so.
change my yahoo password from mil'lon to mil|lon.
	(both in the main and in the wallet sections).
move over as many sites as possible and change my password.

write down these following locations to change when changing passwords:
	1. baseline
		xmlx/passwords/passwords.xml
		xmlx/connections/connections.xml
		xmlx/configs/test.xml
	2. web server (apache) using htpasswd
	3. all types of web content php systems.
	4. database servers (mysql, postgres).
		.my.cnf
		.pgaccessrc
	5. web sites (important).
	6. add the new password as a bad word (xmlx/words/badwords.xml).

add my old passwords as censorship to my web site.
add words from my web site censorhip to my own xmlx/words/badwords.xml.

document the installation of my new mp3 database (php mp3cool).
document the installation of my new guestbook (php gbook).
document the installation of my new db browser (php eskuel).
document the installation of my new counter (php phphits).
document the installation of my new postachi (php main).
document the installation of my new phpwebsite (php portal).
document ths installation of my new contact list plugin.

web site:
connect all my current content into it.
download some plugins for it.
download a blogger install and document it's installation.
connet all my systems to my web page.
add writing (literature) as a hobby.
add D&D as a hobby and add scans of maps etc...

make festival be a permanant server and document how to do it.

configurable file names in Opts::Opts:
in addition to:
	aegis:
you can have:
	gz:aegis:
which means to have the file name pass thrugh aegis and the pipe to go through
	gz.
the same with bzip etc...
The same can be done with tar or zip to select one file out a full archive.
the same coule be: database=pics,table=images,column=jpg,select=id,56
	which would select a binary out of a database and will stream it.

install a few festival scripts and do perl scripts which run festival
	instead of my current festival scripts.

write a patch to aegis which shows the version of aegis.cgi which is used.

bring back the coloring script.
	both the colorc file and the script that ran it).
finish develop_rc.pl script and use it
make it shorter (move code that is not in Meta into meta).
work with shell completions now that I use develop_rc.pl.

features of a db browser with Meta info cgi:
1. real xml file with Meta info.
2. be multi lingual.
3. be able to specify which databases one can browse ("playaround_*" will
	mean that every db name which start with playaround_* could be
	browsed).
4. be able to specify per db users and theyre responsibilities.
5. be CSS compliant (no "how does it look" code in the HTML but rather CSS
tags with a default style sheet which looks well).
6. be able to embed the db browsing result into something larger (larger HTML
or bigger CGI).
7. be able to specify which drivers one could browser (mysql, PG, oracle,
	Informix etc...).

document how to install the mysqlwdb database web browser.
	(just configure it at the begining and put the script in a cgi
	directory).
install and document the php blogger.

dbdef:
-Add a field type "password" which will not store the value passed to it but
rather some encrypted from of it.
-make a def store more than 1 database. (call it defs).

why do I have bad version numbers in perl -MCPAN regarding apache modules ?

install AxKit (how do I install it with apache 2.0 ?).

bring back the rewrite engine with my code and script with everything
	in /local.

write down:
	music (halleluga, sting song)

make my deveop initialization script produce a shell script which sets
	the variables.

download, install and document bash completions.

an idea from the net:
	make a script to generate random passwords for you.

find out whats the interface of Compress::Bzip2.
write my own wrapper to Compress::Bzip2 in Meta::Archive::Tar.
make the backup script do a Bzip2 archive.

install a new version of the libgd library (with xpm support)
	and reinstall the Perl GD module.

pics:
record all my bad images md5 sums.
fix all my bad images (use convert(1). Make a perl tool Convert.).
make the remove_small be able to output a list of files and run it
on my collection.

make a demo of String::Approx.
use String::Approx to support close options.
	(--outfil should suggest --outfile).

This about the subject of presets.
	A preset is a set of values to a set of parameters.
	If I could defined presets for Opts::Opts then a user could
	just select a preset (or add presets of his own in his
	configuration script).

make my backup script make a bz2 archive by default.

xmlx/sgml/xmlx/def/movie.xml isnt right. fix it's generation.

Thumbnail:
	make a script which also creates the thumbnails (as png files to use with gqview).

make an event driven directory iterator with the following events:
	1. on_file - current file,full directory,relative directory.
	2. on_directory_start - current directory,full directory,relative
	directory.
	3. on_directory_end - same as on_directory_start.

make a script in my pics directory which creates a report about my current
	collection in XML format.
send that report as a business prop for the s4f site.

meta distribution:
	try to install and fixup the installation process.

make a gif2jpg executable in a new graphics project.

wrap a nice module which knows how to put tags and remove tags from
	jpg files.

hebrew:
find out how to make kterm write hebrew.
check for a short cut to switch from entering hebrew to english and
	vice versa (CTRL+SHIFT doesnt work).

tag all my jpg files regarding the person in them.
	don't do that until you recorded the md5 sums somewhere.

do a tool for ghostscript (which runs ghostscript and makes various
	conversions).

movies projects
===============
-finish with the movies and authorise a lot of them.
-get data for movies from IMDB (verify movies).
-get directors (I can't get directors still).
-there is a 1 difference in movie counts between stats and count
	of the database. fix that.
-make all views in movies be the same (use xsl transformations).
	actually - even better - import movies into a database and then
	export it out.
-get IMDB ids for all my movies and create links for them from within the
	tables.

move all stuff in perl/bin/Meta/Ui to Demos.
straighten up perl/bin/Meta (organize binaries logically).

next change: move all tests into the modules.

idea:
	development modules will also have a cached copy of the TEXT
	of the source file and so will not have to re-read it from disk.

do dependency calculations for temp files (for functions like devfile,
	devlist_* etc...).

use psgml package for emacs in order to edit XML files with DTD auto
completion and other features.

get ridd of my config option reader (Meta::Utils::Options) (use some stock object for this
	with a maximum of my extension). Make them all XML.
	also stop writing options using "print" but rather have an object that
	can write options for you so that they always speak the same language.

take care of the apache security...

find a way for xchat to automatically identify to the server every time I run
it.
find a way for gnuchess to automatically identify to the server every time I
run it.

get to a situation where all the 20Gig for pics is named.

contacts:
	do a utility to sync two contact lists.
	get the contacts info from my palm pilot too.
	get the contacts file in order (more contacts to be moved from
	remark to xml).
	unite this with my evolution thingy.

do a patch object:
	initialized from a patch file.
	method to apply the patch.
	method to report files which are part of the patch.

fix all my papers to look nice and work on them.

contacts:
	automatically generate filters for kmail ?!?...:)
	make an entity application to manage my contacts.

make an icon for my site (use the gimp).
find out how to make the icon appear in browsers and make it so.

add a directory to my development tree with patches and add my pvfs patches there.
connect the pvfs patches to my site.
make a patch for the linux kernel to make scripts modularized and put it on my site.
make a patch browser (cgi script).
make my Meta package avilable from my site.
post a new meta package on CPAN (0.04).
bring back all my articles and work on them (big change).

add checking that certain patterns do not exists in temp files (like "\ \ ").
	(do a class which eases such things).

web server stuff:
=================
	make the rewrite engine work on the new apache.
	connect the apache to my own security database.

make my own wrapping script which is adjusted to SGML.
use that script to fix all my temp files.
make a script which checks files.

make the devel user mark.

make my own contacts reader.
make my own contacts reader be able to pour out a kmail contacts list.
make my own contacts reader be able to pour out evolution contact lists.
put all my personal information contacts (stored in /local) in my xml file.

idea for a periodical script which runs and:
1. clears eboard games and moves them to the current change.
2. syncs kmail, evolution and my XML contact lists.
3. regenerates my .signature file.
4. backups my stuff to remote sites with pgp.
5. and place holder for more stuff.

make my website copy script be able to erase all remains of the old website.
make my website script be able to create the symlink for the index.html master
file.
make a script which reads the kmail contacts list.
make a script which syncs two contact lists.
	(or just informs you that one has info which the other doesnt).

do a rebuilding of the Opts architecture:
	Make object for each type of parameter which gives you all the info
	you want out of it:
		1. what letter does it stand for in the GNU long opt standard.
		2. conversion between string and value.
		3. conversion between value and string.
		4. validation of input.
		5. etc... 

use real SGML DTD fragments.

make automatic generation of pgp signatures from XML data.
make a script that generates my signature and use it in my email client.

try to close the change.

make pdmt work with aegis (a node which inherits from a regular node
	and the get_path routine works differently).

ENOUGH is ENOUGH
PDMT now.
Switch to PDMT in THIS CHANGE. Drop fucken cook out the window.
I have got to do it NOW.
No need for server now but a one time run will be good enough.
	(and because it's all perl I think it will be faster anyway).

move all perl executalbes to Meta/Lang/Perl/perl_*.
same for Lily,java,html, fhist,cpp,xml

Big change:
===========
move all module tests to the TEST methods.

Big change:
===========
stop using double quotes for strings and start using single quotes.
single quotes do not cause interpolation and so should be faster.
document this in my perl documentation.

make the pl template have more parameters which could potentially be filled
	interactivly by a user.
	(make an executable that gets the right parameters, writes the file
	and then calls aegis aenf).

Make a big change with the following objective:
	stop using Meta::Baseline::Aegis::which in every place with _deve
	_file methods in every place. Instead, every method that needs a file
	should get a Meta::File or something. (which will have a method like
	->get_path()) for other methods to open. This way every place I work
	with files could work with aegis files also (and also with with the
	Web ? Ftp ? think about it).

how come I cant put a link to my meta package in my computing section ?
	some weird cook problem.
make the see also section of each module and script right.
	(according to use sections).
make an HTML tables for downloading all the packages that I make.

make the code at perl package creation not add files several times to the
archive (although the archive protects iteself against that).

Perlpkgs:
	stop adding files under different name to the package.
	add options to add files with explicit content in them right at the
	package definition location.

make generated Makefile.PL have correct PM and EXE_FILES parameters.

to close the change:
====================
make a test for the new Tt module (inlined).
test the tt module inline with a generic testing script.
make deps calculations from the tt modules.

to publish the web site:
========================
make the cook calculation return a graph of modules.
finish the script which moves my site around.

upgrade my postgres and mysql servers.
add a few linux icons to my site.
upgrade my apache.
make apache allow me to browse my cgi directory (see what scripts are there).
my XML parsing is wrong (char handlers should accumulate data).
	make it so or use another parser.
make apache do it's logs to a db and analyze from there.
rewrite my testing infrastructure (test info object which gets passed
	to tests and remove the redirect stuff from all tests).
	move all tests to modules (which can).

make dependencies for template files.
	(at least a couple of macros).
integrate this change (too many files).
make apache authentication use my own script (or dbm file).

make an option to download PDMT from my site.
	(what's the problem with creating the package ? order of cook
	files ?!? debug the cook!!!).

make the apache rewrite script use change numbers (and baseline) views.
web site control:
	stop all those weird directory listings in the script controlled area.
	allow directory listings in my private area.
	enable to see the apache status screen in my private area.
	make my private area be unified.
	allow to see all my documentation from my web site.

bring back sgml manipulation (generation of content).
make a script for moving site to the apache web service area.

write how to enable ident on the machine:
	enable ident in iptables. In bastille it's called ident.
	make sure after bastille that iptables accepts ident
	by running "/etc/rc.d/init.d/iptables status" and seeing
	that this port is open (dpt:auth).
	enable ident to startup by default (chkconfig ident on).
	start ident up.
	no special configuration for the ident daemon is neccessary.

create a database structure and a CGI object for seeing FAQs.
create a CGI script which shows patch files (which files are in them
	and what changes do they make with coloring).
idea:
	hold urls where images come from and so you could check if you already
	visited that url.

finish arranging papers according to hobbies.
add hobby for languages.
add a patches section to my computing section.
website:
	make the border appear again (I have no border for tables now).
integrate everything that's in my ~/save directory (for user devel).
make validation for my css (checkout http://jigsaw.w3.org/css-validator/).
integrate (for god sake).

system:
	how can I force email to come over after a crash ?

make the new upload to cpan module work.
	(make it a method of the perl package).
upload my new module via that new upload module.

ideas:
	enhance lilypond parser to contain several sources and several
		entered by entries per music file.
	syntax file for lilypond and vim.
	teach vim about my temp files and about tt2 syntax.

integrate open_source_development from qlusters.
try to boot up my machine and see if postgress comes up automatically
	(I had problems with it).

make a script which creates apache users from my web site users file.
put my apache users inside a db.
make a script which shows my apache db users from the db.

add dictionaries to every XML file that I have.
	this is so that dictionaries live close to the technical articles
	that give them life and not in some faraway file.

do a browser for books and other stuff too.
	add books which I'm reading now.
get a general db browser and hook it up to my movie db.
make the db(mysql) driven file system work.

today:
	1. write joe cocker in ly format.
	2. buy lamps for the house (many in the house and one in the hall).
	3. clean kitchen.
tommorrow:
	1. pay I bill.
	2. get the cd stand and put all my cds in it.

make a general mapping object (meaning multi map - like a two sided graph).

zone in the web site.
	stuff on my page:
		1. documentation (access to all of my docs subdir).
		2. access to my software repository.
		3. access to aegis software development.
		4. access to my web site statistics.
		5. access to my databases.
		6. access to mp3 database.
		7. access to my email.
make access to my email available via IMAP.

system:
=======
	upgrade to rh7.3.
	write installation instructions for the web site analyzer I installed.
	add running the web site analizer once every day.(cron).

make a link to my private page from my main page.

make a general multi-cast reporting software which reports a variety of things
	(with plugin arch about what it is reporting).
	What it reports should be controllable via tcp/ip.
	The reports should come out as either binary or XML.
make a general caching server which caches the reports from all the reporters
	serves information about the current status (only current for now)
	of the reporters.

mark in the installation instructions of a new machine to scan the crontab
and see what it doing.
in specific:
	1. turn off mrtg every 5 mins (we're not running a router are we ?!?)

document this as the script to connect to the net:
	ifconfig eth0 10.200.1.1 netmask 255.0.0.0 mtu 1452
	/local/tools/bin/pptp 10.0.0.138 user veltzer@IActcom remotename "10.0.0.138 RELAY_PPP1" defaultroute mtu 1452 mru 1452 noauth

document all the changes I did to harden my machine:
made sure "nmap machinename" and "netstat -lp" only showed:
	http
	ssh
	smtp

things that needed attension:
1. in /etc/my.cnf told mysqld not to listen to the networking
	[mysqld]
	datadir=/local/tools/mysqldata
	socket=/var/lib/mysql/mysql.sock
	skip-networking
2. in /etc/X11/xdm/Xservers told X not to listen to networking
	:0 local /usr/X11R6/bin/X -nolisten tcp
3. turned off netfs (nfs) so it wont use rpc.
4. turned off fam (SGI) so it wont use rpc.
5. made postgress not listen to the network (removed the -o -i
	in the postgress init script in /etc/rc.d).
6. made sshd not forward X11 communication by adding the relevant
	option in /etc/ssh/sshd_config

still left to do:
1. move http to https
2. bring back fam but only with socket and not tcp communication.
3. do firewall rules (ipchains or iptables ?).

ideas:
	use fuse to do an Md5 file system which writes to db.
	use fuse to do a database oriented file system.
	use fuse to do a file system with history.
	do a sample of using libgda to access data in several databases
		using the same interface (mysql and postgress for instance).
	install the new aegis cgi script in my cgi directories and protect it
	with a password.

Music
=====
-Write the counting crows song- Mr jones and me.
	Verse:
		Am F Dm7 G7 x 4
	Chorus:
		C F G G Am F Dm7 G7 x 2
-Write Mati Caspi "Bli Hava Ein Shalva"
-Write song:
	god, god, god is good
	god, god, god is great
	what if god was one of us ?
	just a slob like one of us ?
	Just a stranger on the bus trying to find his way home

	Chords:
		Am F C G (verse and chorus)
-Write the cat's open theme song:
	Eb Cm7 Ab Gm Fm Cm7 Bb7 Eb

mark the free-zope account in my passwords file.
start looking at free-zope.
give root (and other users) different passwords (to make the
	machine harder to crack).
move all of my todo items and done items to xml.
pass my xml files through bad words also.

install zope and start using it.
documented the installation of the firewall.

mark sdf-eu.org as a shell site account
	with user veltzer and pass kingcrim.
	with pretty correct details.
stop subscription to cumondagny.com
get a VCARD reading or do a module for it yourself.

add "use" attribute to connection object and dtd.
replace my web page and email address in many web sites.
	(only those that don't spam).
why does my page come out in japanese?
install a better ssh server so that sshd and /local/tools/bin/ssh could talk.
do integration
make the "backup mail server" idea from gilad:
	the actcom server will act as a backup to mine.

fix it so devel could use a password when accessing pgsql.
submit my new page to lots of search engines.
redirect my yahoo mail to mark@veltzer.org.
reopen some of the open mails I had.

pay my car parking bills to the Tel-Aviv city.
upgrade my cell phone to orange.
buy a cable for a nokia phone.

hardening:
1. move http to https
2. bring back fam but only with socket and not tcp communication.
3. do firewall rules (ipchains or iptables ?).
(document all of those)

modules to try out:
	Class-DBI-Join-0.03
	DBD-mysqlPP-0.03
	Encode-1.41
	File-List-0.3
	File-Rdiff-0.01
	File-Scan-0.22
	GraphViz-Data-Structure-0.06
	Imager-0.41
	Log-Dispatch-Config-1.00
	Log-Dispatch-DBI-0.02
	Mail-RFC822-Address-0.3
	mixin-0.02
	Net-Google-0.4.2
	Net-MySQL-0.03
	Net-YahooMessenger-0.010
	Parallel-MPI-0.03
	Parse-RecDescent-FAQ-2.31
	RPM-Tools-0.1
	Schedule-Depend-0.15
	Text-ASED-1.9
	Tie-Cache-LRU-0.21
	Tie-Cfg-0.11
	WWW-Search-Google-0.18

make sure that pptp comes up even after the machine is down.
	(and is restored if the connection goes away).
write a paper about command line args library which supports shell
completions.
stop using bezeq for isp.
get interesting modules from work.
stop internet services from bezek (explain to them why).
give my permenant ip to be DNS distributed.
write down the phone file in my home dir in xml format in the development
	directory.
evolutions keeps its data in a berkeley db. find out the format, document
	it and make a small script to convert back and forth from xml to
	this format. make the same with tasks.
find out why I cant open a vi as user devel when connecting to home
	from work via ssh
connect to actcom and write down my permenant ip.

patch to the kernel to put binfmt_misc with a config option.

I still can't send mail via sendmail - fix it and re-email the aegis bug.

make sure I can read emails from qlusters using pop3.

do a curses C level demo.
find a c++ helper lib for curses and do an install and demo of that.

make the movie xml stuff use person type names and views be according
	to person.

pics:
make a class which knows which of several photoes which have the same
image is of the highest quality (or get from the net).
	(this will be used to leave only a single image of several images
	which are the same image).
make the picture collection store several MD5 sums of the same image so
	that several slightly modified copies of the same image could
	be disregard and only one representative present.
checks on my pics directory:
	all series look like seriesXX_name
	no series is empty
	all names are [lowercase_]* with _ not at the start or end
	all names are in their appriopriate directory (no a name in the b
	directory).
	no weird file names (no spaces, dots or other weird characters).

make a directory iterator which considers a multi-directory structure.
	(like in Aegis).

make a "ccache" like feature in PDMT:
	this means that applying the same rule with the same input files
	will have the same result.

write the charlie parker song.

do a script which makes various statistics on my pictures collection.
do a script which puts my picture statistics in a database.

make the movie database inherit from the prefixes database.

install squid on my machine (to cache things).
idea:
	do an XML for records in computer games and fill my data in.
	download the music db at freedb and see how to put it into a mysql db.

ideas:
	1. store all my papers in a database (extract the titles using
		a special routine I will write).
	2. an XML file for storing chess positions which will be translated
		automatically to svg and be presented in a web site.

check that all galeon saved passwords are also in my passwords file.
update my cupid.co.il description a bit (photo ?!?)
get description of hebrew keyboard so I could type hebrew on my non
	hebrew keyboard.
do a quick computerised course in fast typing.

diary:
	database run diary.
	make an xml file of the database structure.

upgrade common c++, contribute rpm to it.
upgrade aegis.
get myself working on hebrew fonts in vi.

make a general sync between two fs's.
make the ftp operations inherit from general file system operations
	and create the same for a local file system.

system:
=======
increase my /usr directory.
upgrade more rpms from red-carpet.

do more elaborate demos of STL (maps, hashes, string, auto_ptr etc).
make a patch to gcc to issue warnings about bad -I and -L stuff.
make a getlong options of GNU demo.
make a demo of popt command line argument library.
make a demo of xerces c++ parsing library.
make a pthread demo.
make a perl embedding demo (run perl from C/C++).
make a python embedding demo (run python from C/C++).

what about base.pm ?
	I can't seem to be able to install it in the office. Where did I get
	that one 
	from ? (What package ?) and how come that the version that comes with
	perl is 
	1.01 and need 1.97 in Meta ?

do some more shows binaries (shows import).

add xsd (schema) directory to the baseline.

buy following books from orielly:
	linux drivers (next edition),
	advanced perl programming,
	svg/xml
	postgres
	eric raymond book
	richard stallman book
	some web book.
	perl/cgi book

make a script to install my web pages on my apache local site.

checkout new version of openjade.

use Module::Info to do stuff in Perl.pm and not the current parsing way.

improve the md5 importer until it is very clean.
move the chesum importer over to the thumbnail imported.
check the thumbnail importer with some larger directory of images.

news system on my site: install the standard news system on my site.
	(php nuke).

perl packaging:
	use the bad words and actually check that they don't appear in the
	packages.

checkout Net::PBM in order to do thumbnails and other graphic stuff (saw
	 it somewhere on the net said that GD is bad for thumbnails and it
	 does them bad).

check out http://www.maplefish.com/todd/aft-refman.html#4.
	add aft to the baseline with directory and rules.

do some scripts for my spics:
1. script to generate a CATALOG.
2. script to check that all names are well.
3. script to report on series directories which have only one image in them.
4. script to check that all directories are under the same naming convention
	(seriesXX).

get a new version of cwd from the web ?!?
re-enable docbook generation.

check out the fampp project at:
	http://sourceforge.net/projects/fampp/

checkout the following:
	-http://www.coker.com.au/bonnie++/ bonnie++ io benchmark test
	-global gtags for tagging and the new gtags project.

bring back docbook generation using openjade.

do a common c++ demo.
do a dmalloc and mpatrol demos (for malloc debuggin).
make the usual opts object be able to load from database too.
why doesnt xboard do normal sounds ?

change my email filters (they are bad).

autoconf generator projects:
============================
1. get a single function out a dll and create a CHECK_LIB segment for
autoconf.
2. get all the basic headers I'm using to create a CHECK_HEADER segment.
3. check rpms.
4. support make rpm, make deb.

make a XML/DEF for a configuation database with clases (C++,PERL,Python)
	that use it. Make it very extensible.
	don't do it using strings in the database - do it using real database
	types. And also store the descriptions in the database (so UI's could
	print them out).

do the PRIMARY KEY constraint as a constraint for MYSQL and POSTGRES.
add option for single key constraints:
	<field>
		<name>id</name>
		<description>...</description>
		.
		.
		.
		<constraints>
			<constraint>primary<constraint>
		</constraints>
use the gnu encription to show how you read and write encripted files.
make sure that I have a good reference for libstdc++.
	(download from the gcc web site if needed).
get the c++ FAQ into my docs archive.
get the c++ reference into my docs archive.
get the c++ oistream guide into my docs archive.

get a good UNIX networking programming manual into my docs.

Opts.pm change (again):
=======================
anal->analyze
stop using set_description (it can be extracted all over).
print the name of the script without the .pl (add it in Name module).

system:
	checkout constant DNS software.
	change my user name with bezeq.
	fix mysql and postgress databases.
	upgrade all filesystems to ext3.
	erase a lot of old software from my software archive.
	make a script that identifies two version of packages
		and removes them.

system:
-install balsa (I have problems with it).
-problems installing kdepim-pilot-2.2.2-1 because of shared libraries between
	gnome and kde.
-problem installing sane-frontends bacause of ximian giving out gimp libraries
	which are not the same version as the libs that red hat gives.

manage to pass all tests in current change.
make current change go away (with -minimum):

do a configuration database and have classes in C++ and perl to read
	them (and write them).
make a similar xml definition with the same classes which can read and write
	that too.
the C++ example of logging does not work.
make a real pq++ test.

download gcc-3.0.2 which seems to be stable.
upgrade everything to gcc-3.0.2.
do a postgress C++ sample.
constraints (uniqe at least) are not created - check it out.

use the postgress inheritance feature.

improve the progress reporting widget.

website:
========
publish images from yaron on my web site.

dbman:
-make a postgress version of it.
-make a package out of it.
-fix the oneliner import.
-do the full text search on the name, description and content_ascii fields.
-add a dbman_create.pl which will create the database.
	(or as an option in dbman_import).
-write another advantage to using dbman:
	you can have a well known dbman server running somewhere
	and whenever I don't have a man page that should be installed
	but for somereason is not - I just look at the manual from there.
	(this could be on a system which is installed for a client and
	does not have any development tools or manual pages installed).
	Actually - this is even good for a system where you dont use
	dbman at all (for the local machine) and just want a quick
	way to browse the stateoftheart dbman server at [redhat|gnome|kde
	|whatever].
-bench mark the full import process when using a socket for communicating
	with the db (what do I care to enable the mysql to listen to
	a socket too ? - it will just make my performance better and since
	I do personal db projects it's more accurate to estimate performance
	that way).
-make an executable dbman_install.pl which installs a set of manual pages
	into a specific section.
-enable or disable setting the unique constraint on <section,name>.
-enable or disable storing inodes in the db.

find out about the problem with installing XML::SAX::Expat
find out about the bold stuff in konq (why it sometimes shows and
	sometimes not...).

SEE ALSO in perl:
=================
0. The best way to put tags is the way it is in Meta::Geo::Pos2d.pm
1. make a routine which turns a list of package names to a string suitable
	for a SEE ALSO stuff.
2. alway put a link to perl(1) documentation.
3. put links to modules which the module uses (for author maintainers).
4. put links to papa modules (for maintainers and users).
5. put free links to other modules which exists and do related things (or
	the same thing with a different approach).

fix Meta::Utils::System::system_out to use a reference.
move lots of the tests to unit testing.

Database:
=========
1. problem with default values for boolean type fields:
	in Mysql boolean is ENUM('Y','N') and defaults
	need to be 'Y','N' while in Postgress boolean
	fields are BOOLEAN and defaults need to be
	0 or 1. need to do some nice abstraction layer.

-add credit information into the package parsers (finish it).
-add printing credit information into a CREDITS file in package creation.

-move from f2s as they are shutting down around my birthday.

-how about creating the entire set of Class::DBI classes on the fly ?
-make a method to auto create a Class::DBI class out of a Db table
	definition.
-wrap it with a method to create all classes for a db.
-also create regular classes from a db def (with Class::MethodMaker).

-make a ui for thumbnail:
	ui will ask for a directory, scan the directory for inodes, run
	a query against the db and will show all images in a single window
	which have ids matching the inode numbers from the directory.
-do a progress indicator like in schema which can do it in Gtk, text
	or text widgets or nothing at all.
-add 4 import tests:
	thumbnail,pics,movie,md5.
-add credits section to the perlpkg dtd and objects and print that into
	a CREDITS file in the distribution.
	credits = credit*
		credit=name email items 
		items=item*
-make a DTD for enums which generates a perl class...
	(and C h files and python classes etc...).
	This enum shuld be possible to use in a database definition.
-a list of avalialble databases:
	Mysql, Postgres - make an enum out of it.
-here is the list of ops:
	| Insert_priv | enum('N','Y') | | | N | |
	| Update_priv | enum('N','Y') | | | N | |
	| Delete_priv | enum('N','Y') | | | N | |
	| Create_priv | enum('N','Y') | | | N | |
	| Drop_priv | enum('N','Y') | | | N | |
	| Reload_priv | enum('N','Y') | | | N | |
	| Shutdown_priv | enum('N','Y') | | | N | |
	| Process_priv | enum('N','Y') | | | N | |
	| File_priv | enum('N','Y') | | | N | |
	| Grant_priv | enum('N','Y') | | | N | |
	| References_priv | enum('N','Y') | | | N | |
	| Index_priv | enum('N','Y') | | | N | |
	| Alter_priv
-change names and stuff like that to char(60) binary or something like mysql
uses.
-unite all the getsql methods to two methods:
	getsql and getsql_frag
-make enum objects made up of integers and not strings.
-add the following methods to Class::MethodMaker:
	-new_and_inherit("classname") which creates the
	following method:
		sub new($) {
			my($class)=@_;
			my($self)=classname->new();
			bless($self,$class);
			return($self);
		}
	or maybe better:
		sub new($) {
			my($class)=@_;
			my($self)=classname::new($class);
			return($self);
		}
	-meta_get_set which does the -java and _ automatically.
	-meta_get_set_connected in which the set method does the connected
	thing.
	-get_set_enum which creates an enum member which can only have
		a selection of values received.
		and then use it everywhere.

DTDs:
=====
-fixed up dtds to have stuff like password and not pass.
-fixed up the appropriate classes.

write a note about the fact that you have to remove the .cook.fp cache
file when upgrading system libraries in order for the correct compilation
to take effect.

do an example for the new String proximity feature.

make file iterators also supply the stat objects they get when checking
if a file is dir or file etc...
use those stat stuff to get the inode of the parent.
store the inode of the parent.
do the damn UI already.

C/C++:
======
do C scanners using C::Scan.
maybe use the code in prcps350 ?

Perl:
=====
-idea - big auto installer class which gets a list of classes,
	fetches and installs them (may use CPAN's services as a sub
	service).
do some kind of tools which lists all available modules and relations
between them (inehritance and usage).
study all the modules which I have installed.
make a string routine which turns "MarkVeltzer" to "mark_veltzer".
use that to merge pic archives.

database
========
-add transaction support in:
	Dbdata.pm parser (or above it).
	database creation ?
	database cleaning ?
	other places which we handle databases ?
-use Schemas to describe the DEF/XML so that users can make fewer mistakes.
-pour the SQL statements used to create the database into the .db file.
	look them over.
-make it so that name string will be a string limited in length.
-limit more text fields in size.
-use unsigned int too ?
-store the db/DEF xml file in the database so I wont have to specify it
	every time I access a database.
-rewrite the users part of the db authentication so that under each
	user you could have multiple ops.
-when creating database actually create the users.
-when removing database actually remove the users.
-remove users from current databases.
-add a unique constraint to database stuff.
	Unique makes a set of unique columns have a unique value in each row
	of data. How do I specify this in the XML ?
	<fields>
		...
	</fields>
	<constaints>
		<contraint>
			<type>unique</type>
			<members>
				<member></member>
				<member></member>
			</members>
		</constraint>
	<constraints>
	add default value to the enumerated and set types.
	Where do I use this ?
		participation table. String did "bring on the Night". There is
		no reason to say it twice.
		people table (no people which have exactly the same name).
		graph database. No need to specify edges twice.
	other constraints which I should think about: FULLTEXT.
-I can do the creation of indices with the creation of the table (look at the
mysql manual). Why do it in a separate statement ?

open source perl:
=================
1. report VERSION problems to all the authors of the modules which appear in
the CPAN -r option.
2. find all modules with no VERSION tag and update their authors.

install a new aspell version.
check for a new pspell version.
update my mysql documentation (it's from an old version).
fix the pspell extension, send corrections to the author and do a demo for it.

database:
=========
-default values for psql still don't work. Check it out.
	Where can I check it out ? (which fields use default values ?)
-when using optimize I use <optimized>true</optimized> but when I use the
null stuff it is <null>1</null> why ? decide on a standard and use it.

MySQL issues:
=============
1. Do a tool which runs OPTIMIZE TABLE on a db.
2. Do a tool which runs CHECK TABLE on a db.
	(this can check indices by itself...).

manage to install libxslt and the perl wrapper for it.

concentrate all the enternal modules tests in some centralized test.
make a method/script/test which checks that all external modules that I need
are installed.

get a "closeness" library - library which says when two strings are very
similar and how similar are they. C ? Perl ? Jave ?

make some kind of way of storing email open source realted correspondance in
the baseline with connection to the package discussed.

make an object like Version.pm that holds compatibility information
	(for instance between CPUS, COMPILERS, PERL INTERPRETERS etc...).
	make it read them from graph like XML.

make an example of using Class::DBI: a small UI for inserting a new movie
and director.

Testing:
========
use the Devel::Coverage tool to check that my tests have good code coverage.
	(tool like Orens that checks that each test goes through all module
	methods ?)

Spelling:
=========
create a spelling DTD which will hold parts of dictionaries.
Features:
	it will have sections (like project names etc...).
	Each word will be spelled and will have a meaning attached.
This DTD will be read by a class which will write a file for Aspell to
take these words into consideration.
These project related terms could be turned into a glossary and put at
the end of a projects documentation.

Java:
=====
heard about Kawa implementation of XQL for Java - get it and see how
good it is.

Perl:
=====
move all methods from Meta::Utils::File::Path to Meta::Utils::File::Patho.
stop using my old Path module and use the new object.
move all my classes to use Class::MethodMaker.
add my own inheritor from Class::MethodMaker to do my own types of classes.
add a Class::MethodMaker method to create retrieval and insertion into a DB.
add a Class::MethodMaker method to create retrieval and insertion into an XML
file.
start using some kind of named parameter library.

GA in perl:
===========
find the problem with installing Xerces-C perl exntesion and install it.
install the opeal documentation in my documentation.
install the opeal package (test it).

currently:
	fix all the gnome,gtk demos.
	wrap the change up (getting too big).

I saw an event where warnings were not emitted when compiling debug
C++ sources... Check it out...

write a bfd perl module. This will wrap libbfd and will provide most of
it's methods as object methods. On startup of the module (BEGIN block)
it will call the bfd_init function and on end it will call the
finalization function.

Docbook:
========
make a jw wrapper.

Basic Perl stuff:
=================
-make hash scream murder if inserting element which is already there.
-make interface for Array and Oset be the same so that they could more
	easily be exchanged.

Gtk Widgets:
============
do a Gtk combo widget connected to a database.

fix the thumbnail UI not to save files before showing.
Use my own window that knows how to show an image if no such thing
	exists in Gtk.
use Gtk::Gdk::Image directly and not Gtk::Gdk::Pixmap.
store modification time in the thumbnail project.
build a test for Meta::Image::Magick

Perl:
=====
use perl -c to check perl scripts and modules.

Thumbnail UI:
=============
List should be scrolled (fix Pics ui too).

Misc:
=====
0) put pthread example into the development environment.
1) database development is not ready for distributed development now
	(database names need to be change related).
2) what about cascase dependencies for dlls ? currently, if lib x is using
	lib y and y is using z but x does not mention that it uses z it could
	be that x will not be compiled if z changes and it should.
	take care of this.
3) create a standard about whether first letter of exe and libs are upcase
	(they are currently) and change all executables to reflect that

Database:
=========
0) add a script that clones a database and a script that renames a database.

C/C++
=====
check all C and C++ demos.
fix the following demos:
	gtk
	gtkmm
	gnome
	gnomemm
expand the following demo:
	libcwd.
make demos for more libs.
	ImageMagick
	Imlib
	and much more boys and girls.

XHTML:
======
two problems with DTDs right now:
	CATALOG and the xml import result.xml.

pics:
0. test the importer.
1. change name of project to pic to match other names.
	xml def.
	html publishing.
	python executables.
	perl executables.
2. Test doing it using the GD library.
3. try to use other thumbnail generators to speed things up.

Thumbnail code:
===============
0. try to use other thumbnail generators to speed things up.
1. take care of optimization of the inode key (db internals).
2. is there an inode to file conversion ? Is there a perl module for it ?
3. Test doing it using the GD library.

make a test script which runs all tests of a certain object
	(or all sources in the change).

try to verify the xml document using the xmllint checker.
add the xmllint checker as an option in checking xmls.
do a script which runs checks on all xml files.

-unite all the open source notes.
-unite other sets of notes (small text files lying around).

Stream line the performance of Switch.pm by importing at runtime the
classes it needs.

HTML in the XML directory
=========================
what is the problem with the XHTML DTD ? I cant seem to parse it.
make a script (in the Xml subdir) which checks XML docs.

Perl
====
move testing into the classes as a TEST() method.
make a test which tests all of those.

my xml to html script should also write an HTML headers...
	(and it should also clean garbage).
	(and it's entire functionality should be in a subroutine somewhere).

why arent my html pages under XML ? (I do write XHTML and they should
pass all checks...).

specify the birth name in XQL term precicely and not as today (actually
	use XQL).
remove spaces around the name (stringops package).
fix the xml print dom sample to work with SAX and not the current shit. 
try to parse the output and generate a DOM from SAX and not from the output.

Spatial data project
====================
check out the postGIS project to give GIS capabilities to postgress.

Fhist:
======
do some more tools for fhist.
tool to show you a past version.
tool to show you diffs between current and past versions.
	(graphically ?!? (with a diff tool ?)).

utils package:
==============
make a script (over an appropriate library function) to lower-case
file names (without overriding noov func).
make a script to find "holes" in series of files or directories.

Perl
====
add option for profiling to get params in.
shut the checker up.

widgets
=======
make a visual of a directory structure (with a thread to keep it updated ?).
make a visual of the graph structure (through database connections ofcourse).
	also with a thread and see if updates to the database could be
	displayed.

md5
===
add options for iter.pm not to report "." and "..".
write my own DirHandle to cover the problems with the current.
problem with my md5 importer which imports "." and ".." which all have
the same inode.

how about translating Enum objects (from xml/Def files) to perl objects
which only allow those values ?
how about translating Def files to objects (object per table ?).

make a generic piece of software (already have one ?) that converts .deps
files to graphs.
make a script that visualizes using graph visualization the ISA relation
ships in my projects.
same for internal usage.

graph 2d:
=========
do a perl/Tk editor widget for the graph2d database.

XML databases:
==============
-enable to inherit from your parent using a prefix so you could
inherit twice if you wanted to. For instance - have two graph type
structures in one database.
-remove the folders database.
-have the visualization widgets for data in the database have a prefix
option so that you could visualize one of the sets of tables that
you have in the graph with a certain prefix and then the other seperately.

Benchmarking speed:
===================
0. use the perl profiler (it can give per function speed and that
can be very helpful).
1. do a few scripts to do benchmarks of all kinds (run many scripts,
run a lot of perl code checks etc...). Record the Time that these
tests take. Make a benchmark suite out of it.

take a look at Class::MakeMethods (and others) which may make a lot
of my classes simpler (it a get_ set_ auto generator and maybe more ?!?).

optimization: all of my perl source code fixing routines are constantly
loading and saving the file. Make them just routines who get input and
output and pipe from one to another.

idea:
=====
put a forbidden external use list of modules (for instance Exporter and
vars) which the system will check that are NOT used.

what about getting rid of lice.txt and using the gpl_short thing ?
	The problem is that gpl_short and fdl_short are not
	converted to anything... (they are only legalnotice docbook
	entities and are in sgml/include). We need to surround them
	with dummy documents to get them converted. Then we can start
	using them.
	In any case there is a problem - what if you want to do perl
	stuff before there is a "gpl_short.txt" ? it should be known
	that the perl targets depend on gpl_short.txt etc...
	This means cook level enhancement.

write a script to report modules from which the version could not be
established and send notices to the authors.
(make it run over all installed modules - not just the ones that I use).
- also - make it translate modules names to package names and then to author
name and then to author email and send the emails automatically.

put the #__DATA__ check into the checks also.
check prototypes.
fix the Pod::Checker again (it emits stuff and make warnings be critical too).

More info to add to the author file
PGP pass phrase and user name so that he could sign messages.

perl packaging:
===============
add signature from my signature to the INSTALL file.
	(and some statistics about the package).

Another sanity check on perl sources: get routines before set routines.
check that pl and pm templates pass checks again.

How come my tests of perl didnt find the " \n" ? Is it because I only check
the code and not the pods ? Shouldnt I also be checking the pods (at least for
some set of patterns) ?

make one big paper describing all the benefits of Meta:
General file utilities.
Image processing.
Database.
Pdmt
Chess
Data Structues
Widgets
Script Writing
Communications
Aegis interface
Music processing
Book processing
contact processing
Managing websites.
perl modules development.
Perl script development.
C++ development
Java development
docbook paper authoring.
xml private databases.

make a script that knows how to turn all my modules to usings autoloader and
vice versa.
check performance with autoloader and without.

Give help to users in downloading and installing pieces of software in my
INSTALL document (using the CPAN module or the ppm tool).

Write a note about why we do the pod the way we do.
	(the __END__ note and separation of function and documentation).
Write about the use of SelfLoader and bring it back (in most classes it would
be faster).
Write about the heading (first line) both to scripts and modules.

Build my own wrapper for Pod::Checker which:
1. checks warnings too.
2. doesnt print the pesky messages.

performace is becoming too much. optimize.

must fix before integrate:
==========================
-the perl_pod_fix needs to preserve permissions on the file it removes.
-class to encapsulate permissions, groups (access lists) etc ? and so doing the
above line would be a sinch ?
integrate (enough with this weird change).

Interactive programmer helper:
==============================
helper UI to set up a new class for you.

the docbook creation stuff leaves junk files in /tmp. Fix this.

author data unification
=======================
author information is now stored in two places: my xml file and two sgml files
that are used for the docbook papers. Remove the two sgml files and make a
Template-Toolkit macro for author data. Make my author data contain all data
which is now contained in the docbook data and make it able to print itself
out in docbook style and that wil be the macro. Walla. The problem with this
approach is that when my author.xml file changes it will not cause paper
recompile (unlike the current situation). Again - this is a problem of the
dependency system.

Perl packagings:
===============
-real versions for dependant modules.
-put all the cpan upload code into a perl module (in Distrib).
-make a script that tests that all modules (scripts) which follow a certain
regexp are in a certain package. use that to make sure that all the modules
are in the meta package (they shouldnt be right now cause there are new
modules).
-make perl packaging put package name in each perl module when packaging it.
-upload meta-0.03 (automated).

pmail:
need to get more VCD examples to be able to create one.

next batch of changes:
copyright to have COPYRIGHT years (from Aegis) checked there...
check that the current version is the same as the last version number in
Aegis.
check prototypes all defined and are the same.
check first letter in module documentation is lower case.

CPAN tools:
===========
investigate that SNAPSHOT feature.

idea: check that each export is also documented and is defined as a routine.

report the bug in kmail to the kmail authors.
	(the bug where index's to emails get lost altough the email is there).

idea: supply a script with my package which will show you what modules could
be installed without prereq being broken with a certain set of preinstalled
modules (you could then select if you want to install).

idea: rules in the make process which convert text files (like gpl.txt) to
perl modules with just one method which supplies the data in the text file.
This way the Opts::Opts can display the license and when ever I change the
license the perl gets re-created.

aegis integration:
==================
when aegis removes a file (.pl) as a result of an aerm request by
a developer there is no need to put the "+x" flag on that file!!!
(maybe we can tell the shell to pretend that that executable is not
in the baseline ?). Or maybe we can put a template which does do
some execution and says: please dont run me...

pics:
1. do a piece of software to dismember the names in the models.
2. unite all named pics to the big partition (everything else goes in the
second).
3. make a script to check that file names are not case sensitive (lower case
if need be and change name).
4. unite the all the info that I have.
5. start making list of who is who.
6. sort each model into the following categories:
	porn model
	porn star
	model
	amateur model
	nude model
	super model

perl packaging:
===============
document which external modules are in which packages.
This will enable to know which PACKAGES are needed when you install
something. Describe the deps between the packages in a tree.

XML
===
move to SAX parsers. The code there seems to be a lot better and has many more
options.

time tables:
defined a Db scheme for it.

perl modules
============
and make the automatic testing check that the version in the file
corresponds to the version in the ISA section.
make the checkout for perl files change!!! the version in the file (bump it).
make the commit to history disregard the commit if only the version changed.

Movies:
=======
0. analyze return from IMDB using DOM : fix the document coming out of
	IMDB using some fixer class or skip errors in parsing by adjusting
	the parser. This is a must since we don't want to use HTML classes
	but rather XML ones which are richer and have more tools.
1. analyze return from Imdb and get director imdb id.
2. get director image.
3. get director more images.
3. get directors films.(only direction for now).
4. do a script which gets imdb ids for all directors in my db.
5. get all imdb ids for all directors in my db.
6. store those imdb ids in my xml file.

md5 project
===========
do one script which does the unique thing (with no intermediate file).
add features to it (like unzipping gz and bz2 and looking at the content
and thus seeing if those are the same files compressed differently).
use curses for the remove_dup script (for nice interface).

Opts::Opts
==========
add opts->std_anal(); which does opts->analyze(\@ARGV);
(so I wouldnt specify ARGV on each use).
have the devf do the Meta::Baseline::Aegis::which conversion for you.
	(why should I do it ?)

Perl Packaging:
===============
text creation using openjade does not work. Fix it.
fix the text creation from sgml sources.(maybe doit with the open jade
package instead of the current sgmltoolslite...). update open jade ?
check that it works with the openjade driver.
convert Cpan::Upload into a module.
upload new version to CPAN (using that tool).
make a class which checks for bad data (passwords, "sex " etc... in
a package so that there will be no confidential information pushed out).

perl:
=====
make the OPTIONS clause in executables be derives from opts-> statements
in the code.

db project
==========
finish the sa scripts.
do the various sanity checks on the db defs.
add sanity check to db that makes sure that TABLE NAME and FIELD NAMES
	in the ENTIRE DATABASE are not the same. This is important if
	we wish to generate dtds out of defs...

md5 project
===========
make the md5 database EXPAND the folders table (and make sure
	that it works).
make an executable that syncs an md5 database with a list of files.

regular packaging
=================
add packages, package object.
add auto generation of regular packages.
make the simul package be created.

compression object with object which inherit from it which compress
differently.

use the Meta::Development::Version in:
	aegis versioning.

do an enum data object.
do an set data object.

fix evolution and get to a situation where I can edit my contacts.

problem - when changing a database definition AND data for that database it
could be that the database import will be executed before the database
creation and thus attempting to insert the data to the new database. We have
to somehow sequence the importing sections AFTER the database creations
(make them dependant or something...).

packaging:
==========
unite the perlpkg and package to package.
add (at each package) a description of where that package is to be uploaded
to and with which protocol details and the baseline will take care of the
rest.

finish separating names to middle names in the movie xml.
	(have a script to check it).

make all type names be underscores joining two real names.
	(same goes for tables). So I wont have to put them in the dictionary.

pics:
tool to reduce resolution of images when the resolution is not really
neccessary. Are there such tools out there ?

make a class that can check if a string is all lower case.
use it to verify table names, type names, table names for indices, field
names, db names, user names. and more if you can think of more...
	memebers of enums and sets.
also check that description ARE with a large letter in front.
check indeed that those are checked.

make a class which checks passwords (is there such a thing in CPAN ?).
use it to check passwords for users in db definitions.

naming issues:
==============
rename the base project to develop or something.
rename the utils project to util.
inside the Baseline directory all scripts have "base_" prefix. That means that
the directory should be Base and not Baseline...

build system:
=============
try the following:
	open a change. get some file that can possibly have an effect on
	anything (perl executable for example) and then integrate and
	see how everything compiles. Why is that ?!?

try to speed up the archive creation even more can we cut even more of
the 10 seconds needed to create ? (that the major portion of the time
needed to create the package...).
How should I do that ?
	I could stop calcing deps all together (assume that the user knows
	what he's doing...).

for now make a unique constraint on the primary key instead of the current
implementation. Also bring back the references in Pg.
Find out how to shut the PG driver up.

script to check that every script under perl/lib/Meta/Tests is a test.

Compress-Bzip2:
===============
try to take over Compress::Bzip2 again.
clean it up and put it in the baseline (along with a xml file describing it).
start maintaining it.

Archive-Tar:
============
send mail with the bugs to the author.
make Archive-Tar support bzip2 also.
make Archive-Tar be more efficient.

todo:
unite my todo xml files (I alreay have a "done" tag).
pass over my todo xml file and straighten it up.
add dates to items (when were they done).

database issues:
================
make it so my Dbi object will have autocommit turned to 0.
compare creating database with autocommit and without.
start writing a performance document where I will put performance statistics
for optimization purposes.

add option for the create process to print the statements.
	(so you can debug the creation process).
make the pg db creation go without problems.

make the module version inside modules to match the aegis version number.

perl quality:
=============
check that all ISA members of a module appear in the SEE ALSO section.

tips for speedups when populating the database:
1. disable auto commit (only commit at the end).
2. remove the indices and return then after the bulk insert.
3. remove some of the databases features during the bulk insert.

movie db:
=========
make the view information in the XML file be according to person.
make the view information in the db be according to person.
import the view information according to person.

make the movie XML have stoarge information stored explicitly.
	(according to person).
make the movie def have storage information (for various people).
make the import process import storage information too.

make the movie xml have loan information according to person.
make the movie def have loan information too (with person info).
make the import process import loan information too (with person info).

try to get the data pushed to the postgreSQL too...

db infrastructure:
==================
integrate all the modules which do stuff in the database to one module.
make the db_*.pl scripts work well.

commercial/social:
==================
fix the bug for hartwig (single line processing).
make another ASN.1 iteration.
send version to harwig.
write code for aviram.
send emails to arie.

perl in the baseline:
=====================
idea: convert the perl modules installation file to more precise instructions
and graph be able to automatically download it all from the web and install
it...

put my developer user sites on my webpage:
	http://sourceforge.net/users/veltzer/ (summary page for me).
	veltzer@users.sourceforge.net is my email there (forwarded).
	http://search.cpan.org/search?mode=author&query=veltzer (summary page
	for me).
	http://www.cpan.org/authors/id/V/VE/VELTZER/ (directory with all my
	stuff).

what about putting a bad module list somewhere in the baseline ? (external
that is). First would be NetServer::Generic which for some reason you cant
distribute perl software which relies on it. This way it will check that
you're not using blacklisted modules.

do a test for the flush module.
make the color module work right (use the flush module).

benchmark the tar via perl stuff to see why it's so slow.
(maybe write my own module).

idea: add more checks to perl pods for syntax and style.
	actual syntax checks could be good.
	I could also add a filter which will disable syntax checks
	for words which are references to class or other tech details.

can I limit the text size so database usage be more effective just like
	in the blob case ? (movie names dont need to be that big - and the
	same goes for person names).
how can I make the data go in PostgreSQL (for instance I cant put null in the
date...)

perl packaging:
	add a ppd file like in DateTime to my package.

idea- system to store ALL sources inside the database. Dependency
management will be within the database. The way to get over the problems
of h files in C (for instance) will be to do preprocessing (or pre-pre
processing) by myself. How do I get over that for perl ? dunno. Java ? Any way
to overload the default loader there ?

revamp and check the DB export script.
	(actually all the scripts there...).

make the dbi object have the same interface as the stats object (the push
interface). This way you could pass it to statement collection routines and
have them executed.

create a logo for my web site using the gimp.

make mysql client always use a pager.

perl:
	add option in my Makefile.PL to go and get the modules automatically using PPM?

enhancement to Perl/DBI to enable to do statement with placeholders like :name
instead of ? (which gives meaning and make everything better...).

find out if cpan allows uploading in bz2 and upload in bz2.
make a packager that creates bz2 packages on the fly.

add CHANGES, BUGS files to perl packages.

routine to extract a database description in XML from a real database (Mysql
or Postgres).

make the movie_stats.pl faster (it currently uses DOM).
	(maybe do it in python).
make the movie_loans.pl faster (it currently uses DOM).
	(maybe do it in python).

check why the PL file doesnt appear in the CPAN docs...

put more modules in meta and re-upload it (add option to have all modules in
it ? doesnt sound good...).
make better examples for the modules that you put in.

make the pkey column in the pics_ui hidden.
make a pics package which recreates thumbnails for a set of photos (all ?).
	(recreates checksums?)
return cursor color after usage message is printed using Term::ANSIColor

add UML and SQL backends to the db/def system.

event driven SQL table/tree presenter (only queries for data to be
shown ?).

get all of my DTDs on the webpage too (some dtd to html conversion ?).
	what about documentation to the dtd ?.

make the inserting software add it in folders, checksum etc...
	also insert them with order.

finish fixing the password file.

make a downloader software which knows which md5 you already have.
(this is a general concept - md5 can be used to sync two sites...).

there is a project which has an XML tree and XML editor widgets for
GTK/Python. Check it out.

idea for KDE app to store passwords for you.

clustering algorithms for sets of pictures.

article comparing technologies of activation of objects.
central point is that objects are always tied one to another in terms of
interface but the object is to minimize that to a minimum.
another point is that interface exploration is not a great advantage for most
purposes.
comparison of C++,Java,Perl,Python,RMI,Corba as technologies which enable
this separation.

do widget to show folders.

article about the fact that the fact that there is competition today in the OS
market does not mean that the market is healthy since it does not yet have all
the basic conditions for a competitive market and the competition today for
Microsoft did not arrise from a healthy market condition.

article that looks like a report to a science history class in the year 2019.
	(showing how microsoft made a fool out of everybody...).

article about epic technology and languages like Perl,Python and Java.

write a cellular application like in Schema.

write a shipping application like in Schema.

use even less attributes in sgml generation and put everything in the css.

structure in database for picture series (with order).
	each series with a set of pictures.
	maybe this idea can be abstracted to a folder with order structure ?

find out how to write hebrew in vi.

problems with mysql database still outstanding:
	move all mysql databases to /local.
problems with Postgress still outstanding:
	postgress DBD driver is noisy!!! find a way to shut it up.
	don't shut up the Pg driver and fix the errors it's talking about.
	ENUMS and SETS are not handled (this will cause errors!!!).
	REFERENCES are not handled.
	blobs in the postgress implementations are translated to TEXT fields.
	booleans are treated as integers.
	manage to use the ~/.psqlrc file instead of setenvs in my .base_profile file.
	I use Base64 encoding to put binary data in Pg. Why should I do that ?
	binding with SQL_BINARY should work...
outstanding issues for all databases:
	When I have a free paragraph (like when describing a table or
	database) that paragraph may have characters which will cause the SQL
	statement doing the description to break (like ' or "). There is a
	quote method in DBI but this is when you already have a DBI
	connection!!!
	What about reserved words ? Each db has its own set and if you use
	such words (for instance in table or db descriptions) or in a table or
	database name it creates problems. Try to build a filter to counter
	that problem.

make binary data go to the databases also.
	(with file that had the source data also).

do a DTD for songs.
add a songs directory to xml and start getting songs in.

fix the problems that makes the build twice.

install visual age for java for the devel account.
install staroffice for the devel account.

write about the LD_LIBRARY_PATH hack and find a way to do it.
	(i forgot what hack that is...).
get new guile documentation into my archive.

get my book repository into a database.
get my movie repository into a database.

discuss with GNU the need for licenses for DTDs and Database definitions.
	(which could be expanded but the details remain closed).

write a viewer for these databases (php ?).

how about checking that output files are produced after production phase ?
	(it could be done in a single place at the Switch.pm module).

produce SGML(docbook) from dbdata (is that wise ?).

produce dtds from database definitions ?
	several problems involved: fields in differet tables can be the same
		but they may have different meaning.
		Two options to handle this:
			1. make sure that different tables dont have the same
			fields (ugly and same fields are sometimes natural
			(pkey etc..).
			2. give an xml tag name which is unique
			(tablname.fieldname).
		option 2 looks better.

make the produce produce the fs dtd.
make the file reader read itself from that dtd too.
	(add xml parser for it).

write a script which gets an md5 image of whats on the remote server.
work on md5 signatures and store an md5 image of whats on the remote
web site (dont work with revision times anymore...).

install dtd2html again.

check why the script for removing images under a certain size fails...

personal organization:
	mark white house paint and brushes for my brother.
	mark to get books from mom and dad.

Translate DTD's to perl modules ?
	(there is an option to do this...).

bring back perl checks with perl -c -W instead of Lint.

make the backup be able to do aedist also.
use validating writer everywhere.
	(instead of XML::Writer and Meta::Xml::Writer).

inherit from ExtUtils::Installed and provide service to get a package
	from a file.
write my own code for getting a version from a file.
whenever there is no version in a file return 0 so 0 will be written.

write a test for SOAP classes.
what about a changes file in the package ?
what about AUTOLOAD in the packages ?
	how do I do it ?
get a README file listed in the package.
make a routine to get a version out of a module.
make external module versions be listed.
make sure that we depend on perl 5.6.1.
	(can we add it on a prerequisite ?)

how about dependencies between packages ?

create a path object.
find automatically the tests which test the packages involved ?
make the "..." in the test run be aligned...

bring back c++ USING REGULAR CHANNELS.
	(linking through regular channel).

system dependency checks.(each module which runs a system call will
	check if the tool it has is available (using the path module)).
system logging.(each system call is logged to a file).
caching of aegis.pm information.

PDMT!!!
return to including stuff in XML files.

test if sendmail works.
	(also see if it has a hard time on boot).

bring back xml/perlpkg deps on modules in a smart way (without me needing to
parse).
sign my packages ?

add a checker routine to Lang::Xml which validates using XML::DOM::ValParser.
try to move to using a validating writer.
what's this SAX thing ? what can I do with it ?

share the author element of my dtd with the author definition in docbook.

make my references to outside files be unparsed entities and so appear
	on the deps list without me doing anything about it.
	(and remove the code that does anything about it).

make perl packages have depdenencies also.
	(and scripts).

if we use the same module twice in a perl module do we get an error ?
	If not - make it so.

think about how to use the aegis version information more efficiently
	when supplying code to the outside (like in perl packages).

I have lost C++ stuff...:) fix this.
	simplify the C++ stuff.
wrap up the change.

get stuff from makepp.(signatures and stuff).

make the xml cook produce a .deps target file to be included for
	packages. (it will depend on the package xml file).

how do I refer to external file from an XML file in a correct way ?

idea for cluster analysis to segregate photos.

convert the rule system to xml.
make an input file with platforms.(instead of the current arch
	file).
list of source files to be converted to dtd which describes
	their hierarchy so that option files to them
	could be described more accurately.
make a transformation from a dbdef to a dtd.
make an automatic perl packaging system.
	the idea: xml file with all the data needed for packaging a single
		pakcage. that file will produce a dependency of the package
		file on all of its components with a rule to create it.
		the xml file will have:
			the name for the package (packages have
				free names because they can have many
				modules).
			description for the package.
			the version of it (free for the author to bump -
				not every change needs to bump it).
			the readme information attached to the package.
			a list of pms to be distributed.
				(the conversion process will expand it
				to full deps).
			a list of pls to be distributed.
				(the conversion process will expand them
				for pm deps purposes).
		the conversion will create the following:
			Makefile.PL with the information in the XML file.
				(author name and email will be inserted
				automatically).
				The Makefile.PL will also contain all external
				packages needed for all of the modules
				within with their respective versions.
			Changes file with a list of the changes involved.
				(list of changes to every file).
			README: will have the README information for the
				package.
			MANIFEST: will contain all pms needed plus:
					Makefile.PL
					Changes
					README
					MANIFEST
			and will put the pms in there, will run:
				"perl Makefile.PL"
				"make dist"
			and will get the output and will put it in a good
				place in the baseline.
capability to upload the package to CPAN ?
unite link and perlpkg (they are quite similar...) ?

move the backup script to the baseline.
make a script to sign and move all backups to the net.
	(several locations).

fix sgml dependency generation.
	(an SGML parser or a fix to the current XML one...).
How about an XML CATALOG parser which will give you an object
	with all the data and services about the content ?
	(there is a begining of one which I downloaded...).

add pilot note to new computer:
===============================
make a symlink to /dev/pilot to /dev/ttyS0
	(remmember that the bios has to enable the serial ports).

pilot backup note:
==================
pilot-xfer --backup [dir] will backup the entire pilot to that
directory.

reenable perl lint checking (there is a problem with the 5.6.1 version
	with that...).

Is there a way to backup the pilot automatically (without me having to
press the hotsync button ?).

fix all perl sources (history tags).

do a script to backup stuff over night (to several locations).

do the three documentation convertions for c++.

find out about shays fonts.

upgrade to new docbook XML dtd.
should I write a website flattener ?

music stuff:
============
	investigate this chord2html and chord to postscript conversions.
	what is this chord pro software ?

Now I can convert DTDs to html (through XML - or maybe docbook ?). do it.
make my homepage using the webpage dtd or some other like tool.
do rules for C files too.
use doc++ on c++ files. (use that on the sample directory).
html links in the temp files as tags.
remove the table attributes (100% and border=1) from htmls and into
	css.
is there an "#include" statement in htmls ?
	(try @import) Implement last modified using that.

do revisions even for includes.
	(check that all of my includes are components which can have revisions
	in the docbook manual).
add copyright years from aegis for the copyright notice.
add the name of the developer for the copyright notice.
do revisions for htmls (add a few lines at the botton of the page).
do revisions for perl files.
ps are derived from dvi even for non lilypond stuff (like docbook).
	is that what I want ?

Another idea for revision information:
	make a docbook revision file for each docbook source file
	and make the docbook source file include that revision
	file. Make the revision file directly dependant on the
	docbook file while the docbook file will only cascade
	depend on the revision file.

options in aegis where every aeca makes all changes rebuild.
	(make all files depend on the location of the change description ?)

Do the PDMT and USE IT INSTEAD OF COOK.

perl: Maybe all libraries should go in $BL/perl ?
	Is it better ?

temp issues:
============
from now on all error message will be on the docb files but we want to get
them in terms of the temp files. Make a line map between them and translate
, parse the error messages and translate them back.

enable SWIG.
decide on a good SWIG scheme
add xs support.

examples:
=========
add an example for libz.
add an example for audiofile.
add an example for kde. (need to install new kde for this).
add an example for kparts. (need to install new kde for this).
add an example for bonobo (do I need to reinstall bonobo for this ? Is this
c++ or C ?).

Graph visualization
===================
make a visualization utility for graphs
	(download some helper package from CPAN ?!?)
make a utility to visualize the following graphs:
	ldd derived information.
	my libs graph.
	my dependencies.

website issues:
================
How do I avoid the extra frame in my website ?
Text conversion still does not work.

libs change:
============
use the `-Wl,--rpath -Wl,LIBDIR' linker flag
	for external libs (only external as internal must
	use the LD_LIBRARY_PATH).
When changing libs things need to be rebuilt twice... why is that ?
search for libs in the creation of deps stage.

idea:
	tool which gets a list of libs and produces a dep graph between them
	(one which is derived by an ldd type tool).
	Is there a BFD type module for perl which I could use ?

write about added /local/tools/man to /etc/man.conf.
document the fact that /etc/ld.so.conf should have /local/tools/lib/mysql
	in it too if you want to work with mysql.

integration check change:
=========================
why does the pdf fail in the middle always and makes it the second time around
? what is this shit ?
why does a partial integration (not -minimum) sometimes build all documents
resulting from database definitions ?(pics,movie,chess etc...).

learn emacs and start editing xml using emacs (configure emacs so
that he will give you the correct set of tags and will check the
document correctly).

dtd enhancement change:
translate dtds to html using dtd2html and publicize them on the web.
	No dtd2html is quite slim in capabilities. I probably need
	my own translator or get something from the web.

create a format from which docbook files are generated.
	(but a tag for history there that will be replace by
	the files history in docbook format...:).

move the link system to xml.
move the rule system to xml.

don't use the external gzip executable to do compression.
as a first stage use a routine which reopens stdout at the perl
level so it won't need the intermediate shell. At a second stage
actually use the Compress::Zlib module to do actual perl level
compression without running an external executable.

update.pl:
maybe get the modification times from the ls -R to speed things up ?

book database change:
do my book db.(many writers per book is the only addition to the current db).
update the website with all new fixes.

update aegis stuff (there are new hooks in the config file).
document the user install purpose and how add it to the list of users
which are created for a new machine.

docbook format checking change:
problems with conversion that I know of:
	mif
	lyx
	latex
	xml
	text
	info
need to check:
	dvi
	tex
docbook text convertion does not work because it stores temp files
in the home directory of the programmer. Try to fix this.
and check all others
set the INFOPATH so you could use info [mydocs] and get the right info.
set the MANPATH so you could use info [mydocs] and get the right info.
wrap up the change.

check why returned mails are reported when I'm running tests connected to
the inet.

start supporting gcj.

i need the ability to store edge related data in the graph.
try to use SOAP for PDMT.

respell everything.

add the fact that mark2776, is ok on www.kuro5hin.org with pass rrJSMikt

check if yahoo minds uploading bz2 format.
	yahoo only allows .gz files to be uploaded (file.pdf.gz is also
	allowed).
check if rtf,ps,pdf etc are compressed easily and if yes dont
put them as is on my website.
	rtf,ps,pdf,text are highly compressed. Compress them now.

do an XML filter which removes certain tags.

remove more "\ \ " from the baseline.

tags that need not be checked: (do that as a routine for docbook).
	<database>
	<programlisting>
	<table>
	<trademark>
	<street>
	<state>
	<city>
	<firstname>
	<surname>

spelling:
	fix the program with the fact that aspell insists on checking
		program listing tags too.(bug in aspell ?)
	maybe I should not edit the aspell word list directly ?
		(hold the names in some xml file ?)
	make aspell not use my (~/.aspell) replacements file too.

fix up the arch.txt file which holds old architecture names (make them
automatic).

write how I configured the domains in order to use direct mail on
my box.
find out how to start the INET connection at boot and not close it.

backups:
	fix my backup script to backup everything:
		homedir.
		development.(baseline+changes).
		workatothercompanies.
		palm - do this directly from the palm.
		personal databases.
	put gpg on them.
	backup them to public servers.
	make the script run nightly and record how I did that.
	after that remove the non encrypted versions from the sourceforge site.
	remove all files I have on visto after the backups.
	find a new place to backup with ftp,sftp,scp or whatever and do it there too.

use dvitype to convert dvi to text and to verify dvis.

add conversion of the docbook to man.(use docbook2man).
add conversion of the docbook to dvi.(use docbook2dvi).

write a basic utility to count chess games vs opponents.
	(in my non-pgn database).

website stuff:
add a uniform style sheet to my site with a logo and back bottons.
add dssl to my documents. (back buttons and conformance with the regular style sheets).
find a way so I could see my webpage in a developing change (assuming that not all files are in the change).
maybe do my site with frames ?
upload my site.

add option to do docbook stuff with docbook-utils.

-mark the fact that the baseline needs the following services to work:
	mysql
	postgress
	sendmail (tests rely on this).
	sshd (tests rely on this).
	httpd (for aegis viewing).
	xinetd (for ftp - on older systems it's called inetd).

	maybe even write a script to check that all of these services are
	running and that all of these services are in the startup files
	of the system ?

move docb to sgml.
do a script to clean my website of old junk (it isnt the job of the upload
script since he concentrates on uploading - I need some script to produce
whatever is in the website and see what is there because I want it and
what is old junk and remove the old junk. BTW: index.html is NOT junk...:)

change move_to_jpg.pl to a more general utility.

database for hyperlinks (bookmarks).
paper on database inheritance.

change:
try to fix the problem that I have to rebuild everything with every
integration. whats that ?

website:
add some search capabilities to my site (google ?).
fix a lot of my papers.

install lilypond manuals.
if some binary is missing then my scripts just exit with no explanation
	- make it not so.

get the sound blaster live driver to play midi.

mark putting the new flash plugin for the 7.1 install instructions.
send bug to sgmltools-lite people about prefix not being replaced.
write down that added the database,abuse alias for hosts.
make a script to remove identical files (using a perl hash and md5 sums).
do the same script over the database.

why are options in opts one char to the right ?
	(try --help on something and see for yourself...)
why are options not reporting no_limit on number of arguments
	(and instead show the 65000 stupid limit ?)

do a perl script which resizes (with xpect) a list of files to a certain
resolution. (add to images project)

fix the gcc error handling.
fix the C++ helloqt program.

install PyKDE and do example.
change:
add xml/rpc object client and object server.
	(multi object ?).
	show how it runs vs a graph object.
change:(122)
add sets to the big xml hoopla.

find out which dtd that is from the content itself.
make def have connection in it (dtd level).
make set have a def in it (dtd level)

website:
	-dont use width="10%" (use something more appropriate:
		width="minimum" or something...).

improve exporting:
	1. flat export.
	3. integrate.
	2. enable export to write directly to a file.
use the dataElement method of XML::Writer more to cut code.
make the ohash able to retrieve the number of the elements.
make a column fixing routine for xml files.
make the import stuff work.
unify xml stuff - only one xml language (def, sets should go in).
add XML RPC server capabilities.
change names for db executables.
add xml import to databases automatically.
def to dtd conversion - no need - there will be a single dtd for db data.
gtk command line args:
	add free args. (what if number is limited ? should I build a box
		for each one ?)
	connect signals.
contacts:
	add person connections.
		(parent of person x is person y).
	add UI to view and edit all of the above.
change suffix of docbook files to xml (sgml ?).
next C++ change:
	make c++ mechansims the same as all other langs. 
	add gtkmm test and wrap up (you'll need to compile gtkmm in your
		own compiler...:).
	colorisation of gcc output correctly.
add installation of freeciv to list.txt.
paper:
	one world one source tree.
reserved words removal when writing SQL database definitions:
	group is a reserved word.
graph widget.
do dtd convertion.

movie project
=============
	1. go all over all tickets and mark them in the file (that way the
		tickets will realy be counted...).
		This will also check that all tickets have their film marked.
	2. buy a new confirmation book.
	3. Try to confirm as much as possible.
	4. Start putting dates on shows (how do I do that ?).
	5. Develop an application to manage all this... (gnome-db ?)
	6. mark the music tapes that I have.
	7. mark which tickets I have according to movies and lets count it
		and not just print out the number.
	8. Check matching of tape stock and database in both directions.
		This should also check the names of the directors and the
		films.
	9. Backup the database.
	10. Print the database.
	13. My database does not distinguish between persons who have the same
	name the way that the IMDB does (like "Michael Cane (II)" which means
	Michael Cane "The other"...). Maybe that makes some of the data in
	the database a little less valid (as you need to sort through the
	"look alikes" and find the right one. Make a script to do that and use
	the IMDB for it... Keep that script handy since the IMDB people might
	change the definition of what is (II) or (III)...:)
	14. My database puts prefixes in front of film names and not after
	with a comma. For instance: my database would say "The Matrix" and
	not "Matrix, The".
	Examples of prefixes to which this applies:
	The : english
	A : english
	Le : french
	Ha : hebrew
	Il : italian
	Should I move to the IMDB notation? (books also use that notation).
	15. find out what happened to the following titles which were in my
	collection but were lost:
		[Schumacher,Joel][Falling Down+++xml]
		[Wenders,Wim][Until the End of the World+xml]
	Maybe these are with doron too ?
[endings to see]
	Corcodile dundee 2 (Didnt finish because of the Rabin Murder).
	Face of the Wizard ? - Ingmar bergman (from when he leaves the house).
	Play it to the bone-Ron Shelton - two boxers with lolita davidovitch, woody Harelson from the fight scene (1.5.00)
	Dogma-Mat Damon in a movie about two angles who want to go to heaven (black comedy about the church)
	Al Pachine in a movie about a cop going under cover as a gay guy in order to find a killer who's been killing gays
	Lolita by Adrian Lyne
[to mark]
	mark the Bugs Bunny cartoon film that I saw in the films section.

Books STUFF TODO
================
[todo]
	Put stickers on all books with my name and details
	Erase my pencil marked name from all books
	Wrap all of my books up
	Enhance the computer software
	Run through all of my books and make sure they are all registered
		(and vice versa - that every book that it says I have I
		realy do have on the shelf...)
[not finished]
	Conciousness Explained-Daniel C. Dennett (2/3 of the book)

wrap expect.pm in my own version which checks for errors.

write a script which reduces all the indices in a database (removes holes).
Write a ranges mathematical object (a number which can only be in certain
ranges).

why doesnt the feature for seeing old versions of files works in the aegis
	web interface ?
take a look at scandoc and doxygen.

fix problem with the 3 control subnet going into the routing table.
fix the problem that errors are not handled well.

make the c_incl software know how to use C comments and ifdefs.

is there a problem with creating fields with the same name in different
tables? I seem to be getting into those problems ? fix that...

0) different flagsets for different objects (the idea is that there will be
	more flexibility and so we will not have problems with the amd/
	pentium stuff...).
1) finish with dmalloc.(sand/dmalloc).
2) different offsets for different tables in the import script.
3) sanity for indexes.
5) distribution check (with quality of service).

enable per plat/arch link and include directories
enable per plat/arch link products to link.
enable per plat/arch object products to link.
enable a platform for compilation (like alpha etc...).
	This requires:
		0. cross compiler installation.
		1. changes in the cook file.
		2. changes in scripts.
		3. changes in the development shell scripts.
remove the need for a parameter in STK_TRACE.
clean up the database: ifr should be interface or vice versa.
How come we can't profile dlls ? or inst that true ?
When doing profiling you need that all libraries know how to compile in
	prof mode ?

fix the fingerprint stuff with cook

fix the system call to return a correct "in code" return code (1 for success).

-do it so all the perl binaries (in BL/perl/bin) will have x on them.

-the automatic merge feature does not seem to work well as it produces
	conflicts which are not realy there... fix it - its probably a problem
	with my glue...

-improve the way in which I write multi directory implicit rules in cook.
	the %0 variable stands for a directory and a "/" afterwards ?

-write a script that enables import into the database without absolute values
	on index columns (an offset of each primary key index).

-use the comments feature and add comments to the tables in the def file
	for the database.

-use the mysql comments feature and add comments to the tables INSIDE the
	mysql server.

-bring back the strict flags for C compilation.

-add a script to populate the database from text files (to replace
	mysqlimport...).

-make cook not compile files which are not known to aegis.

-handle remove files correctly.

-when a change is in the "awaiting_integration" state the login doesnt
	work well...

-create the database.

-get the changes from work in here.
	I need to install:
		MySql 3.22.32
		MySql++
		Perl DBI/DBD
		Python MySQL

-in OV change the default directories for changes to have the
	qbopt prefix for them.

-check if we can pass a flag to the linker whan linking dlls to assure that
	all symbols are resolved. This is very important so that
	everyone makes sure that he tied all the ties when doing a new dll.

-reinstall my aegis at home with the new improved version and with nroff
	linked to groff.

Fhist issues:
=============
We can do the script that removes all unwanted files using fhist - see
where that leads.
We can disable commiting to history files which match the previous version -
check how and where it leads...

-make a script to remove all files which are identical to the baseline
version. (demo and verbose flags ofcourse...).
-check that script on the change its developed in.

-use the peter miller prefered scripts for mailing notifications to the
	the developers...-or maybe not and just borrow stuff from them...

-integrate.

-get the g++ compilations out of the cook file and use the same mechanism
as in any other language.

-fix up my todo file (according to subjects).

-have an option to have the history perl wrappers silence the fhist
	underneath (that fhist is a babbler...).
-change the name aeuser in the machines to aegis (it looks better on the
emails). Do that in the documentation on how to set up a baseline too.

-find a tool to handle todo lists well (graphically).
	Features I need:
		0. Tree views.
		1. Priority views.
		2. Search.
		3. To be able to take all the information with me.
		4. To be able to see it in a browser.
-make the sendmail location a parameter (it does not exist on all systems
	in the same location and sometimes even not in the user path...).
	Or better yet- download Mail::MailTools? yep.

-write a document about extracting older versions of files using fhist
	and older versions of the baseline. Also mention how to commit
	specific files and the entire change into the history.

-in the future - use the fhist # EDIT and other features in every file.
-download the Mysql documentation.
-enable each library in rule to have its own path (or maybe just add paths
	in the rule - or maybe not?!?)

-write down the LEDA installation instructions in some file in the baseline.
-whats wrong with the usage of the COOK variable ?
	The problem is that Im doing explicit setting of all values
	in the cookbook and leaving nothing for the users...
	Run a test to see if that is right...

-bring back the quote mechanism into cook and see that it works.
	It wouldnt run in a first run because of the g++ compilations,
	but that needs to be moved out of the cookfile too.
-fix the absolute paths now in the cook files for c++ compilations to the
	tools directories (and in c++2dep) and put that in some data file.

-add comments to the perl option files (in Options.pm that is, the ability
	to add comments to the option files).
-document the options in the data/baseline/cook/opts.txt file.

Aegis (to peter miller...)
	-why is -MAXimum the default in aeib ? isnt this logicaly wrong ?
	 wont old built files stay forever in the baseline ? Shouldnt
	 -MINimum be the default ? In any case, if I decide that I want to
	 go with -Minimum I have to remmember to do that always (on each
	 aeib...). Way cant I put it in aepa ?

-my sendmail binary is in /usr/sbin/sendmail... (unlike in slackware where
	it is in my path...). What do we do ?
	The best option would be to use Net::Mail and add that to the
	list of requirements by the system...

-make provisionings for different targets on development and on integration.

-Ask Tom Christiansen to provide an option in Pod::Html to remove the cache
	once pod2html is over...
-Ask Tom Christiansen to provide a return value from Pod::Html::pod2html
	(this function currently does not provide a success indication!?!)

-bring back the c++ and rule system.
-move the actual compilations down to the perl level.
-make sure all the builds and all work.

-how should I handle binary information in aegis with fhist ?
	(how do I let fhist know that its ok if the files have
	"illegal" information in them ?)
	"illegal" information in them ?

-add binary file support to the baseline. The only problem with that is
	notifying
	fhist that a certain file is a binary. Do that in the history scripts
	(base_aegi_conf_history_*.pl files). Ask some module whether a given
	file is binary or not (dont do that according to extension). Fhist
	does not get run a lot so we dont need to save on its running time...

-create a runner for Python code (base_pyth_run.pl).
-generate rules for all samples in both debug and relase modes.
-arrange for rule targets to depend on the ".tg.d" flies as well...(they are
	currently not and if the tg.d files get updated the targets are not
	remade...).

-make it possible for me to actually run baseline executables...:) (LD_LIBRARY_PATH set like PATH but add both to PATH and to LD_LIBRARY_PATH the bins/gcc/dbg
	and dlls/gcc/dbg prefixes and add routines to change those...)
-why does cleanup (ours) report removing of empty directories when the verbose
	is turned on but doesnt report removal of files ?
-why, when I dont have a change does my init scripts fail and my login looks
	dirty ?

-create my own wrapper like base_perl_wrap.pl and use that in every "#!/usr/bin/env" line in every perl script. This way base_perl_wrap could have common flags
to the perl interpreter which the current way cant have.

-add option to remove old logs before every build.

-make the Java system actually compile (install a full compiler system
	in /tools...).
-make the nw system work (it can produce whatever you want...).
	get a new nw or find out which is the leading tool today.
-get a documentation system for C++ working...

-make the rule system work.
-make sure that you can link and make executables.

-bring back prefixes to libraries, dlls and binaries
-make sure that lists for cook are generated with write permission for
others so that they could be removed.
-get ridd of the empty .err files which show up in the baseline.

0. do a script to see the last log file.
1. do a script to see all errors of last compilation.
2. make the link work.

fix all the FIXME's in the script (~/.base_profile).
order the routine in ~/.base_profile in some logical order.
put ~/.base_profile in the documentation.
put ~/.aegi_profile in the documentation.
put ~/.aegisrc in the documentation.
put ~/.bash_profile in the documentation.
create our own ae_c and ae_p and aecd scripts which will fix the env
	vars (just do their own thing and call a fixing routine)

bug in Aegis:
	when even I do an aedist --receive I get project preferences which
	have defaults in them not from my aepa
	When I do aeclean it just cleans the files.
		What If I want to first see what hes gonna do ?
		I implemented a script that does that myself but if aeclean
		will have a --Demo flag where he just shows what hes gonna
		do Im dropping my script completely...

Idea about it - it should have a whiteout file.
	This should be a special file that can be created using
	makedev or something and if it is found in the overlay
	it means that the underlay file should not be shown
	(like it does not exist).
	(this will be a little more complicated when dealing
	with arbitray size path...).

aegis checks for baseline:
	0. integration cycle (which chmods executable scripts)
	1. aecp of script does a chmod.
	2. aenf with templates works.
	3. check that whiteouts work
	4. check that the history mechanism works.

bug for aegis:
	why doesnt aegis purge empty directories after a full integration
	build ? what about development builds ?
	why doesnt aegis cleanup before an integration build ?
	why dont I have a command to generate whiteouts ?
	in the aepconf its written that the default value for development_directory_template is something but when you explicitly put it in the config file
the names of the changes come out different (base.C005 <-> base.C5).
	in aepconf there is a hook called:
		change_file_command
	which receives: ${File_List}
	the problem is, that if you Quote File_List you will have to do
	splitting in the script that youre writing (and in any case that
	defies the purpose of ${Quote} since the the idea is to protect
	from shell unsafe filename (like filenames with spaces...). Since
	${File_List} is a list of space separated files it is impossible to
	determine where one file ends and another begins.
	I suggest
		0. adding a function to aesub:
			${List_Quote ${List}}
			which splits the list and quotes each element.
		1. in general, finding a better way to pass lists to scripts
			in aeconf (I still dont have a good idea...).

Setting up aegis: (write this up in the baseline).
1. create a new group (usually called rnd).
2. add all users which are developers to that group and make it their
	primary (you can remove them from others...).
3. create a special user called aeuser with a simple password and create
	a directory for projects and a directory for changes under that
	user with the rnd group as their group with the suid bit turned
	on just for the changes. This will enable just this user to own
	projects (that means other users wouldnt mess with the projects
	by mistake) and all users to create changes.
	This aeuser should not have a programmers home directory.
	He should be able to activate aegis and thats it!!!
	also create a tmp directory for development junk.
	(also with suid on and write permission for the group).
	make sure that the changes directory exists and has write permission
	for the group (for them to be able to create changes)
4. add only aeuser as adminstrator.
	aeuser should not!!! be a developer.
	the developer,reviewer,intergrator roles should be split
	among the other users.
5. The other developers may be administrators also if you want to avoid
	aegis prohibiting developers from exempting their changes from tests
	etc...
6. Get a full aepa file and look at it and work on the project attributes
	(like default development directory, default test exemptions etc...).

mention in the documentation that you can change the default man path
	in /etc/man.config and add a default directory that will be
	searched for man pages

find out how to make that fucken ext2 partition on the zip drive.

SANDBOX Compilation:
make compilations in sandbox too.
How do we do that:
	0) sources in the sandbox are the Makefile and all other sources.
	1) for each makefile get the list of targets that it will update if
		you do a "make" on it (how do we do that ?).
	2) define those as the targets for cook.
		do this by placing a cook snipplet like that:
		myprog hisprog : Makefile (and all other dependencies make
			lists for them all)
			make
	3) this should do the trick and it will be a nice thing to have anyway
		since we may wish to do other things with it in the future.

License issues:
===============
Each file should have a license at the begining.
The license should be stored in a single!!! place in the baseline.
A routine by each language modules should be provided that receives the
license and generated a text that wraps the license in a comment.
	(warp_string_in_comment method...).
A build procedure should be defined that checks that each file has that
exact license in a single place in the text and if not, replace it.
(from that respect all source files depend on licenses...).

Make LD_LIBRARY_PATH (and all ~/.bashrc stuff) be nicer.
How come I have to do eval on the dircolors stuff and not { } ?
fix the colors in the ls --color (executables are always colored green
	and I want them to be marked as source (for instance .pl or .py
	files which are both executables and sources)).
sync the todo.txt and the sync_todo.txt files.

move the perl.pm into the lang subdir.
make the MANIFEST in each file have the directory also.
have an option to change from ##__DATA__ to #__DATA__ and vice versa in the perl
	language module.
make a separate directory for sh , bash and bash2 and gbash.
make directories for csh and tcsh, ksh, zsh, ash, bsh

stop the colorising modules work if it is printing into a file and not
	into a terminal (it leaves weird characters if it is outputted
	into a file...).
When the colorising module ends - have it return the color to the color
	that it started with (it creates strange effects on the cmd line...).
make the cook print the stuff its doing since right now I dont see the
	command it is running.
make the aegi_path program only report variables and what should be
	done with them.
	(actually all the code should be in libs).
have another program to convert that into a bash script and run those.

put the software_configuration dir in my home dir into other places.
finish with the /usr/bin/env patch that I did.
	(maybe even send a note to the kernel hackers).
get a new screen from old work and maybe some hardware.
print some manuals in old work.
get some downloads from old work.

0) finish the syncing in the development directory.
1) backup current change.
2) backup old projects.
3) setup a standard backup system.
4) finish the port for tsemach.
5) do the database definition for a.

do regular backups (and to the net ?).
check whats with the mail bezek were supposed to give me ?

Open Source:
fix the /usr/bin/env to pass arguments (it currently doesnt do it well...)
	Maybe I should write my own version of it ?
	Check out the source code for it...

do the aegis.vim and cook.vim files to cook and aegis files will be
highlighted.
Make all scripts use the /usr/bin/env utility (instead of hardcoding the
	interpreter).
	Improve the /usr/bin/env software in the meanwhile
compile the python stuff

Add must parameters to Opts.
Dont hardcode any defaults in base_cook_cook.pl but make those variables
	mandatory and put them in the cook initialization template.

Problem-
We have to run everything directly from cook. That is very sad cause we'd
like to do some preprocessing and postprocessing when running compilers,
linkers and cocumentation.
If we do run everything as clean scripts, then we get no host distribution,
unless, we pass the host to those scripts.
Solution-
Lets pass the host to those scripts.
Every script to do something (compile,link,generate documentation etc...).
Is this a good solution ? Maybe - I'm not sure...
Cook_frsh should do an rsh and all should be done on the remove host.
But there is a problem with crippled remotes like NT which cant do anything
by themselves... What do we do about them ?
What about if cook_frsh, in addition to the host would receive a hint about
if to execute all as rsh or continue moving it down ?
Not very clean.
Think about it.

0. do several platforms for java.
1. each platform to produce classes in its own directory (source directory
	to remain clean).
	/java/jikes
	/java/kaffe
	/java/sunja
2. generation of jar file (.jtar source files which specify which classes
	go into the jar file and the jar file gets immediately
	regenerated...).
3. do a perl class to work over jikes dependencies and produce cook like		dependencies.
4. do several platforms the way gcc/wc is done - with definitions of the
	platforms in files and a generating function.
	Activate Jikes with maximum errors turned on.

0. stop the document generation from printing out messages.
	have it put the documentation in /java/doc
1. show me generation of stuff.
2. lets see the deps files get generated.

do a general option reading module for perl.

all perl print methods should be turned to stream methods.

turn the template into XML.
use XML parsing to parse the table.
find an XML viewer so you could have nice graphic editing of this.

check that all the aegis source reporting works.

Write a text parser.
Speed up aegis change files reporting...
Do the aegis reporting line by line to speed things up...
	(or rather write an aegis report so we could pass the parameters to
	the aegis report tool ?)

Write cook level source files reporting accroding to the DMOD,DIRE and MODU
	environment variables...

Tools that we need to have:
0. graphic 2way and 3way merge tool (and directory tool ?).
1. todo graphic organizer which holds the todo file in the baseline and allows
	for merging of todo lists.
2. graphic class viewers for all kinds of languages.
3. lint tools for several languages - for C, for C++, for spec (rpmlint is
	a tool available...).

check that all the cook machine reporting works.

a bug in the shell coloring (after --help the cursor changes color).
	Did we reset the color on exit when using ANSIColor ?

check that my version of the aegis profile stuff is update and add the
	environment variables there.

make sure that every perl binary uses "Opts,System,Debug"
make sure that every perl binary ends with "Meta::Utils::System::sexo($scod);"

have aegis report on which developers there are.

make sure that no temp files are written to the development directory
	but that temp files are written (maybe in the users directory or some
	environment variable setting...).

have cook confirm each name on the list of allowed access is indeed a developer
using the previous routine.

make cook give scripts lists of files of a certain type instead of
	the scripts begin aware of the structure of the baseline.

check out the emacs aegis mode...

0. do the base_cook_colors.pl script that bothers it so much.
1. do the paths stuff to actually get the perl up and running.
2. add tests for the perl stuff and then check that all the perl stuff
	works.
3. write perl hash and list as data structures.
4. do all processing of file names for aegis in a perl script.
5. add an option for locking files and user permissions (surely fhist
	supports locks and all we need to do is use this is the baseline..?).

HTML
====
Get an html syntax checker and check that html files in HTML are ok.
	(it needs to support something like -I for looking for links...:)

Perl Checks:
============
check syntax using B::Lint.

Remember the tests:
	general tests for aegis:
		file permissions.
		file types.
		developer permissions for directories.
		extra files.
		a README.dir syntax checker.
	each languages should provide a syntax checker and convention checker.

how about doing a routine or macros to produce lists of spaces so no spaces
will be in the code ?

how about adding a check (at begining of integration) for source file
integrity ? (for instance : no " \n" in the source file, no "\t\n" in the
source files.. etc...).
	other stuff:
		"if \("
		"for \("
		"while \("
		"if \("
		"\t \t"
		" \t "
		"; "
		" ;"
		TWO SPACES
		" ;$"
		";;$"
		"\) ;"
do the same syntax checking for perl and java.

with the change which puts up watcom compiler errors to -wx also remove all
warning disabling from env/compilers/wcc.nw

do the mutable stuff for gcc.

do all the objects and check they're ok (both platforms).
do binary linking.
run all tests.
integrate

check that no object files contain symbols which are allowed for override
by the compiler. (this will be implicit instantiations, inline virtuals!@!
and others...). This will need an automatic plan and perl file for testing.
	These symbols are thrown in by the compiler with the "W" symbol in
	nm. This should be part of the post build checks.

what about a watcom dump core which appears as _watcom_.dmp sometimes ?
	should we delete this ? what about this ? can we redirect this to
	cook/comp for dumping ?

in the start of cook, make sure that the COOK variable is not!!! set if this
	is an integration build (it should not be set...).

do the error file mechanism so errors from watcom wont show up in the change
	root dir.

add to memory checking routines in the baseline:
	0. add a routine that returns the current dll name.
		It doesnt realy matter how you implement this but
		it will probably have a different implementation in gcc,
		watcom and visual. Try to find a routine in windows that
		gives you this information (and the same for gcc).
	1. print the name of the dll in different debugging functions.

add a verify heap routine to memory.nw.

do color writing in the baseline ? (using the module that can write in colors
	on terminals in perl ?).

what about making all the targets read only ?
	This is currently off because of the fix to the cook using the
	targets= mechanism. Try and bring it back in...

build first object on new wcc.

bring back the precompiled headers for wcc. Do that the following way:
	each platform and sub platform will define extra target files and
	these will be passed till they reach the base_doit level and from
	there on they will be enabled for writing at the rsh level.
	(we need this mechanism for vc precompiled headers too...).

why the fuck do we need dirs in the baseline to be suid for rnd ?
	stop that!!! (this will prevent the pc from doing any harm...).
why the fuck do we need write for the group in directories in the baseline ?
	are we nuts ? stop that.
add user checks in the baseline testing scripts.

Is there a way I could ensure that nw.d files get generated first, then
the .hh,.cc,.ii,.tt and then, at the end .hh.d,.cc.d,.ii.d,.tt.d ?

find a way so I could easily turn on and off the DATA mechanism.
	this could be done exactly like I did the perl runline...

make sure that no dirs in the baseline are up case. make a check for that.
	fix all those issues (problems with NT you know...).
	add that check to the list of checks (could be the start list).

problem with the unix rsh:
	The unix rsh returns just the error code for the last command
	executed. If you expect it to stop in the middle you are dead wrong.
	We need to take of that ourselves. A meanwhile patch could be to
	check that we only issue one command.
	A solution could be to write a wrapper that does commands one after
	the other and if one of them fails it stops. We have to make sure
	that this wrapper exists in all the unices. Maybe sh can do that with
	an option ? or rsh itself ? make sure...

do the rsh on the pc to return right error code.
start compiling on the pc.

do some data structures in perl (i.e. graph,stack and set).
	then finish the cycle inclusing removal scheme.

find an h file compressor and pass all h files through it (will reduce
	compilation time...).

make the Tk and Gtk tests in perl run again.

in cook:
	-if this is an integration check that no targets were specified
	on the command line.
	-if this is an integration then the targets for each lang
		should be "base_[lang]_targ_inte" and not the regular
		"base_[lang]_targ_allx".
		in cppx the definition could be like this:
		base_cppx_targ_inte:
			base_cppx_targ_prex
			base_cppx_targ_allx
			base_cppx_targ_post;
	-use the local feature of peter miller in parallel compilations
		in cook.
create the base_cppx_chec_prex.pl and base_cppx_chec_post.pl scripts.

remove cyclic deps.
	1. write a software to connect all nodes according to reading
		of the cc.d,hh.d,ii.d,tt.d.
	2. check for cycles.
	3. put it in post check.

bench mark current. (you'll see the dates on the last file..).
	3:16 started.
	6:59 ended.
	with no smart shell (everything is done via a shell).
	this is from scratch to all gcc (opt,dbg,prf) objects.
bench mark with smart shell (it should make a difference...).
	since currently were spawning a shell and we need not do this
	(we can split the string ourselves according to ";" and execute each
	step stopping if something goes wrong...and even more advantages are
	that if see commands that we know (perl,chmod) we can avoid running
	another process to do them (yes - we can even simulate the chmod...).
	we can handle redirection too so we wont need a mediating shell
	between us and the process...
	Is there such a package for perl ? (package that does economic shell
	execution within perl....).
bench mark with only one machine that compiles...

change the name of the GSDll.h file (its got capitals in its name...).
	check that there are no other files in the baseline with capital
	letters in their name...
remove errors and warnings of the compiler when scanning include files
	which are not ours...(this could greatly increase the amount of
	warnings we could put on our code and therefore we should try
	to implement this with disregard to the gtk problem which will also
	be solved by this...). check this with the gcc discussion group.
get gtk1.2.6 into the baseline.

get from paolo:
===============
0. good screen.
1. replicate /local/tools on all machines.
2. give me baruchs computer.
3. give me the backups of frida.
4. book about gtk.

merge the code in base_source_files,base_base_files and base_change_files.
make the smart_shell command.
build in parallel with current host.
what about the chmod which I threw out ? bring it back since with smart it
	should be ok.
make in parallel with the current host and chmod.
what about compilation errors - they should now go to different files since
	without this feature we wont be able to distinguish which errors
	are of which object file generated...

make sure that the parallel build works just on my machine.
make the parallel build work on all machines.

fix the amd maps this way:
0. the maps will mean that on each host [host] the location
	/RnD/[host] will be on the local hard drive and for every
	other host /RnD/[host] will be automounted.
1. move all /local/RnD directories to /RnD/[host] on each host [host].
2. remove the perl function unixpath in Meta::Baseline::Aegis which
	covers up this fiasco.

when cook is not silent he gives out warnings like:
	cook: warning: the ``utils/hash/obj/gcc/prf/funcs.o: env/port.hh;''
	recipe only
	appears in the derived "utils/hash/funcs.cc.d" file
	cook: If the relationship between a target and a derived
	ingredient appears
	only in a derived cookbook, it is likely that a clean
	build (solely
	from primary source files) will fail. It is
	recommended that
	relationships such as this be placed
	in a primary source cookbook.
	---Why is that ? I know we can put a flag to stop that but is that
		good ? what does peter say in the guide ?
finish the tests for the perl scripts.

Cook vim sytanx:
finish the cook syntax and check that:
	0. braces in braces.
	1. files look good.
	2. peters files look good.
	3. errors in brackets are reported.
	4. functions are blue.

reinstall all the tools cleanly.
revision of targets:
	targets are now pre,obj,lib,dll,bin

-do an onpc script which is in Meta::Baseline::Onpc.pm which runs a command
	on a pc and returns the exit code.
-do an onpc script to test the Onpc.pm module.
-do a wpp script to just call the Onpc.pm module to do its stuff.
-do a vcc script to just call the Onpc.pm module to do its stuff.
Have a good life...

This is for today:
==================
build full.
-make sure that all the unsets work and the shell stays clean.
-compile debug and make sure everything works with the new flags.
make all binaries and libs for the gcc platform.

download the new jdk from IBM.
put jdk in tools also(remmember to change meta.sh to reflect that...).
	(take the ibm 1.18 jkd).
check the new JDK and make sure everything runs ok...

========================================
do absolute path to binaries in tests.
	(as preparation to dispursing the tests throughout the baseline).
do a change to put the binaries where they belong (this is for libs as
	well as bin) and move them out of /bl/bin and /bl/lib.
suggestion - maybe do a partial build always ? (in integration also...).
	that is - if the exclusion mechanism works right...
make a restriction file on includes like this:
	utils env
	which means that files in utils can only include files
	in env...
make port_slim.hh which has the basic include files that will be the papa
	of port.hh but wont have lots of files included in it...
	make a port_string.hh file for string.h etc.. and this way avoid
	direct includes and compiler dependency in our source files...
	This way our compilations will be much faster...
make the BASE_CC_MAIN macro be faster close the 0,1,2 file handlers so people
	wont read or write from stdin,stdout,stderr (what about stdlog?)
	in any case - we can, by default, reopen them on default real
	files on the disk (with an option to turn it off in the macro
	or something)...

-check that each hh file can be compiled by itself.
	(in debug and opt ofcourse).
	(as part of a full test suite).
-remove unneeded includes in an automatic way (this is only true for C++ files).
	A file will be removed if it is unneeded for ALL architectures.
-remove loops in the include graph automatically.

write the script that takes a cook file and tree files and makes a target file.
make all target files in the system.

benchmark parallel build vs regular build (with short and long comp lists).
reach a stable conclusion about full builds regarding short and long.

work on the checks....(full check).
	foreach check:
		0. check that it works.
		1. try to make it fail and check if it fails

return the gtk stuff (do that with 1.2.5 version).

what about stopping the implicit generation of the chunks ?
	How about that the nw files will look like this:
	====start of nw.d
		utils/hash.hh utils/hash.tt utils/hash.cc : utils/hash.nw
		{
			[base_cppx_func_nwxx2chun [need] [targets]];
		}
	====end of nw.d
	Now this will enable us to extract all chunks of the code in one pass.
	We could also write a simple C program to extract all chunks and
	not just a single one (noweb doesnt know how to do that!!!!) -
	This will speed up the preparation of the chunks by quite a factor
	and will save implicit rules searches (this is an explicit rule).
	(we could remove the implicit one...).
	In any case - check for a new noweb release before going ahead
	and writing the C program to extract the chunks.

fix up the matching functions in the filelist.txt file so you could put regexp
	there.

undef all special GNU macros by finding who they are using the in the GNU
compiler -dm or something.
use the same flags in base_cppx_compile and base_cppx_preproc
(could we do the same of wcc and vcc ?).

use File::Spec to fix the ugly patch in realpath and maybe implement
	a few more routines in Meta::Utils::File::Path.
write the creation of pm.d and pl.d files in cook.
write the creation of pmc and plc files in cook.
use ExtUtils::liblist or something to create perl dependency files
	to keep doing the file checks.
	(keep a .pl.d and .pm.d files!!!).
use B::Lint for perl syntax checking.
use B::Bytecode to compile perl code to platform independant bytecode
	(faster running too because there is no initialization and there
	are no comments...).
use ExtUtils::Commands for various UNIX type commands.
	(check if im executing any unix commands and if so and they are
	in this module - use this module...).
use Safe to check perl syntax.(create a safe block and call eval on the code
	in the block or something like that...).

TAKE CARE OF PERMISSIONS ON FILES
=================================
write a routine to test permission on an entire directory.
write a routine to test permission on an entire change.
write a routine to test permission on an entire baseline.
write a script to do checking of permissions.
add the permission checking code to base_aegi_fullcheck.pl
write a routine to fix permission in a directory,change,baseline.
write a script to activate the above routine.

OPTIMIZE GENERATION OF ALL THE SMALL TEXT FILES
===============================================
maybe we could activate the nwf2nwd simultaneously too on all targets.
	(this would save loading up the perl every time...).?
	what about other scripts ?
Optimize the perl code
suck the juice out of all of that preprocess and benchmark it.

create all the target files from all the cook files using a script that you
	write.

is there any way to use the fact that gcc can compile many source
	files at once ?
	(he can do that!!! gcc -c one.cc two.cc makes one.o and two.o!!!)
	Ask peter miller maybe ?
	Check the cook manual ?
	(other processes could benefit as well - for instance - we wont have
	to load perl so much for every menial task...).

Maybe move some of the functionality to be found in perl scripts to functions
	in the cook ? this will speed things up since perl will not be in
	the loop (and hopefully the cook functions could be even faster...).
	ugliness could be hidden in cook functions instead of external perl
	scripts...

c++ compilation:
================
-what about the memory dumping analysis program johnny and michael were
	taling about ? put a good perl version of it in the baseline.
-Remove that <base/dfg> prefix to everything. change it to cppx and make a
	directory for c++ stuff.
-block the possibility of including tt files in hh files (syntax checks).
-could we use the COOK_AUTOMOUNTER flag (look in the cook documentation)
	to solve the problem with the parallel builds ?
-reduce suffixes which are produced from nw files to only: cc,hh,ii,tt

perl:
=====
-why does the perl check cant load loadable modules ?
	fix this problem and make the check pass ok.
-add more to the checks and pass syntax checks also.

-get a graphical todo list organizer for Meta baseline where the todo
	lists will be stored for all the programmers together but
	each will have access to his own todo list and the todo lists will be
	arranged in a tree according to subject - is there such a tool out
	there ? - it is essential that the data that this works over will be
	common to all - or should it be per change ? - yes it should be per
	change but we should be able to do merges on the todo list so the
	file that this holds must be textual.
	The same goes for a bug control system.

cook questions: (ask peter...)
==============================
was setting "set no-include-cooked-warning" the right thing to do ?
what is this no-cascade stuff ? find out from the documentation...
	did we do the right thing in using it in the cppx module ?
Did we do the right thing to use #include-cooked-nowarn in our cppx.cook
	file ?
how can I set no write permission on all intermediate files ?
	is there a way to do that from inside cook ?
	ask that of peter... If there is then use it and remove
	the code that does the same thing in the perl files.
Should we or shouldnt we keep the dependance of rules in the cook on the
	scripts doing the work for long ?
	on the upside - people who change the scripts in their changes
		get the correct files remade.
	on the downside - people who change the tool doing the actual
		work in the script (some binary that the script uses)
		dont get that same effect altough it is due since the
		dependencies are not well kept for the scripts (not kept
		at all that is).
	on the upside - even in the previous turn of events a user can just
		pull the script into his change, touch it and he gets
		the same effect. Interesting.
mail to peter miller about the character that c_incl uses in between dependencies - he has an option for the prefix and postfix but no option for the infix. Shouldnt he add one ? currently the infix is a newline...

C++ code:
=========
-maybe we should bring over a c pretty pretfier and pretify all C code in the
-maybe we should bring over a c code stripper. This is a software that strips
	the C++ code from everything. We could use it to strip the c++ and
	h files before we give them to the compiler and get better compilation
	times...
same way every time a c file is written....

Add to perl syntax checking capabilities:
=========================================
	1. every perl executable uses Opts
	2. Opts::desc() is same as description for program.
	3. Opts::auth() is same as AUTHOR.
	4. Opts::standard() is used.
	5. name of script in SYNOPSIS and NAME clauses in the documentation
		match the name of the actual file.

	for perl modules:
		check that there is only one module in every ".pm" file and
		it's name is the same as the files name.

Perl:
=====
-add the following tests on all the perl sources:
	eval test
	syntax tests:
		first line test
		use strict test
		use diagnostics test
		use debug test
		EXPORT_OK is used and not EXPORT
	documentation tests
		all paragraphs there in the correct order
		all items are bold
-fix the File::PathConvert manual page problem.
-check that autodocumentation in perl works.

Cook:
=====
-add an option to remove dependency of target on dates of scripts into
	the cookfiles (meaning some flag you light on and off).
-check that aegis gets the right code from cook regarding success or
	failure of compilation...

Perl:
=====
-write correct SYNOPSIS clause in all the perl scripts.
-do all the perl documentation correctly.
-write a perl script to validate that correct perl documentation is applied
	within a module or a perl script.

bring over gtk++.
do tests in the baseline:
	base_helloworld
	base_hellogtk
	base_hellgtk++

get the documentation of gtk+ (in the docs directory of the distribution)
	into the baseline.

cppx:
=====
-should we limit executable files in the baseline to have an exe extension ?
-what about qt ? or a c wrapper in qt ? is qt portable to windows ?

what about a mapping (gis information display) widget for gtk or gtk++ ?
	can we get something like that somewhere ?
	can we write a mockup ?

when I have a double target in cook I use the patterns I matched in order
	to specify the targets - isnt there a mechanism in cook
	to support this ? ([target1] [target2] for instance ?).

At the end of the change:
=========================
1. send documents to all developers.
2. prepare to give them all new dot files.

The integration phase:
======================
1. remove aegis.profile from all machines.
2. remove cook from all machines (so noone will use the old cook).
3. remove noweb from all machine.
4. remove nohtml from all machines.
5. if aegis was inserted into the baseline remove aegis from all machines.

start implementing the following table in some text file so we could use
it in scripts:
========================================================================
nw source /cppx/base read
nw.d intermediate /cppx/base read
cc.d intermediate /cppx/base read
hh.d intermediate /cppx/base read
tt.d intermediate /cppx/base read
ii.d intermediate /cppx/base read
cc intermediate /cppx/base read
hh intermediate /cppx/base read
tt intermediate /cppx/base read
ii intermediate /cppx/base read
exe target /cppx/base execute

java source /java/lib/meta
class target /java/lib/meta
html target /java/lib/meta

cook source /cook
aegis source /aegis
rc source /rc
sh source /sh

pl source /perl/bin/Meta
pm source /perl/lib/Meta

any ----- /tool
any ----- /cppx/import
any ----- /java/import
any ----- /perl/import

What about having a memory protection mechanism like efence or GNUmalloc
or something ?

Perl:
====
How about us not writing the actual pm's but having the make do the pm's
	so the pms will be small ?

find out how to use the strict through debug (and do the same for diagnostics).
	the way we do it today is just to say explicitly in every library
	use strict qw(vars refs subs);
	use diagnostics;
	#use Meta::Utils::Debug qw();

	why should that be so ?

	I just want to say:
	use Meta::Utils::Debug qw();

	and that will look at the env var "BASE_PERL_DEBUG" and include
	strict and diagnostics if neccessary. Actually the code to do
	it is already in Meta::Utils::Debug but its not working
	because the scope of strict and diagnostics is the block they
	are in and this does not effect the package that uses them...
	(it does work for perl script and not packages though...)
	How can we do that ?
	Should we send an email to one of the perl guys or something ?

Perl:
=====
-use more qw(this should make compilation and running a little bit smaller...)
-speed up loading of packages even more with autosplit.
-figure out what to do about debugging - currently we have a problem with
	that in that every source:
	use strict qw(vars refs subs);
	#use diagnositcs;.
	etc..
	we want to have a common line and that line will do all thats
		needed in Meta (and even different things in debug
		and release modes).

Vi configuration for the baseline:
==================================
1. ask the author of vim to have an option to give vi default arguments from
	the environment (VIM_OPTS or something...).
2. ask the author of vim to have an option for vim to not have the vi swap
	file in the same directory of the file that you are editing but
	in a directory set by an option.
3. for all users set the VIM_OPTS to something like VIM_OPTS="--swapdir=/local/RnD/tmp"
4. how about setting up a vi mode for c++ and noweb so people here would
	have nice coloring for syntax in c++ files.
5. how about vim perl mode for perl syntax highlighting.

Meta (in the tools section):
============================
-remove the realpath binary of Meta.
	(check that its not used anywhere).

perl:
=====
-do a restore change script to restore a change from a change backup.tar.gz
-do a shell script that checks that file permissions (as far as execution
goes) are ok within a directory, reports problems and can also fix.
remove the problem that the PATH variable is pointing to perl/bin/baseline
and not to perl/bin (how should this be solved ?)
check that regular expressions that we receive in base_tool_grep_edit.pl are
	valid using the method described in the perl cookbook.
add perl gtk into the baseline with a test program.

java standard stuff:
====================
put opemmap in the java import lib.
do our own demo using the openmap interface.
make sure that cook works right with java.
check with ofir to see if im doing the java the right way.
check with ofir about java documentation and autogeneration
	using javadoc.
add java rules to create a java jar (for the entire meta directory)
	file called meta.jar.
fixup the HelloAwt example to exit on push of the button.
leave no stone unturned in the base_profile
what about the man path ? shouldnt we change that also to point
	to our man directories ?
wrap the perlpod with our wrapper.
do a script to show all machines which are available in Meta.
all base_*.pl that have something to do with aegis should be named:
	base_aegi_*.pl
rewrite ipass_notify as shell script

make everything in the perl dir compile
make the base_perl_check*.pl work right (actually activate the perl
	interpreter right...:)
split the Utils lib into list,hash etc...
split the base_*.pl scripts into tools, perl, java etc...
document all the base_*.pl scripts properly using pod.
check that all scripts work.
start using the better prototyping facilities in perl

now check the java compilation from a non baseline position.
get a java classpath here (install a compiler or something...).

check how to do that each perl file will only need to use Meta::Utils::Utils
and it will get the strict and diagnostics with it as a payment...:)

0. resolve the issue of module dependency in perl.
	How can make sure that when I use a library I will also make
	available the libraries it is using ?
1. start using the perl library extensivly.
2. try to call C directly and use the realpath stuff.
3. use File::Find more.
4. start using the perl way of doing comments.
5. call realpath from C and not using external execution.
6. do the master template file well (aegis/templates/master/master.aegis).
7. should we make a link and a directory for each changes data upon creating
	like data -> /local/RnD/tmp/2data or something ? will that
	be good for keeping the people from clobbering the change
	directory with data files ?
8. move all the opt files to their own directory.

what about the nohtmlm package that I did back then ?
	did it have any extras regarding these issues ?
	check that with paolo.

two major issues:
1. the funny files names (do basename(fiel) instead...).
2. what about the damned include files in the compilation of the imported
	libraries.

tree2 and tree3 distinctions do not work

add another script to compare tree reported sources and aegis reported ones.

in utils.pm:
	base_realpath - to access the C function directly.
	or better yet - a native perl implementation ?

can we get ridd of that shit?!?
its only 86 occurances in the enitre 1500 file baseline - is it realy
worth saving for more problems in dependency checking ?
		(I checked it using base_vinw "" "@import")
		If indeed we can remove it we can simplify the base_nw2dep script.

remove all the chmod's that are done in Howto.cook (what the fuck do we need
	them for ? is it a cook,aegis or our problem ? why the fuck should
	that make our Howto longer ?).

How about storing the cook itself in the baseline ?
(yeah with all the man pages and the whole shebang...).
Check the devinstall file and check which stuff could be moved into
the baseline...

store open map in java import.
what about changing the MANPATH ?

base_will should clean the the target it the build does not make it.
base_will should create the target directory if it does not exist.

make a hello world test program in perl using text,tk,gtk.
make a hello world test program in java using text,awt,swing,gtk.
use javadoc and produce docs.
make it using java jar files in the baseline.
put the java jdk in the baseline (actually - put several of those...).

unite all cook fiels to one coherent cook structure.

get an automatic source documentation softwares here:
	one for html autoproduction.
	one for gui class browsing.
stop the error with the nw2dep.
make it linking the compression stuff.
stop using the stupid Dep files.enough! no more tree2deps.
get rid of the criptic file names in aegis. put every obj near its source
	with _cmp_flg attached.

put all the development stuff in another file than .bashrc.
add the fact that if aegis plants a file to be removed it will be executable
	actual do a full script to fixup all removed files -
	replace the removed files with the standard template
	and also make sure it is executable.
and its execution will print a warning and still make it have all the
garbadge that the remove file now has.
stop using the environment to pass the TODO var around so that base_will
 will know where to write the commands to be executed.
make tools have real sources (.nw files) and not a cc file and a Makefile.

-5) fix the report mechanism to get good source files reports.
	(or add a report of our own inside the baseline ?).
-6) do a new distribution of aegis with that report in it.
-7) fix up my sources script to use those.
-8) do the cmp_lists script of orens in perl.

-3) ask paolo to restore my 327 change on klein.
-2) write the strict cleanup script.
	The script should be written in perl.
	It should do the following.
	1. go from the current directory
		and recusivly check each file to check if its in the change
		or not and if it isnt remove it.

0) come on - do that 2d compressor.
	problems - what is pixmap made of
	(we want to make it easy to compress).
	settle that with what libjpeg wants for compression.
1) lets do a routine to write back all the definitions in the right
	 style. (write dbdefs files back).
2) start working on the database initialization templates.
3) make the database using mysql.
4) start doing the oo wrapper around dbic.
5) make an option where the entire database definition is in a single file.
6) maybe the best place for aegis.profile is in the aegis directory.
7) add more sophisticated file templates substitutions (I mean the files
	in bl/aegis/templates/[cook nw tcl...]
	to make better initial files for the guys.

do a check_suffixes script to check that suffixes are ok in a change,
baseline or sources.
	(this script will not consult removed files ofcourse...).

possible optimizations:
	1. run things together (why do each dep file seperately ?)
	2. stop checking nwd files all together except when explicitly
		asked by the user.

remove the builtin includes that are built in the gcc and wc compile scripts.
our perl libs are coming up very slow. Make them go faster...
make notangle of our own to do the noweb chunks -
	this will take care of the nobs problem (no back slash).
	we could also take out comments in the problem.

make the cleanup via the cook book clean empty directories after cleanup
	also.

Dbi stuff:
==========
0) do we need any fields to be enums ? (that type is supported by sql...)
1) make the dbi class virtual and make it in /inst/tb
2) move all dbi files into dbi/inst/tb/
3) efficiency in the text parsing.
4) efficiency in the binary parsing.
5) will you start writing the varying fields in binary format or what ?
6) do the parsing more efficient (just look ahead for the next tab or newline).
7) do the optimization of the data storing using one single flat array.
8) make the binary hold only the non variable fields (this way the binaries.
	will be smaller).
	Here is another idea -
		In order to read the flat dbi binary file all at once why
		not store to record sets - one for varying fields and one
		for non varying.
9) try to read a full fleged database.
10) actually insert the fkey (check that their are pointing to uniques).
11) maybe all the dynamic data of a record should be in one file and
	not in several ? consider doing it thus.
12) get to a status of reading the database in text, writing in binary
	and converting back to text with no differences.
13) new type multipoll which is a lot of pollilines and a lot of polygons.
14) do we need a recreate method in dbi ? - yes
15) How about wrapping up the dbic with classes of our own so the
engine people will have more fun ?
16) dbiinsert - receives a dbi (with any driver) and inserts a set of
	text tables into it.
17) each database should provide the param filler with ist set of demands.

String stuff:
=============
0) do look ahead routine(like strtok) for strings.
1) implement a correct input routine for the string.
2) make sure the string has no magic numbers in it.
3) make the memory management stuff work.
4) make the substring class and make the split work with the substring class.
5) add many more routines.

Baseline:
=========
4) examine the output of compiling a single small object file using nm -C on
	a linux machine. Why are all those stuff there (from port.hh probably).
	do we need them all ?
9) what about bringing in a source browser like cygnus has - to read the
entire baseline and provide visual browsing of all the sources.
10) in cook:
	enable user to set more parms:
	on which platforms will this be compiled
	do I need to pass tests. etc...
11) remove that stuipd gcc.hh and wc.hh includes from the actual compiler
	directive?!? what is that ?!?
12) organize the cook file more.
13) fix the problem that shells are not copied with the right permissions
	(aecp does not pay attention to permissions).
14) fix the problem that the baseline allows an integration to pass through
	and leaves the nw files with "x" (running) permissions.
	the baseline should pass over the files and fix the permissions
	according to the type of file.
15) add a flag to aeb to remake the entire target recusivly
	(so people will not have to erase the object by hand when
	all they want is to repeat the process of make).
16) add versioning on the libs in the baseline.
17) remove the damn name mangling.
18) what is this business about a name not allowed to be more than 11 chars
	long for a filename ? whats all this business ? heads will fly...
19) cleanup the shell directory and write better scripts there.
20) cross compilation to NT ? (cygnus claim its possible).
21) remote compilation on NT using the cygnus compiler...
22) the compiler has nostdincl switch to turn off standard includes - use
	it so users wouldnt be able to use the C standard libs.
23) a push baseline script.

code:
=====
-add routine in arrays that does a set min.
-does the factory hold a hash table ?
	add an option for it...
-the Delete macro in the baseline should not have the second argument
	due to the virtual objects that are possible.

Perl:
=====
-document all our perl scripts more.
-whenever a shell in the baseline uses backticks to execute something,
	check if that execution suceeded (using something to do with
	backticks) becuase right now there is no such check.

Features for cook:
=================
How about a "set nowrite" flag for receipes and cook will make sure that
after creation of the targets they are not writable ?
How about a variable called [host] in cook to be available during receipes
so we could print out the host on which the current receipe is being
performed ?
How about a modifier like thread numb for each receipe and not just for the
entire cookbook ? different tasks on different groups of machines should be
different in the respect of how many concurrent processes it is sensible to
run...

00) build a collection of favorites and put it in my env.
01) move it so no software will be in the root.
02) create shortcuts for all ini,log+hlp,doc,wri,htm,txt,pdf,rtf and executable files.
	check that the numbers are ok.
03) download a unix2dos and dos2unix utility and put it's install instructions
	in the install file.
04) get some graphic viewing utility (you dont want to install photoshop just to watch
	a jpg file do you ?).
04) translate jeffs call drop into dos format.
05) remove unneeded software from my machine.
06) download LHA and ARC and a unix set of command line tools.
07) format all my zips to NTFS.
08) get a version of MapInfo proffesional (both on my computer and as install package).
09) down load stuff from the iomega site for the zip drive.
10) mail iomega.com that they have a problem with their software - it cannot be installed
	in directories that have a space in them.
11) mail 4nt and tell them the same thing as before.
12) install windows explorer 4.01 and get its favorites into my env directory and back them
	up.
13) check that I backed up all my env stuff.
14) get the todo list into outlook.
15) get all text files into outlook.
16) set up outlook the way I like it and register all changes made.
17) set up my own account on this machine and make the administrators general.
	and not specific to me.
18) get a hint from mapinfo about the right way to put the rasters.
20) reinstall the devstudio since yuval is registered as the owner.
21) reinstall office since yuval is the owner.
22) check how can we port the entire profile and not just shortcuts
	and favorites the way I do it now.
23) check that the entire shortcut directory is made up of
	"shortcut to actualfile.something" entries.

17) get from meir a functioin for intermodulation of frequencies and ask
	a to put it in the planner.
18) put the adobe and the iomega zip software on burned CD's.
19) How to get all the default shortcuts (My Computer,Network neighborhood,recycle bin)
		off my desktop (I can supply my own versions of those) -
		and this includes especially the pesty inbox shortcut for
		msmail.
20) find out with paolo why do things that are running in the background on the start bar
	keep disappearing (like the sound control. why do they do that ?
21) ask paolo how do I make the wheel on the mouse work ? (it doesnt seem to be working
	when I just use it).

1) finish reading the samuelson(comopt) old book.
6) organize the todo files.
7) do all the small stuff on them.
removal of clock from the task bar.
the laptop seems to say that some event is wrong when it boots - check what the problem
	is and fix it.
adding the registration info to the winzip application.
get new batteries for the palm
sync the palm
move the env to the laptop
start working with the java env.
get a hair cut
get the java CD from david
return the video cassette
add the idea that handoffs within sites should not be hard constraints but softones
	(two sectors in a system facing the sea could in principle be assigned the same
	channel).
get from paolo:
	1) cracker for the laura crauft game
	2) universal boot.
when installing iomega remmember to remove their service if you dont use it all the time
	from the devices list (ppa3nt).
add an entry about making a backup hardware configuration of the original,
	and always storing the current and experimental one.
add an entry about the installtion of the ibm java software (that neeeded a boot)
	and about the services (http server) that it starts automatically and about
	its license insertion.
add an entry about the installation of a disk defragmenter.
add an entry about a page file setting as soon as possible with a constant size.
add some thinking about the problem in johachims book about channels in their own band
	according to the order of their appearance -does this not tie the channel
	assignment problem with the channel sequencing problem ?
	How can this be correctly shown in the database ?
	could we handle this problem in a clean way ?
add the fact that the best startup time for nt in the first menu it shows in text mode
	is 2 seconds (not to wait long usually and still to enable change in an emergency).
add changing the configuration time to 2 seconds also.
need to buy in america another CD case and a palm III.0) get my cd box out of the equipment closet and fix the cd's on my desk.
1) get a good opening page for the login in my machine so people wont know this
	is a server.
2) hook up the tape to my machine.
3) organize the laptop that adam brought with all the cd's.
4) check how to remove the all the icons from my desktop.
	(especially the ones which are not shortcuts...)
5) disable everything in the system tray.
6) put some of my stuff on cd's.get all the code out of the scripts and into the libs (perl).

start doing more of the checks (start getting them organized...).

how about adding a check (at begining of integration) for source file
integrity ? (for instance : no " \n" in the source file, no "\t\n" in the
source files.. etc...).
	other stuff:
		"if \("
		"for \("
		"while \("
		"if \("
		"\t \t"
		" \t "
		"; "
		" ;"
		TWO SPACES
		" ;$"
		";;$"
		"\) ;"
do the same syntax checking for perl and java.

with the change which puts up watcom compiler errors to -wx also remove all
warning disabling from env/compilers/wcc.nw

do all the objects and check they're ok (both platforms).
do binary linking.
run all tests.
integrate

check that no object files contain symbols which are allowed for override
by the compiler. (this will be implicit instantiations, inline virtuals!@!
and others...). This will need an automatic plan and perl file for testing.
	These symbols are thrown in by the compiler with the "W" symbol in
	nm. This should be part of the post build checks.

list of changes to be done:
0. change to move all upper case dirs and files in baseline to lower case.
1. mark the following as a change to be done:
	make sure that watcom uses all warnings possible. the setting for that is
		-wx. (-we is treat warnings as errors and we are using that one...).
		we are currently using -w8. Is that the same ? if it is why are
		we not using the maximum by default ? (-wx?).
		move to using -wx and fix problems if any arise.

remove all static declarations and the same goes for extern.

add to memory checking routines in the baseline:
	0. add a routine that returns the current dll name.
		It doesnt realy matter how you implement this but
		it will probably have a different implementation in gcc,
		watcom and visual. Try to find a routine in windows that
		gives you this information (and the same for gcc).
	1. print the name of the dll in different debugging functions.

add a verify heap routine to memory.nw.

do color writing in the baseline ? (using the module that can write in colors
	on terminals in perl ?).

what about making all the targets read only ?
	This is currently off because of the fix to the cook using the
	targets= mechanism. Try and bring it back in...

build first object on new wcc.

bring back the precompiled headers for wcc. Do that the following way:
	each platform and sub platform will define extra target files and
	these will be passed till they reach the scm_doit level and from
	there on they will be enabled for writing at the rsh level.
	(we need this mechanism for vc precompiled headers too...).

why the fuck do we need dirs in the baseline to be suid for rnd ?
	stop that!!! (this will prevent the pc from doing any harm...).
why the fuck do we need write for the group in directories in the baseline ?
	are we nuts ? stop that.
add user checks in the baseline testing scripts.

On all compilations redirect the errors into the appropriate files.

Why doesnt building a single file work ? make it work....

Is there a way I could ensure that nw.d files get generated first, then
the .hh,.cc,.ii,.tt and then, at the end .hh.d,.cc.d,.ii.d,.tt.d ?

find a way so I could easily turn on and off the DATA mechanism.
	this could be done exactly like I did the perl runline...

make sure that no dirs in the baseline are up case. make a check for that.
	fix all those issues (problems with NT you know...).
	add that check to the list of checks (could be the start list).

problem with the unix rsh:
	The unix rsh returns just the error code for the last command
	executed. If you expect it to stop in the middle you are dead wrong.
	We need to take of that ourselves. A meanwhile patch could be to
	check that we only issue one command.
	A solution could be to write a wrapper that does commands one after
	the other and if one of them fails it stops. We have to make sure
	that this wrapper exists in all the unices. Maybe sh can do that with
	an option ? or rsh itself ? make sure...

do some data structures in perl (i.e. graph,stack and set).
	then finish the cycle inclusing removal scheme.

in cook:
	-if this is an integration check that no targets were specified
	on the command line.
	-if this is an integration then the targets for each lang
		should be "scm_[lang]_targ_inte" and not the regular
		"scm_[lang]_targ_allx".
		in cppx the definition could be like this:
		scm_cppx_targ_inte:
			scm_cppx_targ_prex
			scm_cppx_targ_allx
			scm_cppx_targ_post;
	-use the local feature of peter miller in parallel compilations
		in cook.
create the scm_cppx_chec_prex.pl and scm_cppx_chec_post.pl scripts.

remove cyclic deps.
	1. write a software to connect all nodes according to reading
		of the cc.d,hh.d,ii.d,tt.d.
	2. check for cycles.
	3. put it in post check.

bench mark with smart shell (it should make a difference...).
	since currently were spawning a shell and we need not do this
	(we can split the string ourselves according to ";" and execute each
	step stopping if something goes wrong...and even more advantages are
	that if see commands that we know (perl,chmod) we can avoid running
	another process to do them (yes - we can even simulate the chmod...).
	we can handle redirection too so we wont need a mediating shell
	between us and the process...
	Is there such a package for perl ? (package that does economic shell
	execution within perl....).
bench mark with only one machine that compiles...

remove errors and warnings of the compiler when scanning include files
	which are not ours...(this could greatly increase the amount of
	warnings we could put on our code and therefore we should try
	to implement this with disregard to the gtk problem which will also
	be solved by this...). check this with the gcc discussion group.

merge the code in scm_source_files,scm_base_files and scm_change_files.
make the smart_shell command.
build in parallel with current host.
what about the chmod which I threw out ? bring it back since with smart it
	should be ok.
make in parallel with the current host and chmod.
what about compilation errors - they should now go to different files since
	without this feature we wont be able to distinguish which errors
	are of which object file generated...

when cook is not silent he gives out warnings like:
	cook: warning: the ``utils/hash/obj/gcc/prf/funcs.o: env/port.hh;''
	recipe only
	appears in the derived "utils/hash/funcs.cc.d" file
	cook: If the relationship between a target and a derived
	ingredient appears
	only in a derived cookbook, it is likely that a clean
	build (solely
	from primary source files) will fail. It is
	recommended that
	relationships such as this be placed
	in a primary source cookbook.
	---Why is that ? I know we can put a flag to stop that but is that
		good ? what does peter say in the guide ?
finish the tests for the perl scripts.

-do an onpc script which is in Schema::Baseline::Onpc.pm which runs a command
	on a pc and returns the exit code.
-do an onpc script to test the Onpc.pm module.
-do a wpp script to just call the Onpc.pm module to do its stuff.
-do a vcc script to just call the Onpc.pm module to do its stuff.
Have a good life...

do absolute path to binaries in tests.
	(as preparation to dispursing the tests throughout the baseline).
do a change to put the binaries where they belong (this is for libs as
	well as bin) and move them out of /bl/bin and /bl/lib.
suggestion - maybe do a partial build always ? (in integration also...).
	that is - if the exclusion mechanism works right...
make port_slim.hh which has the basic include files that will be the papa
	of port.hh but wont have lots of files included in it...
	make a port_string.hh file for string.h etc.. and this way avoid
	direct includes and compiler dependency in our source files...
	This way our compilations will be much faster...
make the SCM_CC_MAIN macro be faster close the 0,1,2 file handlers so people
	wont read or write from stdin,stdout,stderr (what about stdlog?)
	in any case - we can, by default, reopen them on default real
	files on the disk (with an option to turn it off in the macro
	or something)...

only use set mkdir in the rules that we need to use it.
	(objects and binaries and no others - we do not need to
	create dirs for the derived files (of all types) because they
	are all derived from the ".nw" files and they already are in
	the change. Add an option to force mkdir on all (like now)
	This is useful for when chaging the derivation scripts).

do scm_doit in cook code and check if its better.... - first opt.
do some more perls in cook code and check if its better - second opt.
check if fingerprints is realy faster or not!!!

cook:
=====
Ideas about deps. Once cook knows what the source files are (derived from
the nw.d files), give them to a perl script. The script will return a list
of h files that need to be in the graph - think about it since the idea
still needs work...

cppx:
=====
-check what are the deps for the basic files (port,gcc,wcc).
	If that ok ? what about performance ?
-when using these flags to GCC
	gcc -c -o temp.o temp.cc -E -dM
	you get a lot of intermediate files from the compilation process.
	Could be that some of them contain symbols that we could read,
	find connection and who's using who for real (not h file junk)
	etc... Maybe we could use that somehow ?
-We got a bug with c_incl that if we didnt put the the "scm" in
	"#include <scm/utils/hash.hh>" the c_incl (and our wrapper)
	produced an absolute path in the "nw.d" files.
	This is quite strange when you consider the fact that there
	is an explicit flag for c_incl not to give out full paths
	in the output.check how come we got this strange bug -
	how do we activate c_incl ?
	why should it pour out absolute paths at all ? how does this work ?
	thoughts on this subject - now that c_incl is a little cleaner -
	why does it emit direct absolute includes ? check this out
	with a little sample...
	In any case we need to prohibit doing includes without the "scm"
	prefix...
-check that each hh file can be compiled by itself.
	(in debug and opt ofcourse).
	(as part of a full test suite).
-remove unneeded includes in an automatic way.
-remove loops in the include graph.
-check if include port.hh doesnt blow objects up in size.

take care of error messages in the scripts and in the perl libs.
	pour them out using our own routine to some determined place
	(either STDOUT or STDERR - but make it controllable from one
	location...).

work on the checks....(full check).
	foreach check:
		0. check that it works.
		1. try to make it fail and check if it fails

what about stopping the implicit generation of the chunks ?
	How about that the nw files will look like this:
	====start of nw.d
		utils/hash.hh utils/hash.tt utils/hash.cc : utils/hash.nw
		{
			[scm_cppx_func_nwxx2chun [need] [targets]];
		}
	====end of nw.d
	Now this will enable us to extract all chunks of the code in one pass.
	We could also write a simple C program to extract all chunks and
	not just a single one (noweb doesnt know how to do that!!!!) -
	This will speed up the preparation of the chunks by quite a factor
	and will save implicit rules searches (this is an explicit rule).
	(we could remove the implicit one...).
	In any case - check for a new noweb release before going ahead
	and writing the C program to extract the chunks.

Copy Baseline to the NT machines too and fix the problems there
	with the include so we will take advantage of it...

take care of File::Find (eliminate it whereever not neccessary...).

fix up the matching functions in the filelist.txt file so you could put regexp
	there.
finish the cleanup --safe so it would be ok.

write a perl script to save all environment in a file.
use it in schema.sh to make it much more readable (notice that there could be
many development sessions so you have to save the file to ~/.schema.env.[pid] orsomething.

undef all special GNU macros by finding who they are using the in the GNU
compiler -dm or something.
use the same flags in scm_cppx_compile and scm_cppx_preproc
(could we do the same of wcc and vcc ?).

use File::Spec to fix the ugly patch in realpath and maybe implement
	a few more routines in Schema::Utils::File::Path.
write the creation of pm.d and pl.d files in cook.
write the creation of pmc and plc files in cook.
use ExtUtils::liblist or something to create perl dependency files
	to keep doing the file checks.
	(keep a .pl.d and .pm.d files!!!).
use B::Lint for perl syntax checking.
use B::Bytecode to compile perl code to platform independant bytecode
	(faster running too because there is no initialization and there
	are no comments...).
use ExtUtils::Commands for various UNIX type commands.
	(check if im executing any unix commands and if so and they are
	in this module - use this module...).
use Safe to check perl syntax.(create a safe block and call eval on the code
	in the block or something like that...).

TAKE CARE OF PERMISSIONS ON FILES
=================================
write a routine to test permission on an entire directory.
write a routine to test permission on an entire change.
write a routine to test permission on an entire baseline.
write a script to do checking of permissions.
add the permission checking code to scm_aegis_fullcheck.pl
write a routine to fix permission in a directory,change,baseline.
write a script to activate the above routine.

OPTIMIZE GENERATION OF ALL THE SMALL TEXT FILES
===============================================
maybe we could activate the nwf2nwd simultaneously too on all targets.
	(this would save loading up the perl every time...).?
	what about other scripts ?
Optimize the perl code
suck the juice out of all of that preprocess and benchmark it.

create all the target files from all the cook files using a script that you
	write.

is there any way to use the fact that gcc can compile many source
	files at once ?
	(he can do that!!! gcc -c one.cc two.cc makes one.o and two.o!!!)
	Ask peter miller maybe ?
	Check the cook manual ?
	(other processes could benefit as well - for instance - we wont have
	to load perl so much for every menial task...).

Maybe move some of the functionality to be found in perl scripts to functions
	in the cook ? this will speed things up since perl will not be in
	the loop (and hopefully the cook functions could be even faster...).
	ugliness could be hidden in cook functions instead of external perl
	scripts...

c++ compilation:
================
-Remove that <scm/dfg> prefix to everything. change it to cppx and make a
	directory for c++ stuff.
-block the possibility of including tt files in hh files (syntax checks).
-could we use the COOK_AUTOMOUNTER flag (look in the cook documentation)
	to solve the problem with the parallel builds ?
-reduce suffixes which are produced from nw files to only: cc,hh,ii,tt

perl:
=====
-why does the perl check cant load loadable modules ?
	fix this problem and make the check pass ok.
-add more to the checks and pass syntax checks also.

-get a graphical todo list organizer for schema baseline where the todo
	lists will be stored for all the programmers together but
	each will have access to his own todo list and the todo lists will be
	arranged in a tree according to subject - is there such a tool out
	there ? - it is essential that the data that this works over will be
	common to all - or should it be per change ? - yes it should be per
	change but we should be able to do merges on the todo list so the
	file that this holds must be textual.
	The same goes for a bug control system.

cook questions: (ask peter...)
==============================
was setting "set no-include-cooked-warning" the right thing to do ?
what is this no-cascade stuff ? find out from the documentation...
	did we do the right thing in using it in the cppx module ?
Did we do the right thing to use #include-cooked-nowarn in our cppx.cook
	file ?
how can I set no write permission on all intermediate files ?
	is there a way to do that from inside cook ?
	ask that of peter... If there is then use it and remove
	the code that does the same thing in the perl files.
Should we or shouldnt we keep the dependance of rules in the cook on the
	scripts doing the work for long ?
	on the upside - people who change the scripts in their changes
		get the correct files remade.
	on the downside - people who change the tool doing the actual
		work in the script (some binary that the script uses)
		dont get that same effect altough it is due since the
		dependencies are not well kept for the scripts (not kept
		at all that is).
	on the upside - even in the previous turn of events a user can just
		pull the script into his change, touch it and he gets
		the same effect. Interesting.
mail to peter miller about the character that c_incl uses in between dependencies - he has an option for the prefix and postfix but no option for the infix. Shouldnt he add one ? currently the infix is a newline...

Add to perl syntax checking capabilities:
=========================================
	1. every perl executable uses Opts
	2. Opts::desc() is same as description for program.
	3. Opts::auth() is same as AUTHOR.
	4. Opts::standard() is used.
	5. name of script in SYNOPSIS and NAME clauses in the documentation
		match the name of the actual file.

	for perl modules:
		check that there is only one module in every ".pm" file and
		it's name is the same as the files name.

Perl:
=====
-add the following tests on all the perl sources:
	eval test
	syntax tests:
		first line test
		use strict test
		use diagnostics test
		use debug test
		EXPORT_OK is used and not EXPORT
	documentation tests
		all paragraphs there in the correct order
		all items are bold
-fix the File::PathConvert manual page problem.
-check that autodocumentation in perl works.

Cook:
=====
-add an option to remove dependency of target on dates of scripts into
	the cookfiles (meaning some flag you light on and off).
-check that aegis gets the right code from cook regarding success or
	failure of compilation...

Perl:
=====
-write correct SYNOPSIS clause in all the perl scripts.
-do all the perl documentation correctly.
-write a perl script to validate that correct perl documentation is applied
	within a module or a perl script.

do tests in the baseline for gtk++:

get the documentation of gtk+ (in the docs directory of the distribution)
	into the baseline.

cppx:
=====
-should we limit executable files in the baseline to have an exe extension ?
-what about qt ? or a c wrapper in qt ? is qt portable to windows ?

what about a mapping (gis information display) widget for gtk or gtk++ ?
	can we get something like that somewhere ?
	can we write a mockup ?

use the fhist module in the aegis config file.

add an option to scm_aegis_backup to use bzip and not gzip.

when I have a double target in cook I use the patterns I matched in order
	to specify the targets - isnt there a mechanism in cook
	to support this ? ([target1] [target2] for instance ?).

At the end of the change:
=========================
1. send documents to all developers.
2. prepare to give them all new dot files.

The integration phase:
======================
1. remove aegis.profile from all machines.
2. remove cook from all machines (so noone will use the old cook).
3. remove noweb from all machine.
4. remove nohtml from all machines.
5. if aegis was inserted into the baseline remove aegis from all machines.

start implementing the following table in some text file so we could use
it in scripts:
========================================================================
nw source /cppx/scm read
nw.d intermediate /cppx/scm read
cc.d intermediate /cppx/scm read
hh.d intermediate /cppx/scm read
tt.d intermediate /cppx/scm read
ii.d intermediate /cppx/scm read
cc intermediate /cppx/scm read
hh intermediate /cppx/scm read
tt intermediate /cppx/scm read
ii intermediate /cppx/scm read
exe target /cppx/scm execute

java source /java/lib/schema
class target /java/lib/schema
html target /java/lib/schema

cook source /cook
aegis source /aegis
rc source /rc
sh source /sh

pl source /perl/bin/Schema
pm source /perl/lib/Schema

any ----- /tool
any ----- /cppx/import
any ----- /java/import
any ----- /perl/import

What about having a memory protection mechanism like efence or GNUmalloc
or something ?

How about us not writing the actual pm's but having the make do the pm's
	so the pms will be small ?

Vi configuration for the baseline:
==================================
1. ask the author of vim to have an option to give vi default arguments from
	the environment (VIM_OPTS or something...).
2. ask the author of vim to have an option for vim to not have the vi swap
	file in the same directory of the file that you are editing but
	in a directory set by an option.
3. for all users set the VIM_OPTS to something like VIM_OPTS="--swapdir=/local/RnD/tmp"
4. how about setting up a vi mode for c++ and noweb so people here would
	have nice coloring for syntax in c++ files.
5. how about vim perl mode for perl syntax highlighting.

perl:
=====
scm_progname could perhaps remove the ".pl" extension.
fixup scm_aegis_remove_files_remove to do the purge right...
	(dont call purge at the end but rather each time you
	remove a file go up a dir and check if you can remove that...).
- do a shell script that checks that file permissions (as far as execution
goes) are ok within a directory, reports problems and can also fix.

do a shell script that checks that file permissions (as far as execution
goesi) are ok within a directory, reports problems and can also fix.
remove the problem that the PATH variable is pointing to perl/bin/baseline
and not to perl/bin (how should this be solved ?)
check that regular expressions that we receive in scm_tool_grep_edit.pl are
	valid using the method described in the perl cookbook.
add perl gtk into the baseline with a test program.

administration
==============
move files from my home directory into the change.
	(all the database and data files).
put postscript files in the baseline (documentation of cook,aegis,fhist).
Shouldnt we do a different directory for tool and another for proprietary libs ?
bring over a graphic merge tool and put it in the baseline.
bring in a graphic development environment and put it in the baseline.
bring all the c++ code in the baseline to bl/cppx

Java
====
put opemmap in the java import lib.
add java rules to create a java jar (for the entire schema directory)
	file called schema.jar.
fixup the HelloAwt example to exit on push of the button.
leave no stone unturned in the scm_profile
what about the man path ? shouldnt we change that also to point
	to our man directories ?
wrap the perlpod with our wrapper.
do a script to show all machines which are available in schema.
all scm_*.pl that have something to do with aegis should be named:
	scm_aegis_*.pl
rewrite ipass_notify as shell script

make everything in the perl dir compile
make the scm_perl_check*.pl work right (actually activate the perl
	interpreter right...:)
split the Utils lib into list,hash etc...
split the scm_*.pl scripts into tools, perl, java etc...
document all the scm_*.pl scripts properly using pod.
check that all scripts work.
start using the better prototyping facilities in perl

check how to do that each perl file will only need to use Schema::Utils::Utils
and it will get the strict and diagnostics with it as a payment...:)

0. resolve the issue of module dependency in perl.
	How can make sure that when I use a library I will also make
	available the libraries it is using ?
1. start using the perl library extensivly.
2. try to call C directly and use the realpath stuff.
3. use File::Find more.
4. start using the perl way of doing comments.
5. call realpath from C and not using external execution.
6. do the master template file well (aegis/templates/master/master.aegis).
7. should we make a link and a directory for each changes data upon creating
	like data -> /local/RnD/tmp/336data or something ? will that
	be good for keeping the people from clobbering the change
	directory with data files ?
8. move all the opt files to their own directory.
perl:
	finish the perl stuff
	rename all scripts to .pl's and put the shell under pl.

two major issues:
1. the funny files names (do basename(fiel) instead...).
2. what about the damned include files in the compilation of the imported
	libraries.

in utils.pm:
	scm_realpath - to access the C function directly.
	or better yet - a native perl implementation ?

Aegis
=====
How about storing the cook itself in the baseline ?
(yeah with all the man pages and the whole shebang...).
Check the devinstall file and check which stuff could be moved into
the baseline...

scm_will should clean the the target it the build does not make it.
scm_will should create the target directory if it does not exist.

make a hello world test program in perl using text,tk,gtk.
make a hello world test program in java using text,awt,swing,gtk.
use javadoc and produce docs.
make it using java jar files in the baseline.

unite all cook fiels to one coherent cook structure.

get an automatic source documentation softwares here:
	one for html autoproduction.
	one for gui class browsing.
stop the error with the nw2dep.
make it linking the compression stuff.
stop using the stupid Dep files.enough! no more tree2deps.
get rid of the criptic file names in aegis. put every obj near its source
	with _cmp_flg attached.

add the fact that if aegis plants a file to be removed it will be executable
	actual do a full script to fixup all removed files -
	replace the removed files with the standard template
	and also make sure it is executable.
and its execution will print a warning and still make it have all the
garbadge that the remove file now has.
stop using the environment to pass the TODO var around so that scm_will
 will know where to write the commands to be executed.
make tools have real sources (.nw files) and not a cc file and a Makefile.

-5) fix the report mechanism to get good source files reports.
	(or add a report of our own inside the baseline ?).
-6) do a new distribution of aegis with that report in it.
-7) fix up my sources script to use those.
-8) do the cmp_lists script of orens in perl.

-3) ask paolo to restore my 327 change on klein.
-2) write the strict cleanup script.
	The script should be written in perl.
	It should do the following.
	1. go from the current directory
		and recusivly check each file to check if its in the change
		or not and if it isnt remove it.

-1) patch aecc to do the right LD_LIBRARY_PATH.
0) come on - do that 2d compressor.
	problems - what is pixmap made of
	(we want to make it easy to compress).
	settle that with what libjpeg wants for compression.
1) lets do a routine to write back all the definitions in the right
	 style. (write dbdefs files back).
2) start working on the database initialization templates.
3) make the database using mysql.
4) start doing the oo wrapper around dbic.
5) make an option where the entire database definition is in a single file.
6) maybe the best place for aegis.profile is in the aegis directory.
7) add more sophisticated file templates substitutions (I mean the files
	in bl/aegis/templates/[cook nw tcl...]
	to make better initial files for the guys.

possible optimizations to baseline building:
	1. run things together (why do each dep file seperately ?)

remove the builtin includes that are built in the gcc and wc compile scripts.
our perl libs are coming up very slow. Make them go faster...
make notangle of our own to do the noweb chunks -
	this will take care of the nobs problem (no back slash).
	we could also take out comments in the problem.

make the cleanup via the cook book clean empty directories after cleanup
	also.

Dbi stuff:
==========
0) do we need any fields to be enums ? (that type is supported by sql...)
1) make the dbi class virtual and make it in /inst/tb
2) move all dbi files into dbi/inst/tb/
3) efficiency in the text parsing.
4) efficiency in the binary parsing.
5) will you start writing the varying fields in binary format or what ?
6) do the parsing more efficient (just look ahead for the next tab or newline).
7) do the optimization of the data storing using one single flat array.
8) make the binary hold only the non variable fields (this way the binaries.
	will be smaller).
	Here is another idea -
		In order to read the flat dbi binary file all at once why
		not store to record sets - one for varying fields and one
		for non varying.
9) try to read a full fleged database.
10) actually insert the fkey (check that their are pointing to uniques).
11) maybe all the dynamic data of a record should be in one file and
	not in several ? consider doing it thus.
12) get to a status of reading the database in text, writing in binary
	and converting back to text with no differences.
13) new type multipoll which is a lot of pollilines and a lot of polygons.
14) do we need a recreate method in dbi ? - yes
15) How about wrapping up the dbic with classes of our own so the
engine people will have more fun ?
16) dbiinsert - receives a dbi (with any driver) and inserts a set of
	text tables into it.
17) each database should provide the param filler with its set of demands.
18) make each record point to a restriction record too.
19) add another routine to sanity test a database on all levels.

mysite:
=======
0. do all my pdfs in PDMT.
1. replace the favicon.
2. make the "WELCOME" become "Welcome"
3. add a upload manager module.
4. add a wiki module.
5. add my signature.
6. upload my pdfs (check that they are made in PDMT).
7. add my ssl site.
8. make the background darker.

dd
==
1. do a joomla site.
2. register domain via shay (kol1.[org|org.il|com|co.il]).
3. write about us (for the about us section).
4. get more phones: guy meroz, yediot, haaretz, arab press.
5. get digital camera to take our photos.

